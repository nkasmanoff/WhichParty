{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "\n",
    "1. Scrape and tokenize democratic statements\n",
    "2. Scrape and tokenize republican statements\n",
    "3. Build a model and test\n",
    "4. Make up some phrases.\n",
    "\n",
    "5. I wanted to semantically map the embedding layer, but due to a bug in this code I have to do it another way. \n",
    "\n",
    "6. - Download the \"stances\" of different campaign sites, and see if this provides a grade of how dem or rep that person is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/noahkasmanoff/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/noahkasmanoff/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import dependencies \n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import codecs\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%pylab inline\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Scraping various sources for democratic and republican statements/stances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of dem corpus:  0\n",
      "len of dem corpus:  282\n",
      "len of dem corpus:  283\n",
      "len of dem corpus:  284\n",
      "len of dem corpus:  285\n",
      "len of dem corpus:  286\n",
      "len of dem corpus:  287\n",
      "len of dem corpus:  288\n",
      "len of dem corpus:  289\n",
      "len of dem corpus:  290\n",
      "len of dem corpus:  291\n",
      "len of dem corpus:  292\n",
      "len of dem corpus:  293\n",
      "len of dem corpus:  294\n",
      "len of dem corpus:  295\n",
      "len of dem corpus:  460\n",
      "len of dem corpus:  502\n",
      "len of dem corpus:  517\n",
      "len of dem corpus:  528\n",
      "len of dem corpus:  539\n",
      "\n",
      "Here's an example datapoint.\n",
      "We believe in protecting civil liberties and guaranteeing civil rights and voting rights, women’s rights and workers’ rights, LGBT rights, and rights for people with disabilities.\n",
      "['We', 'believe', 'in', 'protecting', 'civil', 'liberties', 'and', 'guaranteeing', 'civil', 'rights', 'and', 'voting', 'rights', 'women', 's', 'rights', 'and', 'workers', 'rights', 'LGBT', 'rights', 'and', 'rights', 'for', 'people', 'with', 'disabilities']\n",
      "The dem policy corpus contains 55,885 tokens\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#import democratic data\n",
    "\n",
    "#scrape DNC website\n",
    "url = \"https://democrats.org/about/party-platform/\"\n",
    "client = urlopen(url)\n",
    "page_html = client.read()\n",
    "page_soup = BeautifulSoup(page_html,'html.parser')\n",
    "\n",
    "\n",
    "dem_corpus = []\n",
    "print(\"len of dem corpus: \", len(dem_corpus))\n",
    "for tag in page_soup.find_all(['h1', 'p']):\n",
    "  #  print(len(tag.text))\n",
    "  #  print(tag.text)\n",
    "  #  print()\n",
    "    dem_corpus.append(tag.text)\n",
    "print(\"len of dem corpus: \", len(dem_corpus))\n",
    "\n",
    "#scrape this website a lot!\n",
    "dem_urls = [\"https://www.republicanviews.org/democratic-views-on-military-spending/\",\n",
    "       \"https://www.republicanviews.org/democratic-views-on-gay-marriage/\",\n",
    "       \"https://www.republicanviews.org/democratic-party-beliefs/\",\n",
    "       \"https://www.republicanviews.org/democratic-views-on-planned-parenthood/\",\n",
    "       \"https://www.republicanviews.org/democratic-views-on-foreign-policy/\",\n",
    "       \"https://www.republicanviews.org/democratic-views-on-illegal-immigration/\",\n",
    "       \"https://www.republicanviews.org/democratic-views-on-banking-regulation/\",\n",
    "       \"https://www.republicanviews.org/democratic-views-on-crime/\",\n",
    "       \"https://www.republicanviews.org/democratic-views-on-the-u-s-embassy-in-jerusalem/\",\n",
    "       \"https://www.republicanviews.org/democratic-views-on-trade/\",\n",
    "       \"https://www.republicanviews.org/democratic-views-on-energy/\",\n",
    "       \"https://www.republicanviews.org/democratic-views-on-national-security/\",\n",
    "       \"https://www.republicanviews.org/democratic-views-on-the-military/\"]\n",
    "\n",
    "\n",
    "for url in dem_urls:\n",
    "    client = urlopen(url)\n",
    "    page_html = client.read()\n",
    "    page_soup = BeautifulSoup(page_html,'html.parser')\n",
    "    tag = page_soup.findAll('article')[0]  #that's it. \n",
    "    dem_corpus.append(tag.text)\n",
    "    print(\"len of dem corpus: \", len(dem_corpus))\n",
    "\n",
    "#scrape some politics website. Does not use other indexing! \n",
    "url = \"http://www.ontheissues.org/Democratic_Party.htm\"\n",
    "client = urlopen(url)\n",
    "page_html = client.read()\n",
    "page_soup = BeautifulSoup(page_html,'html.parser')\n",
    "\n",
    "\n",
    "for tag in page_soup.find_all(['li']):\n",
    "    dem_corpus.append(tag.text)\n",
    "print(\"len of dem corpus: \", len(dem_corpus))\n",
    "\n",
    "\n",
    "\n",
    "#via wikipedia\n",
    "url = \"https://en.wikipedia.org/wiki/Political_positions_of_the_Democratic_Party\"\n",
    "\n",
    "client = urlopen(url)\n",
    "page_html = client.read()\n",
    "page_soup = BeautifulSoup(page_html,'html.parser')\n",
    "\n",
    "\n",
    "for tag in page_soup.find_all(['h1', 'p']):\n",
    "    dem_corpus.append(tag.text)\n",
    "print(\"len of dem corpus: \", len(dem_corpus))\n",
    "\n",
    "\n",
    "\n",
    "#scrape senate democrats website\n",
    "url = \"https://www.democrats.senate.gov/abetterdeal/higher-wages-and-better-jobs\"\n",
    "\n",
    "client = urlopen(url)\n",
    "page_html = client.read()\n",
    "page_soup = BeautifulSoup(page_html,'html.parser')\n",
    "\n",
    "\n",
    "for tag in page_soup.find_all(['h1', 'p']):\n",
    "  #  print(len(tag.text))\n",
    "  #  print(tag.text)\n",
    "  #  print()\n",
    "    dem_corpus.append(tag.text)\n",
    "print(\"len of dem corpus: \", len(dem_corpus))\n",
    "\n",
    "\n",
    "\n",
    "#continue scraping senate democrats\n",
    "url = \"https://www.democrats.senate.gov/abetterdeal/lower-the-cost-of-living-for-families\"\n",
    "\n",
    "client = urlopen(url)\n",
    "page_html = client.read()\n",
    "page_soup = BeautifulSoup(page_html,'html.parser')\n",
    "\n",
    "for tag in page_soup.find_all(['h1', 'p']):\n",
    "\n",
    "    dem_corpus.append(tag.text)\n",
    "print(\"len of dem corpus: \", len(dem_corpus))\n",
    "\n",
    "\n",
    "#and again \n",
    "\n",
    "url = \"https://www.democrats.senate.gov/abetterdeal/tools-to-succeed-in-the-21st-century\"\n",
    "\n",
    "client = urlopen(url)\n",
    "page_html = client.read()\n",
    "page_soup = BeautifulSoup(page_html,'html.parser')\n",
    "\n",
    "for tag in page_soup.find_all(['h1', 'p']):\n",
    "\n",
    "    dem_corpus.append(tag.text)\n",
    "print(\"len of dem corpus: \", len(dem_corpus))\n",
    "\n",
    "#combine all elements into a continuous body, now resembling a corpus. \n",
    "dem_corpus = \" \".join(dem_corpus)\n",
    "\n",
    "\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "\n",
    "raw_dem_sentences = tokenizer.tokenize(dem_corpus)\n",
    "\n",
    "def sentence_to_wordlist(raw):\n",
    "    clean = re.sub(\"[^a-zA-Z]\",\" \", raw)\n",
    "    words = clean.split()\n",
    "    return words\n",
    "\n",
    "\n",
    "dem_sentences = []\n",
    "for raw_dem_sentence in raw_dem_sentences:\n",
    "    if len(raw_dem_sentence) > 0:\n",
    "        dem_sentences.append(sentence_to_wordlist(raw_dem_sentence))\n",
    "print()     \n",
    "print(\"Here's an example datapoint.\")      \n",
    "print(raw_dem_sentences[50])\n",
    "print(sentence_to_wordlist(raw_dem_sentences[50]))\n",
    "\n",
    "\n",
    "\n",
    "token_count = sum([len(dem_sentence) for dem_sentence in dem_sentences])\n",
    "print(\"The dem policy corpus contains {0:,} tokens\".format(token_count))\n",
    "\n",
    "\n",
    "y_dems = np.ones(shape=np.shape(dem_sentences)) #now the labels. \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rep corpus:  0\n",
      "len of rep corpus:  72\n",
      "len of rep corpus:  280\n",
      "len of rep corpus:  281\n",
      "len of rep corpus:  282\n",
      "len of rep corpus:  283\n",
      "len of rep corpus:  284\n",
      "len of rep corpus:  285\n",
      "len of rep corpus:  286\n",
      "len of rep corpus:  287\n",
      "len of rep corpus:  288\n",
      "len of rep corpus:  289\n",
      "len of rep corpus:  290\n",
      "len of rep corpus:  291\n",
      "len of rep corpus:  292\n",
      "len of rep corpus:  293\n",
      "len of rep corpus:  294\n",
      "Reading 'rep_platform.txt'...\n",
      "\n",
      "Here's an example sentence in rep corpus.\n",
      "[14]\n",
      " Republican party leaders strongly believe that free markets and individual achievement are the primary factors behind economic prosperity.\n",
      "['Republican', 'party', 'leaders', 'strongly', 'believe', 'that', 'free', 'markets', 'and', 'individual', 'achievement', 'are', 'the', 'primary', 'factors', 'behind', 'economic', 'prosperity']\n",
      "The rep policy corpus contains 78,822 tokens\n"
     ]
    }
   ],
   "source": [
    "#Now the republican data. \n",
    "\n",
    "#scrape wikipedia description. \n",
    "url = \"https://en.wikipedia.org/wiki/Political_positions_of_the_Republican_Party\"\n",
    "client = urlopen(url)\n",
    "page_html = client.read()\n",
    "page_soup = BeautifulSoup(page_html,'html.parser')\n",
    "\n",
    "\n",
    "rep_corpus = []\n",
    "print(\"len of rep corpus: \", len(rep_corpus))\n",
    "for tag in page_soup.find_all(['h1', 'p']):\n",
    "  #  print(len(tag.text))\n",
    "  #  print(tag.text)\n",
    "  #  print()\n",
    "    rep_corpus.append(tag.text)\n",
    "print(\"len of rep corpus: \", len(rep_corpus))\n",
    "\n",
    "#Scrape GOP website for official platform\n",
    "#Forbidden, so I copy pasted it all into a text file also in this repo. \n",
    "\n",
    "#on the issues website\n",
    "url = \"http://www.ontheissues.org/Republican_Party.htm\"\n",
    "\n",
    "client = urlopen(url)\n",
    "page_html = client.read()\n",
    "page_soup = BeautifulSoup(page_html,'html.parser')\n",
    "\n",
    "\n",
    "for tag in page_soup.find_all(['li']):\n",
    "  #  print(len(tag.text))\n",
    "  #  print(tag.text)\n",
    "  #  print()\n",
    "    rep_corpus.append(tag.text)\n",
    "print(\"len of rep corpus: \", len(rep_corpus))\n",
    "\n",
    "\n",
    "\n",
    "rep_urls  = [\"https://www.republicanviews.org/republican-views-on-the-economy/\",\n",
    "\n",
    "\"https://www.republicanviews.org/republican-views-on-energy/\",\n",
    "\n",
    "\"https://www.republicanviews.org/republican-views-on-the-environment/\",\n",
    "\n",
    "\"https://www.republicanviews.org/republican-views-on-health-care/\",\n",
    "\n",
    "\"https://www.republicanviews.org/republican-views-on-immigration/\",\n",
    "\n",
    "\"https://www.republicanviews.org/republican-views-on-social-security/\",\n",
    "\n",
    "\"https://www.republicanviews.org/republican-views-on-bitcoin-and-cryptocurrencies/\",\n",
    "\n",
    "\"https://www.republicanviews.org/republican-views-on-the-u-s-embassy-in-jerusalem/\",\n",
    "\n",
    "\"https://www.republicanviews.org/republican-views-on-unemployment/\",\n",
    "\n",
    "\"https://www.republicanviews.org/republican-views-on-terrorism/\",\n",
    "\n",
    "\"https://www.republicanviews.org/republican-views-on-stem-cell-research/\",\n",
    "\n",
    "\"https://www.republicanviews.org/republican-views-on-the-electoral-college/\",\n",
    "\n",
    "\"https://www.republicanviews.org/republican-views-on-religion/\",\n",
    "\n",
    "\"https://www.republicanviews.org/republican-views-on-net-neutrality/\"]\n",
    "\n",
    "for url in rep_urls:\n",
    "    client = urlopen(url)\n",
    "    page_html = client.read()\n",
    "    page_soup = BeautifulSoup(page_html,'html.parser')\n",
    "    tag = page_soup.findAll('article')[0]  #that's it. \n",
    "    rep_corpus.append(tag.text)\n",
    "    print(\"len of rep corpus: \", len(rep_corpus))\n",
    "\n",
    "\n",
    "\n",
    "rep_corpus = \" \".join(rep_corpus)\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#open the text file and \n",
    "rep_platform_corpus_raw = u\"\"\n",
    "print(\"Reading '{0}'...\".format('rep_platform.txt'))\n",
    "with codecs.open('rep_platform.txt', \"r\", \"utf-8\") as book_file:\n",
    "    rep_platform_corpus_raw += book_file.read()\n",
    "\n",
    "rep_corpus += rep_platform_corpus_raw\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "raw_rep_sentences = tokenizer.tokenize(rep_corpus)\n",
    "\n",
    "\n",
    "def sentence_to_wordlist(raw):\n",
    "    clean = re.sub(\"[^a-zA-Z]\",\" \", raw)\n",
    "    words = clean.split()\n",
    "    return words\n",
    "\n",
    "\n",
    "rep_sentences = []\n",
    "for raw_rep_sentence in raw_rep_sentences:\n",
    "    if len(raw_rep_sentence) > 0:\n",
    "        rep_sentences.append(sentence_to_wordlist(raw_rep_sentence))\n",
    "        \n",
    "print()\n",
    "print(\"Here's an example sentence in rep corpus.\")\n",
    "print(raw_rep_sentences[10])\n",
    "print(sentence_to_wordlist(raw_rep_sentences[10]))\n",
    "\n",
    "\n",
    "token_count = sum([len(rep_sentence) for rep_sentence in rep_sentences])\n",
    "print(\"The rep policy corpus contains {0:,} tokens\".format(token_count))\n",
    "\n",
    "\n",
    "y_reps = np.zeros(shape=np.shape(rep_sentences))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now it's modelling time \n",
    "\n",
    "Reference: \n",
    "https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/20_Natural_Language_Processing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "\n",
    "# from tf.keras.models import Sequential  # This does not work!\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, GRU, Embedding\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Tokenizing and splitting these statements into a training/testing format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Republican administration will champion an open and free internet based on principles of free expression and universal values and will pursue policies to empower citizens and U.S. companies operating in authoritarian countries to circumvent internet firewalls and gain accurate news and information online.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_rep_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To recreate the structure of the imdb dataset, the next plan is to concatenate the dem and rep texts and simultaneously with the labels of 1 or 0, and probably shuffle both. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_text = np.concatenate((raw_dem_sentences,raw_rep_sentences))\n",
    "y = np.concatenate((y_dems,y_reps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(X_text, y ,shuffle=True, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6659"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rep policy corpus contains 886,886 tokens\n"
     ]
    }
   ],
   "source": [
    "token_count = sum([len(sentence) for sentence in X_text])\n",
    "print(\"The rep policy corpus contains {0:,} tokens\".format(token_count))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training and testing data are now separated and shuffled. Next task is to tokenize these words once again, but now this will be based on an integer value for indexing each word (note this contains no semantic meaning), and once fit you can determine how many unique words to include."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_words=8000\n",
    "tokenizer = Tokenizer(num_words=num_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting: \n",
    "The tokenizer scans through all the text and strips unwanted characters, converts everything to lowercase, and builds a vocabulary of all the unique words. It's ok that it uses the entire dataset, as the embedding is only based on the training data (not sure how accurate this is though should follow this up). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(X_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9597\n"
     ]
    }
   ],
   "source": [
    "if num_words is None:\n",
    "    num_words = len(tokenizer.word_index)\n",
    "print(len(tokenizer.word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'and': 2,\n",
       " 'to': 3,\n",
       " 'of': 4,\n",
       " '\\r': 5,\n",
       " 'in': 6,\n",
       " 'a': 7,\n",
       " 'that': 8,\n",
       " 'for': 9,\n",
       " 'we': 10,\n",
       " 'on': 11,\n",
       " 'is': 12,\n",
       " 'aug': 13,\n",
       " 'our': 14,\n",
       " 'as': 15,\n",
       " '2000': 16,\n",
       " 'will': 17,\n",
       " 'with': 18,\n",
       " '2004': 19,\n",
       " 'by': 20,\n",
       " 'their': 21,\n",
       " 'be': 22,\n",
       " 'are': 23,\n",
       " 'it': 24,\n",
       " 'not': 25,\n",
       " 'have': 26,\n",
       " 'sep': 27,\n",
       " 'support': 28,\n",
       " 'democrats': 29,\n",
       " 'they': 30,\n",
       " 'from': 31,\n",
       " 'republican': 32,\n",
       " 'more': 33,\n",
       " 'has': 34,\n",
       " 'should': 35,\n",
       " 'or': 36,\n",
       " 'this': 37,\n",
       " 'democratic': 38,\n",
       " 'american': 39,\n",
       " 'party': 40,\n",
       " 'republicans': 41,\n",
       " 'all': 42,\n",
       " 'views': 43,\n",
       " 'believe': 44,\n",
       " 'government': 45,\n",
       " 'health': 46,\n",
       " 'federal': 47,\n",
       " 'an': 48,\n",
       " 'who': 49,\n",
       " 'must': 50,\n",
       " 'military': 51,\n",
       " 'states': 52,\n",
       " 'also': 53,\n",
       " 'rights': 54,\n",
       " 'national': 55,\n",
       " 'people': 56,\n",
       " '”': 57,\n",
       " 'at': 58,\n",
       " 'care': 59,\n",
       " 'jul': 60,\n",
       " '2012': 61,\n",
       " 'which': 62,\n",
       " 'security': 63,\n",
       " 'public': 64,\n",
       " 'new': 65,\n",
       " 'americans': 66,\n",
       " 'those': 67,\n",
       " 'against': 68,\n",
       " 'would': 69,\n",
       " 'its': 70,\n",
       " 'state': 71,\n",
       " 'no': 72,\n",
       " 'other': 73,\n",
       " 'president': 74,\n",
       " 'but': 75,\n",
       " 'energy': 76,\n",
       " 'system': 77,\n",
       " 'many': 78,\n",
       " 'than': 79,\n",
       " 'tax': 80,\n",
       " 'been': 81,\n",
       " 'reform': 82,\n",
       " 'can': 83,\n",
       " 'these': 84,\n",
       " 'while': 85,\n",
       " 'country': 86,\n",
       " 'united': 87,\n",
       " 'u': 88,\n",
       " 'education': 89,\n",
       " 'work': 90,\n",
       " 'defense': 91,\n",
       " 'economic': 92,\n",
       " 'protect': 93,\n",
       " 'act': 94,\n",
       " 'right': 95,\n",
       " 'economy': 96,\n",
       " 'law': 97,\n",
       " 'make': 98,\n",
       " 'congress': 99,\n",
       " 'laws': 100,\n",
       " 'do': 101,\n",
       " 'marriage': 102,\n",
       " 's': 103,\n",
       " 'one': 104,\n",
       " 'jobs': 105,\n",
       " 'programs': 106,\n",
       " '2016': 107,\n",
       " 'when': 108,\n",
       " 'need': 109,\n",
       " 'social': 110,\n",
       " 'access': 111,\n",
       " 'jun': 112,\n",
       " 'most': 113,\n",
       " 'america': 114,\n",
       " 'only': 115,\n",
       " 'so': 116,\n",
       " 'was': 117,\n",
       " 'over': 118,\n",
       " 'top': 119,\n",
       " 'such': 120,\n",
       " 'including': 121,\n",
       " 'any': 122,\n",
       " 'immigration': 123,\n",
       " 'through': 124,\n",
       " 'policy': 125,\n",
       " 'foreign': 126,\n",
       " 'based': 127,\n",
       " 'world': 128,\n",
       " 'fight': 129,\n",
       " 'oppose': 130,\n",
       " 'end': 131,\n",
       " 'private': 132,\n",
       " 'provide': 133,\n",
       " 'them': 134,\n",
       " 'better': 135,\n",
       " 'help': 136,\n",
       " 'research': 137,\n",
       " 'abortion': 138,\n",
       " 'life': 139,\n",
       " 'every': 140,\n",
       " 'trade': 141,\n",
       " 'spending': 142,\n",
       " 'free': 143,\n",
       " 'out': 144,\n",
       " 'current': 145,\n",
       " 'encourage': 146,\n",
       " '–': 147,\n",
       " 'families': 148,\n",
       " 'workers': 149,\n",
       " 'into': 150,\n",
       " 'between': 151,\n",
       " 'religious': 152,\n",
       " 'amendment': 153,\n",
       " 'nuclear': 154,\n",
       " 'funding': 155,\n",
       " 'both': 156,\n",
       " '—': 157,\n",
       " 'administration': 158,\n",
       " 'communities': 159,\n",
       " 'war': 160,\n",
       " 'use': 161,\n",
       " 'ensure': 162,\n",
       " 'first': 163,\n",
       " 'years': 164,\n",
       " 'there': 165,\n",
       " 'needs': 166,\n",
       " 'he': 167,\n",
       " 'budget': 168,\n",
       " 'continue': 169,\n",
       " 'create': 170,\n",
       " 'efforts': 171,\n",
       " 'time': 172,\n",
       " 'well': 173,\n",
       " 'under': 174,\n",
       " 'school': 175,\n",
       " 'reduce': 176,\n",
       " 'same': 177,\n",
       " 'bush': 178,\n",
       " 'policies': 179,\n",
       " 'like': 180,\n",
       " 'without': 181,\n",
       " 'women': 182,\n",
       " 'change': 183,\n",
       " 'college': 184,\n",
       " 'vote': 185,\n",
       " 'what': 186,\n",
       " 'political': 187,\n",
       " 'keep': 188,\n",
       " 'own': 189,\n",
       " 'israel': 190,\n",
       " 'long': 191,\n",
       " 'his': 192,\n",
       " 'because': 193,\n",
       " 'human': 194,\n",
       " 'family': 195,\n",
       " 'trump': 196,\n",
       " 'us': 197,\n",
       " 'service': 198,\n",
       " 'allow': 199,\n",
       " 'market': 200,\n",
       " 'obama': 201,\n",
       " 'restore': 202,\n",
       " 'development': 203,\n",
       " 'increase': 204,\n",
       " 'platform': 205,\n",
       " 'power': 206,\n",
       " 'good': 207,\n",
       " 'international': 208,\n",
       " 'benefits': 209,\n",
       " 'growth': 210,\n",
       " 'pay': 211,\n",
       " 'nation': 212,\n",
       " 'home': 213,\n",
       " 'costs': 214,\n",
       " 'freedom': 215,\n",
       " 'promote': 216,\n",
       " 'nations': 217,\n",
       " 'resources': 218,\n",
       " 'issues': 219,\n",
       " 'constitutional': 220,\n",
       " 'housing': 221,\n",
       " 'immigrants': 222,\n",
       " 'services': 223,\n",
       " 'weapons': 224,\n",
       " 'percent': 225,\n",
       " 'issue': 226,\n",
       " 'were': 227,\n",
       " 'schools': 228,\n",
       " 'just': 229,\n",
       " 'call': 230,\n",
       " 'up': 231,\n",
       " 'action': 232,\n",
       " 'if': 233,\n",
       " 'affordable': 234,\n",
       " 'medicare': 235,\n",
       " 'way': 236,\n",
       " 'environmental': 237,\n",
       " 'see': 238,\n",
       " 'financial': 239,\n",
       " 'children': 240,\n",
       " 'democracy': 241,\n",
       " 'business': 242,\n",
       " 'choice': 243,\n",
       " 'important': 244,\n",
       " 'businesses': 245,\n",
       " 'global': 246,\n",
       " 'century': 247,\n",
       " 'strengthen': 248,\n",
       " 'high': 249,\n",
       " 'strong': 250,\n",
       " 'especially': 251,\n",
       " 'small': 252,\n",
       " 'citizens': 253,\n",
       " 'middle': 254,\n",
       " 'legislation': 255,\n",
       " 'committed': 256,\n",
       " 'control': 257,\n",
       " 'about': 258,\n",
       " 'best': 259,\n",
       " 'instead': 260,\n",
       " 'future': 261,\n",
       " 'program': 262,\n",
       " 'china': 263,\n",
       " 'safety': 264,\n",
       " 'legal': 265,\n",
       " 'investment': 266,\n",
       " 'child': 267,\n",
       " 'illegal': 268,\n",
       " 'treatment': 269,\n",
       " 'money': 270,\n",
       " 'year': 271,\n",
       " 'income': 272,\n",
       " 'community': 273,\n",
       " 'individuals': 274,\n",
       " 'plan': 275,\n",
       " 'america’s': 276,\n",
       " 'discrimination': 277,\n",
       " 'local': 278,\n",
       " 'technology': 279,\n",
       " 'countries': 280,\n",
       " 'peace': 281,\n",
       " 'now': 282,\n",
       " 'members': 283,\n",
       " 'enforcement': 284,\n",
       " 'stem': 285,\n",
       " 'oct': 286,\n",
       " 'terrorism': 287,\n",
       " 'donald': 288,\n",
       " 'institutions': 289,\n",
       " 'constitution': 290,\n",
       " 'safe': 291,\n",
       " 'however': 292,\n",
       " 'too': 293,\n",
       " 'climate': 294,\n",
       " 'some': 295,\n",
       " 'expand': 296,\n",
       " 'made': 297,\n",
       " '2006': 298,\n",
       " 'take': 299,\n",
       " 'respect': 300,\n",
       " 'two': 301,\n",
       " 'opportunity': 302,\n",
       " 'give': 303,\n",
       " 'forces': 304,\n",
       " 'ban': 305,\n",
       " 'drug': 306,\n",
       " 'comprehensive': 307,\n",
       " 'within': 308,\n",
       " 'millions': 309,\n",
       " 'recognize': 310,\n",
       " 'gay': 311,\n",
       " 'down': 312,\n",
       " 'insurance': 313,\n",
       " 'where': 314,\n",
       " 'medical': 315,\n",
       " 'assistance': 316,\n",
       " 'net': 317,\n",
       " 'regulations': 318,\n",
       " 'part': 319,\n",
       " 'healthcare': 320,\n",
       " 'seek': 321,\n",
       " 'believes': 322,\n",
       " 'increased': 323,\n",
       " 'property': 324,\n",
       " 'environment': 325,\n",
       " 'regulation': 326,\n",
       " 'traditional': 327,\n",
       " 'clean': 328,\n",
       " 'students': 329,\n",
       " 'justice': 330,\n",
       " 'last': 331,\n",
       " 'force': 332,\n",
       " 'even': 333,\n",
       " 'does': 334,\n",
       " 'faith': 335,\n",
       " 'welfare': 336,\n",
       " 'sources': 337,\n",
       " 'gays': 338,\n",
       " 'class': 339,\n",
       " 'after': 340,\n",
       " 'standards': 341,\n",
       " 'around': 342,\n",
       " 'lead': 343,\n",
       " 'being': 344,\n",
       " 'during': 345,\n",
       " 'crime': 346,\n",
       " 'focus': 347,\n",
       " 'house': 348,\n",
       " 'stating': 349,\n",
       " 'working': 350,\n",
       " '21st': 351,\n",
       " 'get': 352,\n",
       " 'organizations': 353,\n",
       " 'sector': 354,\n",
       " 'build': 355,\n",
       " 'eliminate': 356,\n",
       " 'internet': 357,\n",
       " 'i': 358,\n",
       " 'adsbygoogle': 359,\n",
       " 'cell': 360,\n",
       " '2003': 361,\n",
       " 'may': 362,\n",
       " 'across': 363,\n",
       " 'possible': 364,\n",
       " 'responsibility': 365,\n",
       " 'learning': 366,\n",
       " 'supported': 367,\n",
       " 'iraq': 368,\n",
       " 'cost': 369,\n",
       " 'full': 370,\n",
       " 'rather': 371,\n",
       " 'minimum': 372,\n",
       " 'poverty': 373,\n",
       " 'labor': 374,\n",
       " 'companies': 375,\n",
       " 'why': 376,\n",
       " 'become': 377,\n",
       " 'protection': 378,\n",
       " 'open': 379,\n",
       " 'urge': 380,\n",
       " 'sex': 381,\n",
       " 'view': 382,\n",
       " 'behind': 383,\n",
       " 'stand': 384,\n",
       " 'quality': 385,\n",
       " 'authority': 386,\n",
       " 'much': 387,\n",
       " 'industry': 388,\n",
       " 'nation’s': 389,\n",
       " 'given': 390,\n",
       " 'used': 391,\n",
       " 'providing': 392,\n",
       " 'cut': 393,\n",
       " 'strongly': 394,\n",
       " 'values': 395,\n",
       " 'upon': 396,\n",
       " 'electoral': 397,\n",
       " 'jerusalem': 398,\n",
       " 'stated': 399,\n",
       " 'how': 400,\n",
       " 'equal': 401,\n",
       " 'civil': 402,\n",
       " 'low': 403,\n",
       " 'plans': 404,\n",
       " 'officials': 405,\n",
       " 'missile': 406,\n",
       " 'advance': 407,\n",
       " 'job': 408,\n",
       " 'oil': 409,\n",
       " 'election': 410,\n",
       " 'wage': 411,\n",
       " 'place': 412,\n",
       " 'cannot': 413,\n",
       " 'taking': 414,\n",
       " 'taxes': 415,\n",
       " 'develop': 416,\n",
       " 'debt': 417,\n",
       " 'approach': 418,\n",
       " 'gun': 419,\n",
       " 'clinton': 420,\n",
       " 'embassy': 421,\n",
       " 'leadership': 422,\n",
       " 'great': 423,\n",
       " 'protecting': 424,\n",
       " 'number': 425,\n",
       " 'union': 426,\n",
       " 'order': 427,\n",
       " 'among': 428,\n",
       " 'department': 429,\n",
       " 'stop': 430,\n",
       " 'student': 431,\n",
       " 'senate': 432,\n",
       " 'far': 433,\n",
       " 'voting': 434,\n",
       " 'veterans': 435,\n",
       " 'higher': 436,\n",
       " 'leaders': 437,\n",
       " 'defend': 438,\n",
       " 'governments': 439,\n",
       " 'key': 440,\n",
       " 'push': 441,\n",
       " 'death': 442,\n",
       " 'natural': 443,\n",
       " 'bill': 444,\n",
       " 'affirm': 445,\n",
       " 'since': 446,\n",
       " 'majority': 447,\n",
       " 'put': 448,\n",
       " 'increasing': 449,\n",
       " 'making': 450,\n",
       " 'threats': 451,\n",
       " 'decision': 452,\n",
       " 'drugs': 453,\n",
       " 'deal': 454,\n",
       " 'wall': 455,\n",
       " 'disabilities': 456,\n",
       " 'fundamental': 457,\n",
       " 'existing': 458,\n",
       " 'able': 459,\n",
       " 'before': 460,\n",
       " 'repeal': 461,\n",
       " 'intelligence': 462,\n",
       " 'nato': 463,\n",
       " 'border': 464,\n",
       " 'common': 465,\n",
       " 'penalty': 466,\n",
       " 'corporate': 467,\n",
       " 'investments': 468,\n",
       " 'employment': 469,\n",
       " 'address': 470,\n",
       " 'supports': 471,\n",
       " 'improve': 472,\n",
       " 'means': 473,\n",
       " 'tribal': 474,\n",
       " 'homeland': 475,\n",
       " 'combat': 476,\n",
       " 'crisis': 477,\n",
       " 'retirement': 478,\n",
       " 'interests': 479,\n",
       " 'agenda': 480,\n",
       " 'greater': 481,\n",
       " 'terrorists': 482,\n",
       " 'partners': 483,\n",
       " 'accountability': 484,\n",
       " 'judges': 485,\n",
       " 'needed': 486,\n",
       " 'oped': 487,\n",
       " 'had': 488,\n",
       " 'back': 489,\n",
       " 'process': 490,\n",
       " 'could': 491,\n",
       " 'establish': 492,\n",
       " 'cuts': 493,\n",
       " 'independence': 494,\n",
       " 'commitment': 495,\n",
       " 'lands': 496,\n",
       " 'therefore': 497,\n",
       " 'east': 498,\n",
       " 'org': 499,\n",
       " 'gop': 500,\n",
       " 'together': 501,\n",
       " 'role': 502,\n",
       " 'society': 503,\n",
       " 'presidential': 504,\n",
       " 'effective': 505,\n",
       " 'success': 506,\n",
       " 'lives': 507,\n",
       " 'status': 508,\n",
       " 'groups': 509,\n",
       " 'citizenship': 510,\n",
       " 'strategy': 511,\n",
       " 'culture': 512,\n",
       " 'va': 513,\n",
       " 'administration’s': 514,\n",
       " 'basic': 515,\n",
       " 'level': 516,\n",
       " 'day': 517,\n",
       " 'lower': 518,\n",
       " 'attack': 519,\n",
       " 'creating': 520,\n",
       " 'executive': 521,\n",
       " 'prevent': 522,\n",
       " 'abuse': 523,\n",
       " 'opportunities': 524,\n",
       " 'indian': 525,\n",
       " '10': 526,\n",
       " 'religion': 527,\n",
       " 'similar': 528,\n",
       " 'violence': 529,\n",
       " 'further': 530,\n",
       " 'she': 531,\n",
       " 'look': 532,\n",
       " 'left': 533,\n",
       " 'paying': 534,\n",
       " 'innovation': 535,\n",
       " 'elections': 536,\n",
       " 'threat': 537,\n",
       " 'relations': 538,\n",
       " 'called': 539,\n",
       " 'serve': 540,\n",
       " 'limit': 541,\n",
       " 'secure': 542,\n",
       " 'systems': 543,\n",
       " 'neutrality': 544,\n",
       " 'criminal': 545,\n",
       " 'large': 546,\n",
       " 'include': 547,\n",
       " 'provided': 548,\n",
       " 'africa': 549,\n",
       " 'obamacare': 550,\n",
       " 'beliefs': 551,\n",
       " 'voted': 552,\n",
       " 'challenges': 553,\n",
       " 'face': 554,\n",
       " 'term': 555,\n",
       " 'know': 556,\n",
       " 'fair': 557,\n",
       " 'benefit': 558,\n",
       " 'leading': 559,\n",
       " 'fund': 560,\n",
       " 'options': 561,\n",
       " 'clear': 562,\n",
       " 'seniors': 563,\n",
       " 'regulatory': 564,\n",
       " 'infrastructure': 565,\n",
       " 'invest': 566,\n",
       " 'country’s': 567,\n",
       " 'markets': 568,\n",
       " 'recent': 569,\n",
       " 'agreement': 570,\n",
       " 'speech': 571,\n",
       " 'powers': 572,\n",
       " 'prosperity': 573,\n",
       " '1': 574,\n",
       " 'strength': 575,\n",
       " 'troops': 576,\n",
       " '“we': 577,\n",
       " 'move': 578,\n",
       " 'meet': 579,\n",
       " 'teachers': 580,\n",
       " 'allies': 581,\n",
       " 'bring': 582,\n",
       " 'fact': 583,\n",
       " 'court': 584,\n",
       " 'workforce': 585,\n",
       " 'position': 586,\n",
       " 'voter': 587,\n",
       " 'land': 588,\n",
       " 'whether': 589,\n",
       " 'risk': 590,\n",
       " 'run': 591,\n",
       " 'liberty': 592,\n",
       " 'decisions': 593,\n",
       " 'reforms': 594,\n",
       " 'individual': 595,\n",
       " 'come': 596,\n",
       " 'million': 597,\n",
       " 'coverage': 598,\n",
       " 'promise': 599,\n",
       " 'training': 600,\n",
       " 'expanding': 601,\n",
       " 'ensuring': 602,\n",
       " 'parents': 603,\n",
       " 'information': 604,\n",
       " 'hold': 605,\n",
       " 'want': 606,\n",
       " 'line': 607,\n",
       " 'billion': 608,\n",
       " 'renewable': 609,\n",
       " 'planned': 610,\n",
       " 'terror': 611,\n",
       " 'cause': 612,\n",
       " 'cooperation': 613,\n",
       " 'here': 614,\n",
       " 'influence': 615,\n",
       " 'campaign': 616,\n",
       " 'conditions': 617,\n",
       " 'enact': 618,\n",
       " 'reject': 619,\n",
       " 'agencies': 620,\n",
       " 'creation': 621,\n",
       " 'supreme': 622,\n",
       " 'past': 623,\n",
       " 'opposed': 624,\n",
       " 'mental': 625,\n",
       " 'limited': 626,\n",
       " 'terrorist': 627,\n",
       " 'taiwan': 628,\n",
       " 'reason': 629,\n",
       " 'aid': 630,\n",
       " 'pro': 631,\n",
       " 'less': 632,\n",
       " 'still': 633,\n",
       " 'makes': 634,\n",
       " 'rebuild': 635,\n",
       " 'ability': 636,\n",
       " 'share': 637,\n",
       " 'rule': 638,\n",
       " 'next': 639,\n",
       " 'priority': 640,\n",
       " 'critical': 641,\n",
       " 'pursue': 642,\n",
       " 'average': 643,\n",
       " 'rates': 644,\n",
       " 'limits': 645,\n",
       " 'post': 646,\n",
       " 'n': 647,\n",
       " 'history': 648,\n",
       " 'racial': 649,\n",
       " 'interest': 650,\n",
       " 'created': 651,\n",
       " 'always': 652,\n",
       " 'you': 653,\n",
       " 'supporting': 654,\n",
       " 'loans': 655,\n",
       " 'major': 656,\n",
       " 'requirements': 657,\n",
       " 'ownership': 658,\n",
       " 'trust': 659,\n",
       " 'young': 660,\n",
       " 'today': 661,\n",
       " 'close': 662,\n",
       " 'unemployment': 663,\n",
       " 'sexual': 664,\n",
       " 'domestic': 665,\n",
       " 'congressional': 666,\n",
       " 'general': 667,\n",
       " 'equip': 668,\n",
       " 'another': 669,\n",
       " 'set': 670,\n",
       " 'parties': 671,\n",
       " 'favor': 672,\n",
       " 'let': 673,\n",
       " 'conservative': 674,\n",
       " 'early': 675,\n",
       " 'said': 676,\n",
       " 'principles': 677,\n",
       " 'rules': 678,\n",
       " 'personal': 679,\n",
       " 'path': 680,\n",
       " 'preserve': 681,\n",
       " 'engage': 682,\n",
       " 'rate': 683,\n",
       " 'funds': 684,\n",
       " 'basis': 685,\n",
       " 'strategies': 686,\n",
       " 'hope': 687,\n",
       " 'done': 688,\n",
       " 'medicaid': 689,\n",
       " 'parenthood': 690,\n",
       " 'republicanviews': 691,\n",
       " 'popular': 692,\n",
       " 'conflict': 693,\n",
       " 'stronger': 694,\n",
       " 'self': 695,\n",
       " 'street': 696,\n",
       " 'then': 697,\n",
       " 'living': 698,\n",
       " 'protections': 699,\n",
       " 'applaud': 700,\n",
       " '000': 701,\n",
       " 'universal': 702,\n",
       " 'anti': 703,\n",
       " 'non': 704,\n",
       " 'afghanistan': 705,\n",
       " 'mccain': 706,\n",
       " 'representatives': 707,\n",
       " 'nov': 708,\n",
       " 'ideas': 709,\n",
       " 'passed': 710,\n",
       " 'pledge': 711,\n",
       " 'require': 712,\n",
       " 'practices': 713,\n",
       " 'effort': 714,\n",
       " 'appropriate': 715,\n",
       " 'already': 716,\n",
       " 'progress': 717,\n",
       " 'enable': 718,\n",
       " 'often': 719,\n",
       " 'agreements': 720,\n",
       " 'each': 721,\n",
       " 'impose': 722,\n",
       " 'destruction': 723,\n",
       " 'proposed': 724,\n",
       " 'did': 725,\n",
       " 'asia': 726,\n",
       " 'greatly': 727,\n",
       " 'regarding': 728,\n",
       " 'romney': 729,\n",
       " 'apr': 730,\n",
       " 'go': 731,\n",
       " 'live': 732,\n",
       " 'her': 733,\n",
       " 'borders': 734,\n",
       " 'unions': 735,\n",
       " 'pass': 736,\n",
       " 'due': 737,\n",
       " 'areas': 738,\n",
       " 'necessary': 739,\n",
       " 'food': 740,\n",
       " 'problem': 741,\n",
       " 'led': 742,\n",
       " 'adoption': 743,\n",
       " 'value': 744,\n",
       " 'problems': 745,\n",
       " 'corporations': 746,\n",
       " 'others': 747,\n",
       " 'example': 748,\n",
       " 'lost': 749,\n",
       " 'centers': 750,\n",
       " 'providers': 751,\n",
       " 'wish': 752,\n",
       " '2007': 753,\n",
       " 'filed': 754,\n",
       " '“the': 755,\n",
       " 'missiles': 756,\n",
       " 'choose': 757,\n",
       " 'shared': 758,\n",
       " 'times': 759,\n",
       " 'break': 760,\n",
       " 'goal': 761,\n",
       " 'grants': 762,\n",
       " 'sure': 763,\n",
       " 'toward': 764,\n",
       " 'credit': 765,\n",
       " 'save': 766,\n",
       " 'remain': 767,\n",
       " 'decades': 768,\n",
       " 'digital': 769,\n",
       " 'abroad': 770,\n",
       " 'data': 771,\n",
       " 'fully': 772,\n",
       " 'reserve': 773,\n",
       " 'gas': 774,\n",
       " 'courts': 775,\n",
       " 'prevention': 776,\n",
       " 'terms': 777,\n",
       " '3': 778,\n",
       " 'voters': 779,\n",
       " 'office': 780,\n",
       " 'ballistic': 781,\n",
       " 'privacy': 782,\n",
       " 'washington': 783,\n",
       " 'window': 784,\n",
       " 'posts': 785,\n",
       " 'tagged': 786,\n",
       " 'prayer': 787,\n",
       " 'belief': 788,\n",
       " 'hard': 789,\n",
       " 'overseas': 790,\n",
       " 'god': 791,\n",
       " 'never': 792,\n",
       " 'allowed': 793,\n",
       " 'honor': 794,\n",
       " 'lgbt': 795,\n",
       " 'parts': 796,\n",
       " 'keeping': 797,\n",
       " 'commission': 798,\n",
       " 'big': 799,\n",
       " 'demand': 800,\n",
       " 'modernize': 801,\n",
       " 'impact': 802,\n",
       " 'intellectual': 803,\n",
       " 'start': 804,\n",
       " 'banks': 805,\n",
       " 'condemn': 806,\n",
       " 'arms': 807,\n",
       " 'accounts': 808,\n",
       " 'three': 809,\n",
       " 'held': 810,\n",
       " 'capital': 811,\n",
       " 'puerto': 812,\n",
       " 'modern': 813,\n",
       " 'simply': 814,\n",
       " 'poor': 815,\n",
       " 'second': 816,\n",
       " 'proliferation': 817,\n",
       " 'latin': 818,\n",
       " 'thru': 819,\n",
       " 'forward': 820,\n",
       " 'real': 821,\n",
       " 'away': 822,\n",
       " 'say': 823,\n",
       " 'particularly': 824,\n",
       " 'production': 825,\n",
       " 'enforce': 826,\n",
       " 'independent': 827,\n",
       " 'includes': 828,\n",
       " 'promoting': 829,\n",
       " 'participation': 830,\n",
       " 'science': 831,\n",
       " 'water': 832,\n",
       " 'contributions': 833,\n",
       " 'measures': 834,\n",
       " 'special': 835,\n",
       " 'cover': 836,\n",
       " 'size': 837,\n",
       " 'adversaries': 838,\n",
       " 'israeli': 839,\n",
       " '2008': 840,\n",
       " 'longer': 841,\n",
       " 'wages': 842,\n",
       " 'race': 843,\n",
       " 'finance': 844,\n",
       " 'man': 845,\n",
       " 'homes': 846,\n",
       " 'despite': 847,\n",
       " 'leave': 848,\n",
       " 'building': 849,\n",
       " 'towards': 850,\n",
       " 'age': 851,\n",
       " 'advanced': 852,\n",
       " 'transparency': 853,\n",
       " 'tools': 854,\n",
       " 'white': 855,\n",
       " 'central': 856,\n",
       " 'maintain': 857,\n",
       " 'restrictions': 858,\n",
       " 'multiple': 859,\n",
       " 'essential': 860,\n",
       " 'prescription': 861,\n",
       " 'pre': 862,\n",
       " 'iran': 863,\n",
       " 'region': 864,\n",
       " 'ties': 865,\n",
       " 'southern': 866,\n",
       " 'senator': 867,\n",
       " '2014': 868,\n",
       " 'democrat': 869,\n",
       " 'vouchers': 870,\n",
       " 'economics': 871,\n",
       " 'relocation': 872,\n",
       " 'propose': 873,\n",
       " 'whole': 874,\n",
       " 'party’s': 875,\n",
       " 'gained': 876,\n",
       " 'wealth': 877,\n",
       " 'idea': 878,\n",
       " 'raise': 879,\n",
       " 'politics': 880,\n",
       " 'john': 881,\n",
       " 'potential': 882,\n",
       " 'deserve': 883,\n",
       " 'diplomacy': 884,\n",
       " 'liberties': 885,\n",
       " 'generations': 886,\n",
       " 'form': 887,\n",
       " 'ways': 888,\n",
       " 'voluntary': 889,\n",
       " 'taxpayers': 890,\n",
       " 'dangerous': 891,\n",
       " 'themselves': 892,\n",
       " 'actions': 893,\n",
       " 'marijuana': 894,\n",
       " '11': 895,\n",
       " 'era': 896,\n",
       " 'goals': 897,\n",
       " 'currently': 898,\n",
       " 'russia': 899,\n",
       " 'seems': 900,\n",
       " 'candidates': 901,\n",
       " 'few': 902,\n",
       " 'bitcoin': 903,\n",
       " 'center': 904,\n",
       " 'charitable': 905,\n",
       " 'morale': 906,\n",
       " 'gap': 907,\n",
       " 'reach': 908,\n",
       " 'matter': 909,\n",
       " 'code': 910,\n",
       " 'broken': 911,\n",
       " 'soldiers': 912,\n",
       " 'exercise': 913,\n",
       " 'attempts': 914,\n",
       " 'everyone': 915,\n",
       " 'prepare': 916,\n",
       " 'throughout': 917,\n",
       " 'learn': 918,\n",
       " 'grow': 919,\n",
       " 'safeguard': 920,\n",
       " 'activities': 921,\n",
       " 'personnel': 922,\n",
       " 'avoid': 923,\n",
       " 'source': 924,\n",
       " 'world’s': 925,\n",
       " 'population': 926,\n",
       " 'protected': 927,\n",
       " 'allowing': 928,\n",
       " 'air': 929,\n",
       " '2013': 930,\n",
       " 'north': 931,\n",
       " 'v': 932,\n",
       " 'pollution': 933,\n",
       " 'going': 934,\n",
       " 'growing': 935,\n",
       " 'woman': 936,\n",
       " 'patients': 937,\n",
       " 'isis': 938,\n",
       " 'guard': 939,\n",
       " '9': 940,\n",
       " 'tend': 941,\n",
       " 'poll': 942,\n",
       " 'george': 943,\n",
       " 'fronts': 944,\n",
       " 'savings': 945,\n",
       " 'iraqi': 946,\n",
       " 'lawyers': 947,\n",
       " 'taken': 948,\n",
       " 'employers': 949,\n",
       " 'undermine': 950,\n",
       " 'consumers': 951,\n",
       " 'forced': 952,\n",
       " 'contribute': 953,\n",
       " 'nearly': 954,\n",
       " 'offer': 955,\n",
       " 'using': 956,\n",
       " 'efficient': 957,\n",
       " 'cultural': 958,\n",
       " 'space': 959,\n",
       " 'director': 960,\n",
       " 'banking': 961,\n",
       " 'former': 962,\n",
       " 'competition': 963,\n",
       " 'police': 964,\n",
       " 'gender': 965,\n",
       " 'certain': 966,\n",
       " 'language': 967,\n",
       " 'consider': 968,\n",
       " 'couples': 969,\n",
       " 'facilities': 970,\n",
       " 'manage': 971,\n",
       " 'vital': 972,\n",
       " 'cap': 973,\n",
       " 'responsible': 974,\n",
       " 'add': 975,\n",
       " 'material': 976,\n",
       " 'abortions': 977,\n",
       " 'preventing': 978,\n",
       " 'strategic': 979,\n",
       " 'regime': 980,\n",
       " 'point': 981,\n",
       " 'banning': 982,\n",
       " 'proposal': 983,\n",
       " '2018': 984,\n",
       " 'definition': 985,\n",
       " 'plus': 986,\n",
       " 'results': 987,\n",
       " 'cells': 988,\n",
       " 'four': 989,\n",
       " 'solutions': 990,\n",
       " 'it’s': 991,\n",
       " 'candidate': 992,\n",
       " 'barriers': 993,\n",
       " 'dollars': 994,\n",
       " 'levels': 995,\n",
       " 'employees': 996,\n",
       " 'color': 997,\n",
       " 'paid': 998,\n",
       " 'transportation': 999,\n",
       " 'competitive': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is ordered by the number of occurences of the word. \n",
    "tokenizer.word_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now it's time to tokenize all of the training and testing data for future use. \n",
    "X_train_tokens = tokenizer.texts_to_sequences(X_train_text)\n",
    "\n",
    "X_test_tokens = tokenizer.texts_to_sequences(X_test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Padding and truncating\n",
    "\n",
    "Not all senetences are created equal (both in meaning and length!) To preserve the same size input property of a neural network, this means padding the shorter phrases, and truncating the longer ones. For padding these zeros (which will be interpreted as meaningless) will be placed at the start of the sentence as the sequential nature should play less of a role. Rather than an abrupt jump to zero which could have an adverse effect on the RNN, it is smarter to go from 0 up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_tokens = [len(tokens) for tokens in X_train_tokens + X_test_tokens]\n",
    "num_tokens = np.array(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.730740351404116"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(num_tokens)\n",
    "#avg num of tokens in a phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(num_tokens)\n",
    "#max num of tokens in a phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "max_tokens = int(max_tokens)\n",
    "max_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96200630725334135"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(num_tokens < max_tokens) / len(num_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So by setting it to mean + 2 stds, this covers about 93% of the dataset. Fine by me!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pad = 'pre' #pad in the beginning, reasoning explained earlier. \n",
    "\n",
    "X_train_pad = pad_sequences(X_train_tokens, maxlen=max_tokens,\n",
    "                            padding=pad, truncating=pad)\n",
    "\n",
    "X_test_pad = pad_sequences(X_test_tokens, maxlen=max_tokens,\n",
    "                           padding=pad, truncating=pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4461, 50)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2198, 50)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pad.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = tokenizer.word_index\n",
    "inverse_map = dict(zip(idx.values(), idx.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokens_to_string(tokens):\n",
    "    \"\"\"Helper function to go back to the text.\"\"\"\n",
    "    # Map from tokens back to words.\n",
    "    words = [inverse_map[token] for token in tokens if token != 0]\n",
    "    \n",
    "    # Concatenate all words.\n",
    "    text = \" \".join(words)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9597"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(Sep 2004)\\r\\n    Provide new strategies to help poor nations.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_text[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sep 2004 \\r provide new strategies to help poor nations'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_to_string(X_train_tokens[10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Creating a Recurrent Neural Network \n",
    "\n",
    "\n",
    "Now for the implementation of an RNN to classify this data, using the keras structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "embedding_size = 10  #dimensions of word2vec (basically.)\n",
    "\n",
    "#this is essentially a word2vec model but it is a part of the RNN, as it trains simultaneously. \n",
    "model.add(Embedding(input_dim=num_words,\n",
    "                    output_dim=embedding_size,\n",
    "                    input_length=max_tokens,  \n",
    "                    name='layer_embedding'))\n",
    "\n",
    "\n",
    "\n",
    "model.add(GRU(units=16, return_sequences=True))\n",
    "model.add(GRU(units=8, return_sequences=True))\n",
    "model.add(GRU(units=4))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "optimizer = Adam(lr=1e-3)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer_embedding (Embedding)  (None, 50, 10)            80000     \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 50, 16)            1296      \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 50, 8)             600       \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 4)                 156       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 82,057\n",
      "Trainable params: 82,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4237 samples, validate on 224 samples\n",
      "Epoch 1/15\n",
      "4237/4237 [==============================] - 8s 2ms/step - loss: 0.6767 - acc: 0.5754 - val_loss: 0.6481 - val_acc: 0.6473\n",
      "Epoch 2/15\n",
      "4237/4237 [==============================] - 6s 1ms/step - loss: 0.6643 - acc: 0.6141 - val_loss: 0.6447 - val_acc: 0.6473\n",
      "Epoch 3/15\n",
      "4237/4237 [==============================] - 6s 1ms/step - loss: 0.6518 - acc: 0.6169 - val_loss: 0.6238 - val_acc: 0.6652\n",
      "Epoch 4/15\n",
      "4237/4237 [==============================] - 6s 1ms/step - loss: 0.5443 - acc: 0.7274 - val_loss: 0.5331 - val_acc: 0.7545\n",
      "Epoch 5/15\n",
      "4237/4237 [==============================] - 6s 1ms/step - loss: 0.4342 - acc: 0.8058 - val_loss: 0.4795 - val_acc: 0.7991\n",
      "Epoch 6/15\n",
      "4237/4237 [==============================] - 6s 1ms/step - loss: 0.3375 - acc: 0.8671 - val_loss: 0.4660 - val_acc: 0.8036\n",
      "Epoch 7/15\n",
      "4237/4237 [==============================] - 6s 1ms/step - loss: 0.2636 - acc: 0.9063 - val_loss: 0.4953 - val_acc: 0.7902\n",
      "Epoch 8/15\n",
      "4237/4237 [==============================] - 6s 1ms/step - loss: 0.2102 - acc: 0.9308 - val_loss: 0.5114 - val_acc: 0.7991\n",
      "Epoch 9/15\n",
      "4237/4237 [==============================] - 6s 1ms/step - loss: 0.1607 - acc: 0.9547 - val_loss: 0.5529 - val_acc: 0.7991\n",
      "Epoch 10/15\n",
      "4237/4237 [==============================] - 6s 1ms/step - loss: 0.1341 - acc: 0.9634 - val_loss: 0.5552 - val_acc: 0.8125\n",
      "Epoch 11/15\n",
      "4237/4237 [==============================] - 6s 1ms/step - loss: 0.1037 - acc: 0.9762 - val_loss: 0.5738 - val_acc: 0.8080\n",
      "Epoch 12/15\n",
      "4237/4237 [==============================] - 6s 1ms/step - loss: 0.0884 - acc: 0.9804 - val_loss: 0.6403 - val_acc: 0.8080\n",
      "Epoch 13/15\n",
      "4237/4237 [==============================] - 6s 1ms/step - loss: 0.0841 - acc: 0.9790 - val_loss: 0.6330 - val_acc: 0.8080\n",
      "Epoch 14/15\n",
      "4237/4237 [==============================] - 6s 1ms/step - loss: 0.0691 - acc: 0.9842 - val_loss: 0.6464 - val_acc: 0.8080\n",
      "Epoch 15/15\n",
      "4237/4237 [==============================] - 6s 1ms/step - loss: 0.0571 - acc: 0.9882 - val_loss: 0.7096 - val_acc: 0.8036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x130a06b70>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_pad, y_train,\n",
    "          validation_split=0.05, epochs=15, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2198/2198 [==============================] - 1s 516us/step\n",
      "Accuracy: 83.48%\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(X_test_pad, y_test)\n",
    "print(\"Accuracy: {0:.2%}\".format(result[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of mis-classified text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#In order to show an example of mis-classified text, \n",
    "#we first calculate the predicted sentiment for the first 500 texts in the test-set.\n",
    "\n",
    "y_pred = model.predict(x=X_test_pad[0:500])\n",
    "y_pred = y_pred.T[0]\n",
    "\n",
    "\n",
    "#These predicted numbers fall between 0.0 and 1.0. \n",
    "#We use a cutoff / threshold and say that all values above 0.5 \n",
    "#are taken to be 1.0 and all values below 0.5 are taken to be 0.0. \n",
    "#This gives us a predicted \"class\" of either 0.0 or 1.0.\n",
    "\n",
    "\n",
    "cls_pred = np.array([1.0 if p>0.5 else 0.0 for p in y_pred])\n",
    "cls_true = np.array(y_test[0:500])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then get indices for all the texts that were incorrectly classified by comparing all the \"classes\" of these two arrays.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2580"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_dems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4079"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6125544376032437"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_reps) / (len(y_dems) + len(y_reps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect = np.where(cls_pred != cls_true)\n",
    "incorrect = incorrect[0]\n",
    "\n",
    "len(incorrect)  #how many out of 500 were wrong?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = incorrect[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'They also hope to prohibit gun sales to those receiving involuntary mental health services on an outpatient basis, if a court deems them dangerous.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = X_test_text[idx]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11404887"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "\n",
      "While House Democrats such as Nancy Pelosi demand a road to citizenship for illegal immigrants, Boehner’s proposed plan discusses no such accommodation.\n",
      "Incorrectly classified as  0.982943\n",
      "\n",
      "5\n",
      "\n",
      "These are public lands, and the public should have access to them for appropriate activities like hunting, fishing, and recreational shooting.\n",
      "Incorrectly classified as  0.928313\n",
      "\n",
      "6\n",
      "\n",
      "Consumer choice is the most powerful factor in healthcare reform.\n",
      "Incorrectly classified as  0.781549\n",
      "\n",
      "12\n",
      "\n",
      "Democrats believe in reforming asylum policies, believing that we should have “equitable asylum policies that treat people the same whether they have fled violence from the Right and Left.” They believe that immigrants are currently facing a lack of due process protections, and wish to see these protections restored, so that immigrants cannot face deportation due to minor offenses, “and are eligible to receive safety net services supported by their tax dollars.”\n",
      "Democratic Views On The Death Penalty\n",
      "Democratic views on the death penalty revolve around the opinion that it must only be used in certain cases.\n",
      "Incorrectly classified as  0.102309\n",
      "\n",
      "16\n",
      "\n",
      "Agricultural lands account for nearly half of the total land area in America and our agricultural practices have a significant impact on our water, land, oceans, and the climate.\n",
      "Incorrectly classified as  0.013445\n",
      "\n",
      "18\n",
      "\n",
      "Family reunification should continue to be the cornerstone of our legal immigration system.”\n",
      "Democrats vs Republicans on Immigration\n",
      "While Democrats believe in supporting a path to citizenship for illegal immigrants, Republicans support stronger border patrols and stronger repercussions for those caught in the U.S. illegally, as well as those who employ them or help them falsify documentation.\n",
      "Incorrectly classified as  0.0178956\n",
      "\n",
      "19\n",
      "\n",
      "The relocation was part of a long trend of improvement in American-Israeli relations spearheaded by the Trump administration (and largely resisted by Democrats).\n",
      "Incorrectly classified as  0.0222769\n",
      "\n",
      "22\n",
      "\n",
      "Overall, one key consideration for those who question or criticize the relocation is the possibility of its leading to unrest in the region.\n",
      "Incorrectly classified as  0.0134414\n",
      "\n",
      "26\n",
      "\n",
      "It also alienates people and countries who are crucial to defeating terrorism; the vast majority of Muslims believe in a future of peace and tolerance.\n",
      "Incorrectly classified as  0.0380913\n",
      "\n",
      "42\n",
      "\n",
      "Democrats will fight any attempts by Republicans in Congress to privatize, voucherize, or “phase out” Medicare as we know it.\n",
      "Incorrectly classified as  0.016391\n",
      "\n",
      "48\n",
      "\n",
      "We especially support the innovative financing mechanisms that make options available to all children: education savings accounts (ESAs), vouchers, and tuition tax credits.\n",
      "Incorrectly classified as  0.907175\n",
      "\n",
      "52\n",
      "\n",
      "We will support strong legislatures, independent judiciaries, free press, vibrant civil society, honest police forces, religious freedom, and equality for women and minorities.\n",
      "Incorrectly classified as  0.0133979\n",
      "\n",
      "54\n",
      "\n",
      "We support a progressive vision of religious freedom that respects pluralism and rejects the misuse of religion to discriminate.\n",
      "Incorrectly classified as  0.185594\n",
      "\n",
      "58\n",
      "\n",
      "It’s a vote to defund cancer screenings, and birth control, and basic healthcare for millions of women.\n",
      "Incorrectly classified as  0.0976767\n",
      "\n",
      "74\n",
      "\n",
      "We will extend the peace by supporting the rise of democracy, and the hope and progress that democracy brings, as the alternative to hatred and terror in the Middle East.\n",
      "Incorrectly classified as  0.967659\n",
      "\n",
      "87\n",
      "\n",
      "The logic is, essentially, that the goal of regulation is to guide the river, while overregulation is advocating for damming it up.\n",
      "Incorrectly classified as  0.0141617\n",
      "\n",
      "88\n",
      "\n",
      "The view from nearer to the present day, though, isn’t nearly as positive for many traditionally Liberal groups.\n",
      "Incorrectly classified as  0.0138306\n",
      "\n",
      "101\n",
      "\n",
      "Their goals include to incorporate mental-health criteria into the existing law regarding who can and cannot own guns.\n",
      "Incorrectly classified as  0.013462\n",
      "\n",
      "103\n",
      "\n",
      "They also seek the completion of negotiations for a Trans-Pacific Partnership, which would open new and rapidly growing Asian markets to the United States.\n",
      "Incorrectly classified as  0.974376\n",
      "\n",
      "107\n",
      "\n",
      "[31][32] Additionally, the party supports stricter fuel emissions standards to prevent air pollution.\n",
      "Incorrectly classified as  0.0145657\n",
      "\n",
      "112\n",
      "\n",
      "The Party of Regulation\n",
      "Let’s start with the bigger picture.\n",
      "Incorrectly classified as  0.041295\n",
      "\n",
      "122\n",
      "\n",
      "While many conservatives will decry such views as taking a weak position on crime, the rationales explained in this piece are meant to point to the factors that have led many to believe in such causes.\n",
      "Incorrectly classified as  0.0154951\n",
      "\n",
      "124\n",
      "\n",
      "Its gravest peril originates in the White House, the current occupant of which has launched a campaign, both at home and internationally, to subjugate it to agents of government.\n",
      "Incorrectly classified as  0.956441\n",
      "\n",
      "129\n",
      "\n",
      "While Dianne Feinstein leads a subset of Democratic senators who disagree with Trump’s decision, the pro-relocation views evident in the unanimous vote are most obviously espoused by New York’s Chuck Schumer.\n",
      "Incorrectly classified as  0.0156905\n",
      "\n",
      "132\n",
      "\n",
      "Republicans in Congress have chosen gridlock and dysfunction over trying to find solutions to the real challenges we face.\n",
      "Incorrectly classified as  0.0135503\n",
      "\n",
      "134\n",
      "\n",
      "The Democratic views on abortion strongly support Roe vs. Wade, and include a woman being given the right to abort a pregnancy regardless of whether or not she is able to pay for it.\n",
      "Incorrectly classified as  0.0139264\n",
      "\n",
      "140\n",
      "\n",
      "As a nation, we have drastically reduced pollution, mainstreamed recycling, educated the public, and avoided ecological degradation.\n",
      "Incorrectly classified as  0.975484\n",
      "\n",
      "142\n",
      "\n",
      "In Venezuela, we will push the government to respect human rights and respond to the will of its people.\n",
      "Incorrectly classified as  0.39767\n",
      "\n",
      "145\n",
      "\n",
      "We will continue to oppose—and seek to overturn—federal and state laws and policies that impede a woman’s access to abortion, including by repealing the Hyde Amendment.\n",
      "Incorrectly classified as  0.042235\n",
      "\n",
      "146\n",
      "\n",
      "While freedom of expression is a fundamental constitutional principle, we must condemn hate speech that creates a fertile climate for violence.\n",
      "Incorrectly classified as  0.045568\n",
      "\n",
      "147\n",
      "\n",
      "A major factor in the 40-year decline in the middle class is that the rights of workers to bargain collectively for better wages and benefits have been under attack at all levels.\n",
      "Incorrectly classified as  0.0475734\n",
      "\n",
      "153\n",
      "\n",
      "They allow Americans to work together to solve most of the problems facing their communities.\n",
      "Incorrectly classified as  0.983146\n",
      "\n",
      "155\n",
      "\n",
      "[33]\n",
      " The modern Democratic party emphasizes egalitarianism and social equality through liberalism.\n",
      "Incorrectly classified as  0.295746\n",
      "\n",
      "164\n",
      "\n",
      "To do this, we need to educate our people and train our workforce; support entrepreneurship and promote inclusion in the digital economy; attract and retain talented people from all over the world; and invest in research and development, innovation hubs, as well as in getting ideas to market.\n",
      "Incorrectly classified as  0.0134791\n",
      "\n",
      "171\n",
      "\n",
      "Americans want to know that there is a plan of action, and that it’s one they can stand behind.\n",
      "Incorrectly classified as  0.984288\n",
      "\n",
      "175\n",
      "\n",
      "Because of conflicting federal and state laws concerning marijuana, we encourage the federal government to remove marijuana from the list of “Schedule 1″ federal controlled substances and to appropriately regulate it, providing a reasoned pathway for future legalization.\n",
      "Incorrectly classified as  0.0133774\n",
      "\n",
      "179\n",
      "\n",
      "To do so, he has invested a great deal in information sharing, as well as in promoting information sharing among our allies.\n",
      "Incorrectly classified as  0.0133509\n",
      "\n",
      "181\n",
      "\n",
      "Back then they were called risk-takers, dreamers, and small business owners.\n",
      "Incorrectly classified as  0.969658\n",
      "\n",
      "198\n",
      "\n",
      "(Aug 2000)\r\n",
      " FactCheck: \"God\" removed from DNC platform.\n",
      "Incorrectly classified as  0.0155434\n",
      "\n",
      "208\n",
      "\n",
      "And we can have more economic fairness, so the rewards are shared broadly, not just with those at the top.\n",
      "Incorrectly classified as  0.0137594\n",
      "\n",
      "211\n",
      "\n",
      "To echo Scalia, we dissent.\n",
      "Incorrectly classified as  0.80982\n",
      "\n",
      "223\n",
      "\n",
      "Democrats believe that no one should be able avoid paying their fair share by hiding money abroad, and that corrupt leaders and terrorists should not be able to use the system of international finance to their advantage.\n",
      "Incorrectly classified as  0.0625453\n",
      "\n",
      "241\n",
      "\n",
      "Who Is Responsible for the Violence?\n",
      "Incorrectly classified as  0.108236\n",
      "\n",
      "244\n",
      "\n",
      "All this highlights the continuing conflicts and contradictions in public attitudes and public policy toward illegal substances.\n",
      "Incorrectly classified as  0.981615\n",
      "\n",
      "245\n",
      "\n",
      "He should be impeached by the House of Representatives and convicted by the Senate.\n",
      "Incorrectly classified as  0.973091\n",
      "\n",
      "253\n",
      "\n",
      "The result is 45.8 million people on food stamps and 77 million on Medicaid, plus another 5.7 million in the Children’s Health Insurance Program.\n",
      "Incorrectly classified as  0.955456\n",
      "\n",
      "259\n",
      "\n",
      "We will build on the historic opening with Burma and advocate for greater human rights protections and national reconciliation among Burma’s many different ethnic groups.\n",
      "Incorrectly classified as  0.016702\n",
      "\n",
      "262\n",
      "\n",
      "“Today also demonstrates American leadership.\n",
      "Incorrectly classified as  0.946506\n",
      "\n",
      "272\n",
      "\n",
      "[67]\n",
      " The 2012 Democratic Party platform endorses maintaining commitment to Israel's security, claiming a strong and secure Israel is vital because of strategic interests and common values, the Obama administration providing nearly $10 billion to Israel in the past three years, military support for Israel, such as the Iron Dome system, the Egypt–Israel Peace Treaty, the Israel–Jordan peace treaty, and recognizing Jerusalem as and remains the capital of Israel, and opposes any attempt to delegitimize Israel on the world stage.\n",
      "Incorrectly classified as  0.0340676\n",
      "\n",
      "278\n",
      "\n",
      "Republicans believe that the sooner we act the better, as this will not only give those closer to retirement reassurance that they will see their benefits, but will also give younger workers more time to plan their own retirement within the new system.\n",
      "Incorrectly classified as  0.968317\n",
      "\n",
      "286\n",
      "\n",
      "We also believe that Native children are the future of tribal nations and that the Indian Child Welfare Act is critical to the survival of Indian culture, government, and communities and must be enforced with the statutory intent of the law.\n",
      "Incorrectly classified as  0.0136464\n",
      "\n",
      "294\n",
      "\n",
      "We support binding arbitration to help workers who have voted to join a union reach a first contract.\n",
      "Incorrectly classified as  0.0154265\n",
      "\n",
      "298\n",
      "\n",
      "We have been inspired by the movements for criminal justice that directly address the discriminatory treatment of African Americans, Latinos, Asian Americans and Pacific Islanders, and American Indians to rebuild trust in the criminal justice system.\n",
      "Incorrectly classified as  0.0295829\n",
      "\n",
      "302\n",
      "\n",
      "We also recognize and honor the contributions and the sacrifices made in service of our country by the Americans living in the territories of Guam, American Samoa, the U.S. Virgin Islands, and the Commonwealth of the Northern Mariana Islands.\n",
      "Incorrectly classified as  0.0133275\n",
      "\n",
      "313\n",
      "\n",
      "Jerusalem has long been disputed by the Palestinian side, and the movement of the embassy sends a clear signal that the United States supports Israel’s claim to the city.\n",
      "Incorrectly classified as  0.01393\n",
      "\n",
      "314\n",
      "\n",
      "(Aug 2000)\r\n",
      " No frivolous gun lawsuits, no gun licensing.\n",
      "Incorrectly classified as  0.975748\n",
      "\n",
      "328\n",
      "\n",
      "(Aug 2000)\r\n",
      " Invest in stem cell and other medical research.\n",
      "Incorrectly classified as  0.0344104\n",
      "\n",
      "330\n",
      "\n",
      "While Republicans also believe that gay marriage should be left to the states to decide, Republicans as a whole would prefer to see states ban gay marriage, where Democrats hope to see the opposite.\n",
      "Incorrectly classified as  0.103744\n",
      "\n",
      "331\n",
      "\n",
      "That is why we will support efforts to limit the use of forced arbitration clauses in employment and service contracts, which unfairly strip consumers, workers, students, retirees, and investors of their right to their day in court.\n",
      "Incorrectly classified as  0.013471\n",
      "\n",
      "338\n",
      "\n",
      "They believe that a health care system that is run by the government will reduce both the efficiency and the standard of care, as well as compromise the patient-physician relationship, and increase waiting periods within the health care system, as evidenced by government-centered health care systems throughout the world.\n",
      "Incorrectly classified as  0.981798\n",
      "\n",
      "342\n",
      "\n",
      "It has provided decades of stability and economic growth for the world and for America.\n",
      "Incorrectly classified as  0.0152123\n",
      "\n",
      "362\n",
      "\n",
      "Democratic views on energy revolve around the concept of preserving our energy sources and our environment for future generations.\n",
      "Incorrectly classified as  0.444874\n",
      "\n",
      "375\n",
      "\n",
      "Further, Congress should work towards legislation that requires removal of a regulation of equal or greater economic burden when a new regulation is enacted.\n",
      "Incorrectly classified as  0.979561\n",
      "\n",
      "412\n",
      "\n",
      "During President Obama’s time in office, he and his party have taken several actions in regards to homeland security.\n",
      "Incorrectly classified as  0.01723\n",
      "\n",
      "419\n",
      "\n",
      "Democrats have a comprehensive agenda to invest in America’s cities, grounded on the premise that local leaders are best equipped to create a better future for their residents—but need the resources and flexibility to get the job done.\n",
      "Incorrectly classified as  0.0133768\n",
      "\n",
      "423\n",
      "\n",
      "In the past, Clinton has often argued for, rather than against, increases in military spending.\n",
      "Incorrectly classified as  0.0133754\n",
      "\n",
      "426\n",
      "\n",
      "Not only can we afford to maintain a strong civilian presence, we cannot afford not to… As we help these nations meet their own challenges and grow their own economies, their men and women will buy their first cars, their first computers, and everything from movies to medical equipment.\n",
      "Incorrectly classified as  0.027192\n",
      "\n",
      "430\n",
      "\n",
      "He explicitly states that there will be no path at all to citizenship for individuals who broke the immigration laws.\n",
      "Incorrectly classified as  0.980755\n",
      "\n",
      "431\n",
      "\n",
      "(Aug 2000)\r\n",
      " Choice is a fundamental, constitutional right.\n",
      "Incorrectly classified as  0.113123\n",
      "\n",
      "432\n",
      "\n",
      "On October 15, 2007, Gore won the Nobel Peace Prize for his efforts to build greater knowledge about man-made climate change and laying the foundations for the measures needed to counteract these changes asserting that \"the climate crisis is not a political issue, it is a moral and spiritual challenge to all of humanity.\n",
      "Incorrectly classified as  0.0135224\n",
      "\n",
      "439\n",
      "\n",
      "Fifteen of the 16 hottest years on record have occurred this century.\n",
      "Incorrectly classified as  0.0138142\n",
      "\n",
      "452\n",
      "\n",
      "And we support reviewing the feasibility of extending the ACA to all the territories and increasing the Medicaid cap.\n",
      "Incorrectly classified as  0.0180863\n",
      "\n",
      "480\n",
      "\n",
      "For too many of us, health care costs are still too high, even for those with insurance.\n",
      "Incorrectly classified as  0.0149811\n",
      "\n",
      "486\n",
      "\n",
      "The Army is at its lowest troop levels since before World War II.\n",
      "Incorrectly classified as  0.976056\n",
      "\n",
      "490\n",
      "\n",
      "Surprisingly, despite all the negative media the electoral college has gotten over the past couple of years, public support for it has gone up in recent years.\n",
      "Incorrectly classified as  0.95605\n",
      "\n",
      "496\n",
      "\n",
      "They also hope to prohibit gun sales to those receiving involuntary mental health services on an outpatient basis, if a court deems them dangerous.\n",
      "Incorrectly classified as  0.114049\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for val in incorrect:\n",
    "    print(val)\n",
    "    idx = val\n",
    "    text = X_test_text[idx]\n",
    "    print()\n",
    "    print(text)\n",
    "    print(\"Incorrectly classified as \",y_pred[idx])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Data\n",
    "\n",
    "Now let's try and classify new statements. Some will be obvious, while others should be consfusing.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text1 = \"Climate change is the most important issue to address.\"\n",
    "text2 = \"We need a safer form of gun control.\"\n",
    "text3 = \"Obamacare is bad\"\n",
    "text4 = \"Our welfare system is broken\"\n",
    "text5 = \"The wealthy need to pay their fair share in taxes.\"\n",
    "text6 = \"Roe v Wade must be overturned.\"\n",
    "text7 = \"Make America Great Again\"\n",
    "text8 =  \"Israel is our greatest ally.\"  #inherently ambiguous (I hope!)\n",
    "text9 = \"I love russia.\"\n",
    "texts = [text1, text2, text3, text4, text5, text6, text7, text8,text9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens = tokenizer.texts_to_sequences(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 50)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tokens_pad = pad_sequences(tokens, maxlen=max_tokens,\n",
    "                           padding=pad, truncating=pad)\n",
    "tokens_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.96718007],\n",
       "       [ 0.39847985],\n",
       "       [ 0.02395949],\n",
       "       [ 0.01504334],\n",
       "       [ 0.10007751],\n",
       "       [ 0.01378797],\n",
       "       [ 0.89935702],\n",
       "       [ 0.05324052],\n",
       "       [ 0.97865218]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(tokens_pad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now recreating that prediction method with a raw input for a more direct approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Democrat\n"
     ]
    }
   ],
   "source": [
    "text = [input()]\n",
    "tokens = tokenizer.texts_to_sequences(text)\n",
    "tokens_pad = pad_sequences(tokens, maxlen=max_tokens,\n",
    "                           padding=pad, truncating=pad)\n",
    "\n",
    "x = model.predict(tokens_pad)\n",
    "if x[0][0] < .5:\n",
    "    print(\"Republican\")\n",
    "else:\n",
    "    print(\"Democrat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Democrat\n"
     ]
    }
   ],
   "source": [
    "if x[0][0] < .5:\n",
    "    print(\"Republican\")\n",
    "else:\n",
    "    print(\"Democrat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qualitatively speaking, this model gueses 6 out of 7, not bad! The democratic ones that serve as the first two are the one's misclassified, and maybe this says something about their policy..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Exploration\n",
    "\n",
    "\n",
    "One perk of the embedding layer is that during the training period, it semantically maps the meaning of different words based on their classification, relative place in the sequence, etc. Certain terms will end up being more meaningful ot the message, while others are not (like stop words, 'and', the',etc.)\n",
    "\n",
    "\n",
    "By retreiving the embedding layer, we can explore these embeddings and have a little peek under the hood as to what this model has learned about politics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the layer from the model\n",
    "layer_embedding = model.get_layer('layer_embedding')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 10)\n"
     ]
    }
   ],
   "source": [
    "#get the weights from that layer. \n",
    "weights_embedding = layer_embedding.get_weights()[0]\n",
    "print(weights_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, vec, in enumerate(weights_embedding):\n",
    "    #convert to word\n",
    "    tokenizer.word_index\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously we said that the vec would have 8 dimensions, so this is consistent with those findings here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ex what is the \n",
    "token_good = tokenizer.word_index['good']\n",
    "token_good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "423"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_great = tokenizer.word_index['great']\n",
    "token_great"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.82499659,  0.70365268,  0.87161672,  0.42685714,  0.06458494,\n",
       "        0.61854428,  0.22443061,  0.57985944,  0.1151525 ,  0.68127704], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_embedding[token_good]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5167501 ,  0.44600865,  0.53695512,  0.25615156,  0.2797631 ,\n",
       "        0.29351661,  0.23447201,  0.71865511,  0.74952543,  0.16358115], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_embedding[token_great]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since these words are similar, we'd expect their embeddings to be close (speaking from displacement meaning) We see that in some of these dimensions, that is the case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting\n",
    "\n",
    "Using this helper function, find the distances between every word and sort.\n",
    "\n",
    "\n",
    "\n",
    "# There is an issue with this function where the index goes beyond what I have originally set. Seems this won't work (yet). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_sorted_words(word, metric='cosine'):\n",
    "    \"\"\"\n",
    "    Print the words in the vocabulary sorted according to their\n",
    "    embedding-distance to the given word.\n",
    "    Different metrics can be used, e.g. 'cosine' or 'euclidean'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the token (i.e. integer ID) for the given word.\n",
    "    token = tokenizer.word_index[word]\n",
    "\n",
    "    # Get the embedding for the given word. Note that the\n",
    "    # embedding-weight-matrix is indexed by the word-tokens\n",
    "    # which are integer IDs.\n",
    "    embedding = weights_embedding[token]\n",
    "\n",
    "    # Calculate the distance between the embeddings for\n",
    "    # this word and all other words in the vocabulary.\n",
    "    distances = cdist(weights_embedding, [embedding],\n",
    "                      metric=metric).T[0]\n",
    "    \n",
    "    # Get an index sorted according to the embedding-distances.\n",
    "    # These are the tokens (integer IDs) for words in the vocabulary.\n",
    "    sorted_index = np.argsort(distances)\n",
    "    \n",
    "    # Sort the embedding-distances.\n",
    "    sorted_distances = distances[sorted_index]\n",
    "    \n",
    "    # Sort all the words in the vocabulary according to their\n",
    "    # embedding-distance. This is a bit excessive because we\n",
    "    # will only print the top and bottom words.\n",
    "    sorted_words = [inverse_map[token] for token in sorted_index\n",
    "                  if token != 0]\n",
    "    # Helper-function for printing words and embedding-distances.\n",
    "    def _print_words(words, distances):\n",
    "        for word, distance in zip(words, distances):\n",
    "            print(\"{0:.3f} - {1}\".format(distance, word))\n",
    "\n",
    "    # Number of words to print from the top and bottom of the list.\n",
    "    k = 10\n",
    "\n",
    "    print(\"Distance from '{0}':\".format(word))\n",
    "\n",
    "    # Print the words with smallest embedding-distance.\n",
    "    _print_words(sorted_words[1:k+1], sorted_distances[1:k+1])\n",
    "\n",
    "    print(\"...\")\n",
    "\n",
    "    # Print the words with highest embedding-distance.\n",
    "    _print_words(sorted_words[-k:], sorted_distances[-k:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance from 'obamacare':\n",
      "0.011 - institutions\n",
      "0.015 - commander\n",
      "0.016 - commissions\n",
      "0.018 - miners\n",
      "0.018 - statehood\n",
      "0.020 - burden\n",
      "0.020 - fcc’s\n",
      "0.021 - commend\n",
      "0.021 - months\n",
      "0.022 - “building\n",
      "...\n",
      "0.465 - august\n",
      "0.466 - narco\n",
      "0.468 - suspected\n",
      "0.473 - couples\n",
      "0.482 - stronger\n",
      "0.483 - credits\n",
      "0.483 - threatened\n",
      "0.519 - unrivaled\n",
      "0.588 - democrats\n",
      "0.845 - jul\n"
     ]
    }
   ],
   "source": [
    "print_sorted_words('obamacare', metric='cosine')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# New Idea: I've downloaded Josh Gottheimer's stances on the issues, now tokenize and model this to predict each statement, looking at the strongest ones on each as proof."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 'gottissues.txt'...\n"
     ]
    }
   ],
   "source": [
    "#open the text file and \n",
    "gottheimer_raw = u\"\"\n",
    "print(\"Reading '{0}'...\".format('gottissues.txt'))\n",
    "with codecs.open('gottissues.txt', \"r\", \"utf-8\") as book_file:\n",
    "    gottheimer_raw += book_file.read()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WORKING FOR YOU!\\nIn Congress, I’m laser-focused on getting things done for our families and for our children. When I got there, I quickly noticed that the extreme partisanship and gridlock were even worse than any of us could have imagined. However, I also found that from day one, if you actually made an effort to reach across the aisle, to find common ground, you could actually get things done that are good for the country and for New Jersey.\\n\\nEarly last year, I was elected Co-Chair of the bipartisan Problem Solvers Caucus. It’s a group of 24 Democrats and 24 Republicans who meet every week to see where we can make progress on our toughest issues, from lowering taxes, to creating jobs, to fixing our infrastructure, to balancing the budget. Just like when I was at Ford Motor Company and Microsoft, my goal is to bring people together to get something done. I was honored to be recognized as the most bipartisan freshman Democrat in Congress. For me, it’s not about a partisan agenda; it’s about working with both sides for what’s best for New Jersey. It’s about our shared values – our Jersey Values.\\n\\nWhat does that mean? We need lower taxes, less red tape, balanced budgets, and we must reinstitute the State and Local Tax Deduction (SALT) that was gutted by the federal Tax Hike Bill. We must claw more of our federal tax dollars back home, instead of continuing to prop up those Moocher States who take so much more than they give. We must also fight for clean drinking water, top-notch schools and STEM education for our children, and investment in our roads, bridges, and tunnels – so we can cut down on our commutes and attract new and keep our businesses.I will always stand by our seniors, veterans, and first responders, so our families are safe from crime and terror at home and around the world.\\n\\nThe bottom line: I work for Jersey, not some national political party. We are always stronger when we work together and remember that our best days are ahead of us.\\n\\nCutting Taxes and Clawing Back our Federal Tax Dollars\\nBefore I took office, our District had one of the worst returns on the tax dollars we sent to Washington – just $0.33 for every dollar. Our hard-earned money has instead been going to prop up Moocher States like Mississippi and Alabama that get back as much as $4.38 per dollar. That’s a raw deal and it means that making up the gap falls upon the shoulders of our towns and taxpayers.\\n\\nSo, when Congress passed a Tax Hike Bill that slammed our state and raised taxes on a majority of our residents and businesses, I fought back for Jersey. I’m also not going to stand idly by when so much damage is being done to our state. This massive tax hike on New Jersey is already driving property values down and sending businesses and jobs to other states.\\n\\nLast December, I introduced a Jersey Tax Cut Plan to restore the value of the State and Local Tax Deduction (SALT). Our plan gives New Jersey taxpayers a tax cut by allowing them to donate to new charitable funds set up by their towns. In just four months, Democrats and Republicans came together to pass our plan and it was signed into law. I’m now working to make sure this plan – which is supported by our nation’s tax scholars and consistent with legal precedent and IRS rulings – can be quickly implemented in our towns to provide much needed tax relief.\\n\\nOur Jersey Tax Cut Plan is just one way I’m fighting back against the Moocher States and working to cut taxes for our families and our businesses. We must eliminate wasteful spending, balance budgets, and cut taxes, at every level – and I’ve made that my top priority. When I took office, I also quickly got to work with our mayors and local officials to claw back more of the tax dollars that we have already sent to Washington. Working together, we’re getting results – winning back 16% more than in recent years. That’s $290 per family to help our towns lower their property taxes, fix our infrastructure, protect our students in their schools, respond quickly to storms, and provide essential equipment our first responders need to fight crime and terror.\\n\\nThere’s nothing partisan about getting our families a better return on their investment. Whether it’s cutting taxes or clawing back our hard-earned money, I will keep fighting to make our District more affordable for our families and more attractive for businesses to invest and create jobs.\\n\\nBringing New Businesses and Jobs to the District\\nHere in North Jersey, we have some of the best schools and brightest minds who call our communities home. Many of the top life science companies are based in our state and we have some of the fastest broadband in the country – which is why the whole back-end of the New York Stock Exchange sits in Bergen County. The question is: How can we maximize these assets to create good-paying job and strengthen our economy?\\n\\nThat’s why, as part of my Five-Point Economic Growth Plan, I’m working across the aisle to help create jobs, draw, keep and expand businesses in northern New Jersey, lower taxes, cut red tape, and eliminate outdated, burdensome regulations. I’ve also fought to secure bipartisan funding for the Gateway Program and other essential investments to fix our transit, roads, bridges, and infrastructure to boost economic growth. Ultimately, harnessing our potential is about creating the conditions where innovative businesses can thrive and stay here to create good-paying jobs for our residents.\\n\\nFor my pro-business work across the aisle to help New Jersey, I was honored to receive the U.S. Chamber of Commerce’s “Spirit of Enterprise” Award. I have partnered with chapters across our District and the New Jersey Chamber of Commerce President Tom Bracken noted that I am, “fighting for us every day.” I will continue to work to lower taxes and help businesses of all sizes stay and grow in New Jersey by making the state we love more affordable.\\n\\nFixing Our Roads, Bridges, Tunnels and Trains\\nNew Jersey is second in the nation among states with commuters who rely on public transit. Meanwhile, one-third of New Jersey’s bridges are considered unsafe for travel and NJ Transit had more accidents in 2016 than any of the 10 largest commuter railroads in the country.\\n\\nWith the safety of our families at stake, there’s no room for partisan games. My first stand-alone bill to pass the House, the FRA Safety Data Improvement Act, strengthens our data collection so that we can uncover potential safety problems on our rails before they can do harm or cost lives.\\n\\nSafety has to be our top priority, but we also know that we can’t attract new businesses and jobs to a state where our roads, tunnels and bridges are crumbling. That’s why I’ve fought to secure bipartisan funding for the Gateway Project, which would double our rail capacity into New York City. Right now, only twenty-one trains can travel in and out of the city in an hour because we have one tunnel – that’s more than a hundred years old and in massive disrepair – along this corridor that one-fifth of America’s economy relies upon. Moving this project forward couldn’t be more vital to our region and our nation’s economy.\\n\\nI’ve also worked to bring new bus and rail service to our communities in Sussex and Warren and we need to bring light rail to Bergen County to ease our commute within our District. Fixing our infrastructure isn’t just essential to our economic future. Most importantly, it allows us to get home earlier to spend more time with our families and tuck our kids into bed.\\n\\nStanding Strong Against Terror, Standing by Our Veterans and First Responders\\nIn New Jersey, we know all too well about the threat of homegrown, Lone-Wolf terror, and that we must always be vigilant at home and in the war on terror – against ISIS, Al-Qaeda, Hamas, and other terrorist groups around the world. We need to make certain our cops, first responders, and military have the tools they need to protect our families and to prevent terrorists from following through on their threats, both foreign and domestic. There is no room for compromise against terror and Americans must present in a united front, coming together as Democrats and Republicans, for our national security. We owe that to all Americans and to the brave men and women, who have risked their lives to protect our freedoms.\\n\\nIn the aftermath of the tragic terror attack in New York City last October, where a rented pickup truck was used to kill eight people, including Darren Drake, a resident of New Milford, New Jersey, I was proud to work with Darren’s father Jimmy to develop a plan to prevent future ISIS-inspired Lone-Wolf attacks. Named in memory of Darren, TheDarren Drake Combatting 21st Century Weapons of Terror Act is essential to help keep us safe against these new, emerging threats.\\n\\nLast year, I also introduced the bipartisan Freezing Assets of Suspected Terrorists and Enemy Recruits (FASTER) Act to give law enforcement the tools that they need to combat domestic terrorism, especially Lone-Wolf attacks in our backyard. We must make sure that our law enforcement agencies have the training, information, and cutting-edge resources necessary to protect our communities.\\n\\nI will always have the backs of the brave cops that keep our families safe across North Jersey. For my work in Congress and at home to support law enforcement, I was received a perfect rating on a recent scorecard from the National Association of Police Organizations (NAPO), which includes police from across our state and the New Jersey State PBA.\\n\\nI’m also working to honor our commitment to our military, veterans, and first responders who put their lives on the line every day by ensuring that they have the best possible care, when they serve and after. I am committed to helping New Jersey veterans cut through the red tape and bureaucratic hurdles whether it relates to their benefits, health care, a VA home loan, or overdue medals. I’m proud that the very first measure of mine to become law was to help our veterans get jobs when they return home and makes it easier for these courageous men and women to get care in the District.\\n\\nCivil Rights and Equality\\nAs I learned growing up, we were all created in the image of God. I believe that everyone should be treated equally no matter what their background, race, sexual orientation, or station in life. We will only succeed as a nation if everyone is included and treated with respect and dignity. It’s what built America and allowed our economy and culture to flourish.\\n\\nAs a member of the Congressional LGBTQ Equality Caucus, I’ve fought to extend protections for the LGBTQ community. Last year, I proudly introduced the Freedom from Discrimination in Credit Act (FDCA), a bipartisan bill to prohibit credit discrimination based on sexual orientation and gender identity.\\n\\nI’m also fighting to defend the hard-won victories enshrined in the Voting Rights Act and working towards prison reform for nonviolent offenders, an area with great bipartisan support that will save taxpayers money.\\n\\nProtecting Medicare & Social Security\\nOur seniors shouldn’t have to worry that their Social Security checks, which they worked hard for, will always clear and that Medicare will be available to them. I’m fighting to protect and strengthen these essential programs for future generations and will always oppose any attempt to privatize them or cut benefits. In Congress, I’ve strongly opposed attempts to reduce the cost-of-living adjustment and access to Social Security, and voted against a budget plan that would have ended Medicare as we know it.\\n\\nWe also have to do more for our greatest generation and for our residents who are approaching retirement age. With my Three-Part Senior Security Strategy, my goal is to make it more affordable for seniors to stay in Jersey and enjoy their retirement here with their families. First, I’m working to cut taxes and help seniors save more of their hard-earned money during their golden years by co-sponsoring a bipartisan bill to finally put an end to the double taxation of Social Security benefits. The second part of our plan is working to pass a bipartisan bill to prevent this income from being garnished by debt collectors. Third, I’m fighting to protect seniors’ pocketbooks against the onslaught of aggressive Medicare scammers. Social Security and Medicare are the foundation of our retirement security; they should be a guarantee – not a gamble or put at risk in any way.\\n\\nLast but not least, I introduced the bipartisan Senior Housing Improvement and Retirement Accounts (IRA) Act, to give seniors the opportunity to save money so they can stay right here in New Jersey. My legislation cuts taxes for seniors if they sell their home and use a Roth IRA for retirement savings. New Jersey seniors are moving away because they cannot afford to stay, which is why I introduced this common-sense plan to help them save and stay in the Garden State.\\n\\nSafeguarding our Children’s Drinking Water\\nLike all parents, I’m deeply concerned about the health and safety of our children. Yet, despite the quality of the education offered in our schools, we haven’t been so sure about the quality of the water that flows out of our school’s water fountains, faucets or pipes, many of them generations old. We’ve all see the headlines about elevated lead levels in the water at our schools – and no mother or father should have to worry about whether the water their child drinks contains lead or other toxic chemicals.\\n\\nThat’s why I announced a Clean Water for Kids Plan, urging the state to improve reporting about the testing being done at our kids’ schools and to make it accessible to the public so that parents know exactly what’s in the water their kids might drink. We can’t solve this problem if we don’t know exactly what it is. I’ve also called for the Governor to strengthen efforts to keep our water lead-free in a comprehensive plan to get to the bottom of this problem and protect our children’s health and safety.\\n\\nIf we’re going to get lead out of our school drinking water once and for all, our schools will need better resources for testing, remediation and reporting. Last year, I introduced The Lead-Free Schools Act – a bipartisan bill that requires testing for lead in our schools, empowers parents by improving transparency and creates a pilot program to help schools replace out-of-date infrastructure like lead-tainted water fountains. This bill will also claw back some of the federal tax dollars we are already sending to Washington to help secure the health and safety of our children. Under my bipartisan plan, parents have the transparency they want, schools can invest in lead-free water, and our kids will be safe.\\n\\nBuilding Strong Families\\nWe live in a time where three women currently sit on the Supreme Court, women occupy twenty percent of all congressional seats, and scores sit in America’s boardrooms. The sky should be the limit for all of our sons and our daughters.\\n\\nAs I said in my very first speech on the floor of Congress, I unequivocally fight any attempt to get between a woman and her doctor when it comes to making personal health care choices. I also believe women should have access to affordable health care services around the country.\\n\\nWe need to expand opportunities for women in business. Last year, I proudly cosponsored the Paycheck Fairness Act to ensure that women receive equal pay for equal work.\\n\\nWe must also support families by providing new parents with sensible family leave and quality, affordable childcare. We should also invest in stem cell research and ensure that the National Institutes of Health continue to fund ground-breaking research in cancer, autism, and other diseases.\\n\\nInvest in Education, STEM, College Affordability\\nOur District has the best K-12 schools in the country but we can’t afford to take our eye off the ball. We must aggressively push forward and ensure that our children are given every opportunity to succeed in the global, digital economy. At Microsoft, I saw first-hand how few engineers and computer programmers our country produces; we simply aren’t graduating enough of them. And, given our immigration policies, many of the engineers who graduate from our colleges can’t stay here. The result is a huge skills gap – one I’m fighting hard to close.\\n\\nI support integrating education technology in the classroom and programs that greatly emphasize Science, Technology, Engineering, Arts and Math (STEAM), skills that are increasingly necessary for children who will enter the workforce in the coming decades. I am also exploring ways to help our local business community partner with our schools so that students get the training they need to build successful careers.\\n\\nProviding our children with a STEAM education will make our District an attractive location for companies from the technology industry and position our children to compete for the high paying jobs of the future. Meanwhile, what we do now to help our technology industry grow is of critical importance when it comes to Northern New Jersey’s economic future. In fact, studies have shown that over time each high-tech job creates about five jobs outside of tech (two professional and three nonprofessional). In Congress, I supported the Strengthening Career and Technical Education for the 21st Century Act, to boost the efficiency of the training programs that we already have on the books so they actually achieve their job training goals. I am working to claw back those resources to help in our District and state.\\n\\nBeyond job training, we also must take steps to make college more affordable. The costs of college tuition have skyrocketed 80 percent in the last decade. Seven in ten college graduates have an average debt of more than $35,000, and only 59 percent of students seeking a bachelor’s degree actually finish. We need to incentivize college completion, for both students and colleges, better match college training with employer needs, and address the runaway costs.\\n\\nIsrael\\nI unequivocally support the strength, safety, and prosperity of Israel. I am working with Democrats and Republicans to strengthen the U.S.-Israel partnership as our strongest ally. Knowing of the challenges we both face, I want to enhance this alliance by working tirelessly towards greater economic, diplomatic, cultural, and defense exchanges between Israel and the United States.\\n\\nIsrael’s commitment to freedom of expression and religion, and democratic values is unprecedented across the globe, across history, and especially across the Middle East. This is precisely why Israel is, and must remain, our closest ally. It is also why I believe so strongly that Israel cannot be used as partisan football and instead must maintain strong, bipartisan support. In Congress, I am working for a stronger partnership to stop dangerous terrorist financing, invest in robust missile defense, and increase technology exchanges between Israel and the United States. I believe we must do everything in our power to support the strength, safety, and prosperity of Israel – including fight back against biased attacks and those who wish to harm our vital partner. That’s why, last year, I introduced a bipartisan bill to help state and local governments fight back against the politically-motivated boycott of Israel. That’s also why, since 2015, I’ve strongly opposed the Iran Deal that failed to permanently prevent Tehran from developing a nuclear bomb or addressed the aggressive development of long-range ballistic missiles to carry these weapons.\\n\\nThere should be nothing partisan about protecting our national security and defending our vital ally, Israel.\\n'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gottheimer_raw  #now convert !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gottheimer_text = gottheimer_raw.split('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From what I can tell, this data needs to already be in the corpus prior to testing. This means re-running the model every time you grab one of these text files. I need a robust scraper that immediately gets all the text including this one, but keeping them in separate directories until testing later. This is especially because this prediction data is not labelled. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the blank spaces correspond to words not in original corpus... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gottheimer_tokens = tokenizer.texts_to_sequences(gottheimer_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gottheimer_tokens_pad = pad_sequences(gottheimer_tokens, maxlen=max_tokens,\n",
    "                            padding=pad, truncating=pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = model.predict(gottheimer_tokens_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = 0\n",
    "for result in results:\n",
    "    if result > .5:\n",
    "        x+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x/ len(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "105 of the len(results)= 135 statements are democratic, meaning this is a democratic candidate (probably )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now to repeat this testing this with a republican candidate, for reproducibility, I'll stick with Gott's competitor, John Mcann\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 'mcissues.txt'...\n"
     ]
    }
   ],
   "source": [
    "#open the text file and \n",
    "mcann_raw = u\"\"\n",
    "print(\"Reading '{0}'...\".format('mcissues.txt'))\n",
    "with codecs.open('mcissues.txt', \"r\", \"utf-8\") as book_file:\n",
    "    mcann_raw += book_file.read()\n",
    "\n",
    "\n",
    "mcann_text = mcann_raw.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mcann_tokens = tokenizer.texts_to_sequences(mcann_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mcann_tokens_pad = pad_sequences(mcann_tokens, maxlen=max_tokens,\n",
    "                            padding=pad, truncating=pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = model.predict(mcann_tokens_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = 0\n",
    "for result in results:\n",
    "    if result > .5:\n",
    "        x+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48598130841121495\n"
     ]
    }
   ],
   "source": [
    "print(x/len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Too many Americans are unemployed, underemployed or working undesirable jobs',\n",
       " '\\n\\nThat’s why I’m running for Congress',\n",
       " '\\n\\nTaxes\\n\\nI will work to make the tax code more favorable to small businesses which are the backbone of the nation’s economy',\n",
       " ' It’s time that Congress put Main Street before Wall Street',\n",
       " '\\n\\nSince historic tax cuts passed, New Jersey residents are concerned about the elimination of the SALT (state and local tax) deduction',\n",
       " ' Elect me to Congress and I will work to fix this pertinent concern',\n",
       " '\\n\\nTrade\\n\\nWe’ve all heard the arguments for free and fair trade',\n",
       " ' Like the President, I am for America First trade',\n",
       " ' We need to reevaluate trade deals to see what benefits America first',\n",
       " '\\n\\nWe’ve been taken advantage of too often on the world stage—while your jobs have been shipped off to other countries',\n",
       " '\\n\\nAs your Congressman I will never vote for a bill that guts American jobs and creates a negative trade balance',\n",
       " ' All trade deals need to protect jobs, grow the economy, and forge good diplomatic relations around the world',\n",
       " '\\n\\nAs Americans, we are proud of our rich immigrant history and understand the need to reform immigration law',\n",
       " ' But New Jersey Governor Phil Murphy plans to make New Jersey a Sanctuary State for illegal immigrants—handcuffing law enforcement from working with federal immigration officials to arrest illegal immigrants convicted of VIOLENT CRIMES living in our communities',\n",
       " '\\n\\nHow could the Democrats be so irresponsible? Sanctuary City laws endanger our communities, and I will not stand by as politicians posture for reelection risking you and your loved ones’ lives',\n",
       " ' Our incredible state cannot be a sanctuary for violent criminals',\n",
       " '\\n\\nProud of my immigrant heritage, I will lead the fight in Congress to protect our families by:\\n\\nStopping the liberal Democrats in the D',\n",
       " 'C',\n",
       " ' and NJ swamps from blocking our President’s commonsense plan to fight illegal immigration',\n",
       " '\\nWorking to secure the border and ports of entry',\n",
       " '\\nBlocking terrorists, gangs, and drugs from entering this country',\n",
       " '\\nVoting to end the Diversity Visa Lottery and Chain Migration',\n",
       " '\\nWorking to create Merit-Based immigration so we’re only taking in the best and brightest from around the world',\n",
       " '\\nSecuring our border and protecting Americans shouldn’t come down to partisan politics',\n",
       " ' It is our government’s primary job to protect Americans but the elites have been failing us, year after year',\n",
       " '\\n\\nLet’s elect someone who will finally fight to protect all of our country’s citizens',\n",
       " '\\n\\n\\nIn the 1990s when Hillarycare (the precursor to Obamacare) was being prepped to pass, I worked as a young staff member in the United States Senate to expose Hillarycare as a fraud perpetrated on the American people',\n",
       " '\\n\\nAs a business owner, I’m committed to bringing a market-based approach to healthcare',\n",
       " '\\n\\nYou need better access to the doctors of your choice',\n",
       " '\\n\\nYou need better care for whatever health challenges you face',\n",
       " '\\n\\nYou need to be unburdened from crippling insurance rates',\n",
       " '\\n\\nAs your Congressman, I will finish the job of repealing and replacing Obamacare with a market-based approach that improves access to quality, affordable healthcare',\n",
       " ' I will also fight the current deathgrip Big Pharma has on D',\n",
       " 'C',\n",
       " ' politicians and will work to drive down costs and drive up care',\n",
       " '\\n\\nLet’s bring back medical freedom so you can get about living',\n",
       " '\\n\\nFrom the Desk of Paul Brubaker\\n\\nDear fellow American:\\n\\nMy name is Paul Brubaker and I’m writing to you today to tell you about a moment in history that occurred on the floor of the United States Senate back in summer of 1994; back when Hilary Clinton attempted, for the first time, to take over our healthcare system and the pivotal role John McCann played, who is your candidate for Congress in the 5th District of New Jersey',\n",
       " ' I know all about this because I was there',\n",
       " '  \\n\\nBack in 1994, I was the Republican Staff Director for the Senate Sub Committee on Oversight of Government Management',\n",
       " ' At that time the Democrats had complete control of our government and the Republicans had not controlled the House of Representatives for over 40 years',\n",
       " '  One of our committee’s functions was to monitor the Clintons’ Plan which would have taken over 1/7th of the US economy',\n",
       " ' At the time, then Republican Senator Arlen Spector’s office was the lead Republican office fighting the Clinton Plan',\n",
       " '\\n\\nDuring the Summer of 1994 it seemed all but inevitable that the Clinton Plan was going to become law',\n",
       " ' Then on August 10, 1994 there was a seismic shift in the political debate',\n",
       " ' The Republican Senator entered the Senate floor along with John McCann and presented to the nation a chart that demonstrated to the entire country what a bureaucratic mess the Clinton Plan was for the nation',\n",
       " ' The Senator announced that he was bringing Mr',\n",
       " ' McCann to the floor because he was the one who prepared the chart(s)',\n",
       " ' We on the committee watched and cheered as the Republican Senator used the chart to expose the flaws on the Plan',\n",
       " ' We on staff could see that public opinion was reversed',\n",
       " ' Less than 3 weeks later, the Clinton Plan was declared dead',\n",
       " ' As Staff Director of the Sub Committee on Government Oversight and Management, my staff and I recognized how much work John McCann put into the creation of the chart and held a special appreciation for how he contributed to changing political debate on the Bill',\n",
       " ' The rest is history we are all familiar with',\n",
       " ' The defeat of the Clintons’ Plan significantly weakened the House Democrats and a few weeks later, the Republicans took control of the House of Representatives gaining 54 seats in the next election led by Newt Gingrich’s Contract with America',\n",
       " '\\n\\nI do not live in the district and have no vested interest in this election',\n",
       " ' I do know that John McCann has a great understanding of Health Care Policy; I know that he has a personal interest in it as his wife is a high-risk Obstetrician with his oldest child heading off to medical school this summer',\n",
       " ' In a political climate where people write anonymous emails and posts making wild claims and remarks, I thought that the voters of New Jersey’s District 5, should know the facts concerning Mr',\n",
       " ' McCann’s important role because I was there',\n",
       " '   \\n\\nSincerely,\\n\\nPaul Brubaker\\n\\nFormer Republican Staff Director\\n\\nThe Second Amendment is personal for me—since 1981 when my veteran father was a victim of domestic terrorism',\n",
       " '\\n\\nShot by members of a domestic terror organization while working for Brinks, my father’s—and our family’s life—was never the same',\n",
       " '\\n\\nWithout the ability to defend our homes and our families, we can never truly be free',\n",
       " '\\n\\nThe Founding Fathers provided Americans with the freedom to exercise this right to keep and bear arms without governmental infringement',\n",
       " '\\n\\nOur inalienable rights to life, liberty and the pursuit of happiness are protected by the Second Amendment',\n",
       " ' Guns can save lives',\n",
       " '\\n\\nThis is why I will always fight to defend Second Amendment rights from liberal politicians in Washington and Trenton',\n",
       " '\\n\\nClick here to review my 2018 U',\n",
       " 'S',\n",
       " ' House Candidate Q&A with the NRA',\n",
       " '\\n\\nAs the only candidate in the race that has ever had a carry-and-conceal permit, I am the only pro-gun candidate in NJ-5 who will fight to protect your Second Amendment rights',\n",
       " '\\n\\n\\nSupport our military\\n\\nAs our incredible Defense Secretary James Mattis has said, “No enemy in the field has done more to harm the readiness of our military than sequestration',\n",
       " '”\\n\\nI will work with our President to invest in our military so they are fully equipped to protect our great country and our allies',\n",
       " ' We must roll back the Obama Administration’s cuts to defense spending—which have crippled our ability to defend ourselves, forcing our incredible servicemen and women to use outdated equipment',\n",
       " '\\n\\nJerusalem as Capital of Israel\\n\\nWhen President Trump recognized Jerusalem as the capital of Israel, I applauded this historic decision',\n",
       " ' After eight years of the Obama Administration’s anti-Israel policies, it’s time to restore our unwavering support and defense of Israel—our greatest ally',\n",
       " '\\n\\nNorth Korea\\n\\nIn order to truly Make America Safe Again, we must address North Korean aggression',\n",
       " ' When you send me to Congress, I will work with our President to stop North Korea from becoming a nuclear power',\n",
       " ' We must strengthen our support for allies in the region as well as use economic influence to spur action by the Chinese government',\n",
       " '\\n\\nRocket Man is no match for American leadership',\n",
       " '\\n\\nIran\\n\\nThe Obama Administration’s Iran deal is a national disgrace—rolling back sanctions on the Iranian regime as the nation continues to be a state sponsor of terrorism, advancing both ballistic missile and nuclear weapons programs',\n",
       " '\\n\\nI will work with our President to address all national security threats as we fight to eradicate radical Islamic terror',\n",
       " '\\n\\nI believe in school choice',\n",
       " ' Whether you want your kids in public school, private, charter or homeschool, I believe you—not some D',\n",
       " 'C',\n",
       " ' swamp creature—should be making the best decision for your family',\n",
       " '\\n\\nOur country is far behind other countries in updating our infrastructure',\n",
       " ' I believe this issue may be one of the few bipartisan issues left that we can all agree to work on to improve our communities',\n",
       " ' Through private-public partnerships, I know we can update our infrastructure and make it state-of-the-art',\n",
       " '\\n\\nLife begins at conception',\n",
       " '\\n\\nOn January 19, Congress voted on the “Born-Alive Abortion Survivors Protection Act,” making it the law of the land that a doctor must provide medical care to babies who survive botched abortions',\n",
       " ' While the bill passed the House, Rep',\n",
       " ' Gottheimer voted NO on protecting these poor children',\n",
       " '\\n\\nWhat kind of man votes in favor of letting babies born outside the womb die?\\n\\nLife begins at conception',\n",
       " ' Congress should be fighting for every American’s life whether they be in the womb or in old age—whether they be healthy or suffering from disabilities',\n",
       " '\\n\\nAs a Member of Congress I will oppose all taxpayer funding for any portion of Planned Parenthood’s budget supporting abortion services or the harvesting of fetal tissue',\n",
       " '\\n\\nI am a supporter of women’s healthcare, but there should be no taxpayer funding for abortions',\n",
       " '\\n\\nAs your Congressman, I will fight to ensure the government has a responsibility to protect the sanctity of life—one of our constitutional, Creator-endowed inalienable rights',\n",
       " '\\n\\nOpioid epidemic\\n\\nI have met too many families who have lost husbands, wives and children to the deadly opioid epidemic',\n",
       " '\\n\\nIt’s time we as Americans fight this life-altering crisis together—discovering better ways to treat chronic pain',\n",
       " ' By exploring non-addictive medications and holistic treatments to actually help patients get better, we will empower our fellow Americans to return to full and active lives, enjoying our inalienable rights of life, liberty and the pursuit of happiness',\n",
       " '\\n\\nBig Pharma has a powerful grip on politicians—but I can never be bought',\n",
       " ' I will fight for the best solutions for you—not some lobbyist’s bottomline',\n",
       " '\\n\\nWe also need to cut off the illegal drug supply pouring across our border that is poisoning our youth',\n",
       " ' By securing our Southern border, we will stop the illegal flow and access to deadly drugs',\n",
       " '\\n\\nCongress has become a career for professional politicians like Josh Gottheimer and Bob Menendez',\n",
       " ' The system is broken and we need term limits, which is why I was proud to sign the U',\n",
       " 'S',\n",
       " ' Term Limits pledge and will fight for term limits as your Congressman',\n",
       " ' \\n\\n']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcann_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion \n",
    "\n",
    "\n",
    "By looking at the issues page of a republican and democrat running for the same seat, we see that of the 135 detected statements on the dem's page, 105 were considered dem, good for 78%. On the contrary, the republican's issue page has 107 detected statements, where 61 register as democrat or 57%. At face value this means that the model successfully distinguished which candidate is more democratic of the two, there is a lot more work to be done. For one the training data isn't necessarily perfect and could be drawn from more sources, the strengh of such statements used here may have an impact, among other things. Overall this seems like a good starting point and this project seems to have some potential. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
