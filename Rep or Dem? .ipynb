{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "\n",
    "1. Scrape and tokenize democratic statements\n",
    "2. Scrape and tokenize republican statements\n",
    "3. Build a model and test\n",
    "4. Make up some phrases.\n",
    "\n",
    "5. I wanted to semantically map the embedding layer, but due to a bug in this code I have to do it another way. \n",
    "\n",
    "6. - Download the \"stances\" of different campaign sites, and see if this provides a grade of how dem or rep that person is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/noahkasmanoff/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/noahkasmanoff/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import dependencies \n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import codecs\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%pylab inline\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Scraping various sources for democratic and republican statements/stances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of dem corpus:  0\n",
      "len of dem corpus:  282\n",
      "len of dem corpus:  447\n",
      "len of dem corpus:  489\n",
      "len of dem corpus:  504\n",
      "len of dem corpus:  515\n",
      "len of dem corpus:  526\n",
      "\n",
      "Here's an example datapoint.\n",
      "We believe in protecting civil liberties and guaranteeing civil rights and voting rights, women’s rights and workers’ rights, LGBT rights, and rights for people with disabilities.\n",
      "['We', 'believe', 'in', 'protecting', 'civil', 'liberties', 'and', 'guaranteeing', 'civil', 'rights', 'and', 'voting', 'rights', 'women', 's', 'rights', 'and', 'workers', 'rights', 'LGBT', 'rights', 'and', 'rights', 'for', 'people', 'with', 'disabilities']\n",
      "The dem policy corpus contains 37,666 tokens\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#import democratic data\n",
    "\n",
    "#scrape DNC website\n",
    "url = \"https://democrats.org/about/party-platform/\"\n",
    "client = urlopen(url)\n",
    "page_html = client.read()\n",
    "page_soup = BeautifulSoup(page_html,'html.parser')\n",
    "\n",
    "\n",
    "dem_corpus = []\n",
    "print(\"len of dem corpus: \", len(dem_corpus))\n",
    "for tag in page_soup.find_all(['h1', 'p']):\n",
    "  #  print(len(tag.text))\n",
    "  #  print(tag.text)\n",
    "  #  print()\n",
    "    dem_corpus.append(tag.text)\n",
    "print(\"len of dem corpus: \", len(dem_corpus))\n",
    "\n",
    "\n",
    "\n",
    "#scrape some politics website. Does not use other indexing! \n",
    "url = \"http://www.ontheissues.org/Democratic_Party.htm\"\n",
    "client = urlopen(url)\n",
    "page_html = client.read()\n",
    "page_soup = BeautifulSoup(page_html,'html.parser')\n",
    "\n",
    "\n",
    "for tag in page_soup.find_all(['li']):\n",
    "    dem_corpus.append(tag.text)\n",
    "print(\"len of dem corpus: \", len(dem_corpus))\n",
    "\n",
    "\n",
    "\n",
    "#via wikipedia\n",
    "url = \"https://en.wikipedia.org/wiki/Political_positions_of_the_Democratic_Party\"\n",
    "\n",
    "client = urlopen(url)\n",
    "page_html = client.read()\n",
    "page_soup = BeautifulSoup(page_html,'html.parser')\n",
    "\n",
    "\n",
    "for tag in page_soup.find_all(['h1', 'p']):\n",
    "    dem_corpus.append(tag.text)\n",
    "print(\"len of dem corpus: \", len(dem_corpus))\n",
    "\n",
    "\n",
    "\n",
    "#scrape senate democrats website\n",
    "url = \"https://www.democrats.senate.gov/abetterdeal/higher-wages-and-better-jobs\"\n",
    "\n",
    "client = urlopen(url)\n",
    "page_html = client.read()\n",
    "page_soup = BeautifulSoup(page_html,'html.parser')\n",
    "\n",
    "\n",
    "for tag in page_soup.find_all(['h1', 'p']):\n",
    "  #  print(len(tag.text))\n",
    "  #  print(tag.text)\n",
    "  #  print()\n",
    "    dem_corpus.append(tag.text)\n",
    "print(\"len of dem corpus: \", len(dem_corpus))\n",
    "\n",
    "\n",
    "\n",
    "#continue scraping senate democrats\n",
    "url = \"https://www.democrats.senate.gov/abetterdeal/lower-the-cost-of-living-for-families\"\n",
    "\n",
    "client = urlopen(url)\n",
    "page_html = client.read()\n",
    "page_soup = BeautifulSoup(page_html,'html.parser')\n",
    "\n",
    "for tag in page_soup.find_all(['h1', 'p']):\n",
    "\n",
    "    dem_corpus.append(tag.text)\n",
    "print(\"len of dem corpus: \", len(dem_corpus))\n",
    "\n",
    "\n",
    "#and again \n",
    "\n",
    "url = \"https://www.democrats.senate.gov/abetterdeal/tools-to-succeed-in-the-21st-century\"\n",
    "\n",
    "client = urlopen(url)\n",
    "page_html = client.read()\n",
    "page_soup = BeautifulSoup(page_html,'html.parser')\n",
    "\n",
    "for tag in page_soup.find_all(['h1', 'p']):\n",
    "\n",
    "    dem_corpus.append(tag.text)\n",
    "print(\"len of dem corpus: \", len(dem_corpus))\n",
    "\n",
    "#combine all elements into a continuous body, now resembling a corpus. \n",
    "dem_corpus = \" \".join(dem_corpus)\n",
    "\n",
    "\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "\n",
    "raw_dem_sentences = tokenizer.tokenize(dem_corpus)\n",
    "\n",
    "def sentence_to_wordlist(raw):\n",
    "    clean = re.sub(\"[^a-zA-Z]\",\" \", raw)\n",
    "    words = clean.split()\n",
    "    return words\n",
    "\n",
    "\n",
    "dem_sentences = []\n",
    "for raw_dem_sentence in raw_dem_sentences:\n",
    "    if len(raw_dem_sentence) > 0:\n",
    "        dem_sentences.append(sentence_to_wordlist(raw_dem_sentence))\n",
    "print()     \n",
    "print(\"Here's an example datapoint.\")      \n",
    "print(raw_dem_sentences[50])\n",
    "print(sentence_to_wordlist(raw_dem_sentences[50]))\n",
    "\n",
    "\n",
    "\n",
    "token_count = sum([len(dem_sentence) for dem_sentence in dem_sentences])\n",
    "print(\"The dem policy corpus contains {0:,} tokens\".format(token_count))\n",
    "\n",
    "\n",
    "y_dems = np.ones(shape=np.shape(dem_sentences)) #now the labels. \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rep corpus:  0\n",
      "len of rep corpus:  72\n",
      "len of rep corpus:  280\n",
      "Reading 'rep_platform.txt'...\n",
      "\n",
      "Here's an example sentence in rep corpus.\n",
      "[14]\n",
      " Republican party leaders strongly believe that free markets and individual achievement are the primary factors behind economic prosperity.\n",
      "['Republican', 'party', 'leaders', 'strongly', 'believe', 'that', 'free', 'markets', 'and', 'individual', 'achievement', 'are', 'the', 'primary', 'factors', 'behind', 'economic', 'prosperity']\n",
      "The rep policy corpus contains 57,193 tokens\n"
     ]
    }
   ],
   "source": [
    "#Now the republican data. \n",
    "\n",
    "#scrape wikipedia description. \n",
    "url = \"https://en.wikipedia.org/wiki/Political_positions_of_the_Republican_Party\"\n",
    "client = urlopen(url)\n",
    "page_html = client.read()\n",
    "page_soup = BeautifulSoup(page_html,'html.parser')\n",
    "\n",
    "\n",
    "rep_corpus = []\n",
    "print(\"len of rep corpus: \", len(rep_corpus))\n",
    "for tag in page_soup.find_all(['h1', 'p']):\n",
    "  #  print(len(tag.text))\n",
    "  #  print(tag.text)\n",
    "  #  print()\n",
    "    rep_corpus.append(tag.text)\n",
    "print(\"len of rep corpus: \", len(rep_corpus))\n",
    "\n",
    "#Scrape GOP website for official platform\n",
    "#Forbidden, so I copy pasted it all into a text file also in this repo. \n",
    "\n",
    "#on the issues website\n",
    "url = \"http://www.ontheissues.org/Republican_Party.htm\"\n",
    "\n",
    "client = urlopen(url)\n",
    "page_html = client.read()\n",
    "page_soup = BeautifulSoup(page_html,'html.parser')\n",
    "\n",
    "\n",
    "for tag in page_soup.find_all(['li']):\n",
    "  #  print(len(tag.text))\n",
    "  #  print(tag.text)\n",
    "  #  print()\n",
    "    rep_corpus.append(tag.text)\n",
    "print(\"len of rep corpus: \", len(rep_corpus))\n",
    "\n",
    "\n",
    "\n",
    "rep_corpus = \" \".join(rep_corpus)\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#open the text file and \n",
    "rep_platform_corpus_raw = u\"\"\n",
    "print(\"Reading '{0}'...\".format('rep_platform.txt'))\n",
    "with codecs.open('rep_platform.txt', \"r\", \"utf-8\") as book_file:\n",
    "    rep_platform_corpus_raw += book_file.read()\n",
    "\n",
    "rep_corpus += rep_platform_corpus_raw\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "raw_rep_sentences = tokenizer.tokenize(rep_corpus)\n",
    "\n",
    "\n",
    "def sentence_to_wordlist(raw):\n",
    "    clean = re.sub(\"[^a-zA-Z]\",\" \", raw)\n",
    "    words = clean.split()\n",
    "    return words\n",
    "\n",
    "\n",
    "rep_sentences = []\n",
    "for raw_rep_sentence in raw_rep_sentences:\n",
    "    if len(raw_rep_sentence) > 0:\n",
    "        rep_sentences.append(sentence_to_wordlist(raw_rep_sentence))\n",
    "        \n",
    "print()\n",
    "print(\"Here's an example sentence in rep corpus.\")\n",
    "print(raw_rep_sentences[10])\n",
    "print(sentence_to_wordlist(raw_rep_sentences[10]))\n",
    "\n",
    "\n",
    "token_count = sum([len(rep_sentence) for rep_sentence in rep_sentences])\n",
    "print(\"The rep policy corpus contains {0:,} tokens\".format(token_count))\n",
    "\n",
    "\n",
    "y_reps = np.zeros(shape=np.shape(rep_sentences))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now it's modelling time \n",
    "\n",
    "Reference: \n",
    "https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/20_Natural_Language_Processing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "\n",
    "# from tf.keras.models import Sequential  # This does not work!\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, GRU, Embedding\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Tokenizing and splitting these statements into a training/testing format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Republican administration will champion an open and free internet based on principles of free expression and universal values and will pursue policies to empower citizens and U.S. companies operating in authoritarian countries to circumvent internet firewalls and gain accurate news and information online.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_rep_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To recreate the structure of the imdb dataset, the next plan is to concatenate the dem and rep texts and simultaneously with the labels of 1 or 0, and probably shuffle both. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_text = np.concatenate((raw_dem_sentences,raw_rep_sentences))\n",
    "y = np.concatenate((y_dems,y_reps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(X_text, y ,shuffle=True, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5326"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training and testing data are now separated and shuffled. Next task is to tokenize these words once again, but now this will be based on an integer value for indexing each word (note this contains no semantic meaning), and once fit you can determine how many unique words to include."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_words=6000\n",
    "tokenizer = Tokenizer(num_words=num_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting: \n",
    "The tokenizer scans through all the text and strips unwanted characters, converts everything to lowercase, and builds a vocabulary of all the unique words. It's ok that it uses the entire dataset, as the embedding is only based on the training data (not sure how accurate this is though should follow this up). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(X_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if num_words is None:\n",
    "    num_words = len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'and': 2,\n",
       " 'to': 3,\n",
       " 'of': 4,\n",
       " '\\r': 5,\n",
       " 'in': 6,\n",
       " 'we': 7,\n",
       " 'a': 8,\n",
       " 'for': 9,\n",
       " 'that': 10,\n",
       " 'aug': 11,\n",
       " '2000': 12,\n",
       " '2004': 13,\n",
       " 'our': 14,\n",
       " 'will': 15,\n",
       " 'is': 16,\n",
       " 'on': 17,\n",
       " 'with': 18,\n",
       " 'sep': 19,\n",
       " 'by': 20,\n",
       " 'as': 21,\n",
       " 'their': 22,\n",
       " 'support': 23,\n",
       " 'are': 24,\n",
       " 'not': 25,\n",
       " 'have': 26,\n",
       " 'be': 27,\n",
       " 'it': 28,\n",
       " 'democrats': 29,\n",
       " 'from': 30,\n",
       " 'or': 31,\n",
       " 'should': 32,\n",
       " 'more': 33,\n",
       " 'american': 34,\n",
       " 'government': 35,\n",
       " 'all': 36,\n",
       " 'has': 37,\n",
       " 'federal': 38,\n",
       " 'must': 39,\n",
       " 'health': 40,\n",
       " 'jul': 41,\n",
       " 'rights': 42,\n",
       " 'people': 43,\n",
       " '2012': 44,\n",
       " 'an': 45,\n",
       " 'who': 46,\n",
       " 'military': 47,\n",
       " 'states': 48,\n",
       " 'public': 49,\n",
       " 'they': 50,\n",
       " 'national': 51,\n",
       " 'new': 52,\n",
       " 'americans': 53,\n",
       " 'at': 54,\n",
       " 'which': 55,\n",
       " 'no': 56,\n",
       " 'party': 57,\n",
       " 'against': 58,\n",
       " 'its': 59,\n",
       " 'republican': 60,\n",
       " 'this': 61,\n",
       " 'education': 62,\n",
       " 'those': 63,\n",
       " 'care': 64,\n",
       " 'other': 65,\n",
       " 'tax': 66,\n",
       " 'believe': 67,\n",
       " 'protect': 68,\n",
       " 'state': 69,\n",
       " 'republicans': 70,\n",
       " 'jun': 71,\n",
       " 'also': 72,\n",
       " 'work': 73,\n",
       " 'u': 74,\n",
       " 'congress': 75,\n",
       " 'right': 76,\n",
       " 'top': 77,\n",
       " 'economic': 78,\n",
       " '2016': 79,\n",
       " 'president': 80,\n",
       " 'been': 81,\n",
       " 'system': 82,\n",
       " 'can': 83,\n",
       " 'law': 84,\n",
       " 'access': 85,\n",
       " 'than': 86,\n",
       " 'but': 87,\n",
       " 'fight': 88,\n",
       " 'united': 89,\n",
       " 'many': 90,\n",
       " 'reform': 91,\n",
       " 'country': 92,\n",
       " 'security': 93,\n",
       " 'make': 94,\n",
       " 'programs': 95,\n",
       " 'act': 96,\n",
       " 'including': 97,\n",
       " 's': 98,\n",
       " 'laws': 99,\n",
       " 'economy': 100,\n",
       " 'world': 101,\n",
       " 'end': 102,\n",
       " 'private': 103,\n",
       " 'oppose': 104,\n",
       " 'jobs': 105,\n",
       " 'through': 106,\n",
       " 'communities': 107,\n",
       " 'encourage': 108,\n",
       " 'defense': 109,\n",
       " '—': 110,\n",
       " 'energy': 111,\n",
       " 'provide': 112,\n",
       " 'based': 113,\n",
       " 'america': 114,\n",
       " 'free': 115,\n",
       " 'amendment': 116,\n",
       " 'need': 117,\n",
       " 'better': 118,\n",
       " 'over': 119,\n",
       " 'life': 120,\n",
       " 'abortion': 121,\n",
       " 'any': 122,\n",
       " 'one': 123,\n",
       " 'help': 124,\n",
       " 'funding': 125,\n",
       " 'democratic': 126,\n",
       " 'every': 127,\n",
       " 'families': 128,\n",
       " 'ensure': 129,\n",
       " 'most': 130,\n",
       " 'school': 131,\n",
       " 'only': 132,\n",
       " 'workers': 133,\n",
       " 'when': 134,\n",
       " 'do': 135,\n",
       " 'trade': 136,\n",
       " 'so': 137,\n",
       " 'these': 138,\n",
       " 'while': 139,\n",
       " 'women': 140,\n",
       " 'nuclear': 141,\n",
       " 'needs': 142,\n",
       " 'such': 143,\n",
       " 'restore': 144,\n",
       " 'policy': 145,\n",
       " 'marriage': 146,\n",
       " 'without': 147,\n",
       " 'create': 148,\n",
       " 'war': 149,\n",
       " 'continue': 150,\n",
       " 'change': 151,\n",
       " 'keep': 152,\n",
       " 'religious': 153,\n",
       " 'social': 154,\n",
       " 'first': 155,\n",
       " 'service': 156,\n",
       " 'human': 157,\n",
       " 'reduce': 158,\n",
       " 'foreign': 159,\n",
       " 'policies': 160,\n",
       " 'them': 161,\n",
       " 'family': 162,\n",
       " 'would': 163,\n",
       " 'use': 164,\n",
       " 'promote': 165,\n",
       " 'power': 166,\n",
       " 'home': 167,\n",
       " 'current': 168,\n",
       " 'constitutional': 169,\n",
       " 'nation': 170,\n",
       " 'between': 171,\n",
       " 'call': 172,\n",
       " 'bush': 173,\n",
       " 'administration': 174,\n",
       " 'political': 175,\n",
       " 'schools': 176,\n",
       " 'years': 177,\n",
       " 'housing': 178,\n",
       " 'into': 179,\n",
       " 'democracy': 180,\n",
       " 'efforts': 181,\n",
       " 'out': 182,\n",
       " 'long': 183,\n",
       " 'century': 184,\n",
       " 'pay': 185,\n",
       " 'strengthen': 186,\n",
       " 'allow': 187,\n",
       " 'costs': 188,\n",
       " 'time': 189,\n",
       " 'choice': 190,\n",
       " 'freedom': 191,\n",
       " 'increase': 192,\n",
       " 'both': 193,\n",
       " 'oct': 194,\n",
       " 'was': 195,\n",
       " 'action': 196,\n",
       " 'international': 197,\n",
       " 'growth': 198,\n",
       " 'child': 199,\n",
       " 'china': 200,\n",
       " 'immigration': 201,\n",
       " 'like': 202,\n",
       " 'legislation': 203,\n",
       " 'discrimination': 204,\n",
       " 'children': 205,\n",
       " 'committed': 206,\n",
       " 'nations': 207,\n",
       " '2006': 208,\n",
       " 'middle': 209,\n",
       " 'investment': 210,\n",
       " 'treatment': 211,\n",
       " 'us': 212,\n",
       " 'same': 213,\n",
       " 'resources': 214,\n",
       " 'safety': 215,\n",
       " 'weapons': 216,\n",
       " 'financial': 217,\n",
       " 'services': 218,\n",
       " 'community': 219,\n",
       " 'there': 220,\n",
       " 'high': 221,\n",
       " 'strong': 222,\n",
       " 'local': 223,\n",
       " 'citizens': 224,\n",
       " 'safe': 225,\n",
       " 'vote': 226,\n",
       " 'climate': 227,\n",
       " 'especially': 228,\n",
       " 'market': 229,\n",
       " 'comprehensive': 230,\n",
       " 'constitution': 231,\n",
       " 'just': 232,\n",
       " 'development': 233,\n",
       " 'expand': 234,\n",
       " 'research': 235,\n",
       " 'traditional': 236,\n",
       " 'peace': 237,\n",
       " 'good': 238,\n",
       " 'global': 239,\n",
       " 'affordable': 240,\n",
       " 'assistance': 241,\n",
       " 'institutions': 242,\n",
       " 'israel': 243,\n",
       " 'gays': 244,\n",
       " 'income': 245,\n",
       " 'future': 246,\n",
       " 'because': 247,\n",
       " 'individuals': 248,\n",
       " 'own': 249,\n",
       " 'america’s': 250,\n",
       " 'students': 251,\n",
       " 'technology': 252,\n",
       " 'members': 253,\n",
       " 'millions': 254,\n",
       " 'business': 255,\n",
       " 'program': 256,\n",
       " 'ban': 257,\n",
       " 'drug': 258,\n",
       " '2003': 259,\n",
       " 'now': 260,\n",
       " 'college': 261,\n",
       " 'property': 262,\n",
       " 'countries': 263,\n",
       " 'recognize': 264,\n",
       " 'faith': 265,\n",
       " 'platform': 266,\n",
       " 'best': 267,\n",
       " 'important': 268,\n",
       " 'forces': 269,\n",
       " 'up': 270,\n",
       " 'control': 271,\n",
       " 'give': 272,\n",
       " 'eliminate': 273,\n",
       " 'legal': 274,\n",
       " 'urge': 275,\n",
       " 'learning': 276,\n",
       " 'instead': 277,\n",
       " '”': 278,\n",
       " 'poverty': 279,\n",
       " 'well': 280,\n",
       " 'authority': 281,\n",
       " 'iraq': 282,\n",
       " 'under': 283,\n",
       " 'year': 284,\n",
       " '21st': 285,\n",
       " 'small': 286,\n",
       " 'spending': 287,\n",
       " 'environmental': 288,\n",
       " 'sector': 289,\n",
       " 'too': 290,\n",
       " 'his': 291,\n",
       " 'respect': 292,\n",
       " 'if': 293,\n",
       " 'increased': 294,\n",
       " 'why': 295,\n",
       " 'enforcement': 296,\n",
       " 'medicare': 297,\n",
       " 'insurance': 298,\n",
       " 'class': 299,\n",
       " 'terrorism': 300,\n",
       " 'opportunity': 301,\n",
       " 'lead': 302,\n",
       " 'businesses': 303,\n",
       " 'build': 304,\n",
       " 'minimum': 305,\n",
       " 'benefits': 306,\n",
       " 'budget': 307,\n",
       " 'down': 308,\n",
       " 'way': 309,\n",
       " 'clean': 310,\n",
       " 'civil': 311,\n",
       " 'union': 312,\n",
       " 'standards': 313,\n",
       " 'across': 314,\n",
       " 'justice': 315,\n",
       " 'upon': 316,\n",
       " 'affirm': 317,\n",
       " 'take': 318,\n",
       " 'disabilities': 319,\n",
       " 'possible': 320,\n",
       " 'welfare': 321,\n",
       " 'nato': 322,\n",
       " 'labor': 323,\n",
       " 'defend': 324,\n",
       " 'low': 325,\n",
       " 'protection': 326,\n",
       " 'officials': 327,\n",
       " 'responsibility': 328,\n",
       " 'debt': 329,\n",
       " 'student': 330,\n",
       " 'missile': 331,\n",
       " 'leadership': 332,\n",
       " 'protecting': 333,\n",
       " 'about': 334,\n",
       " 'wage': 335,\n",
       " 'companies': 336,\n",
       " 'organizations': 337,\n",
       " 'internet': 338,\n",
       " 'tribal': 339,\n",
       " 'judges': 340,\n",
       " 'advance': 341,\n",
       " 'oped': 342,\n",
       " 'industry': 343,\n",
       " 'behind': 344,\n",
       " 'where': 345,\n",
       " 'last': 346,\n",
       " 'full': 347,\n",
       " 'leaders': 348,\n",
       " 'fundamental': 349,\n",
       " 'key': 350,\n",
       " 'partners': 351,\n",
       " 'percent': 352,\n",
       " 'nation’s': 353,\n",
       " 'equal': 354,\n",
       " 'quality': 355,\n",
       " 'combat': 356,\n",
       " 'medical': 357,\n",
       " 'healthcare': 358,\n",
       " 'force': 359,\n",
       " 'some': 360,\n",
       " 'executive': 361,\n",
       " 'governments': 362,\n",
       " 'abuse': 363,\n",
       " 'made': 364,\n",
       " 'success': 365,\n",
       " 'indian': 366,\n",
       " 'regulations': 367,\n",
       " 'accountability': 368,\n",
       " 'culture': 369,\n",
       " 'obama': 370,\n",
       " 'what': 371,\n",
       " 'seek': 372,\n",
       " 'higher': 373,\n",
       " 'corporate': 374,\n",
       " 'employment': 375,\n",
       " 'establish': 376,\n",
       " 'agenda': 377,\n",
       " 'open': 378,\n",
       " 'cannot': 379,\n",
       " 'taking': 380,\n",
       " 'focus': 381,\n",
       " 'needed': 382,\n",
       " 'gun': 383,\n",
       " 'drugs': 384,\n",
       " 'voting': 385,\n",
       " 'among': 386,\n",
       " 'natural': 387,\n",
       " 'commitment': 388,\n",
       " 'lands': 389,\n",
       " 'house': 390,\n",
       " 'supported': 391,\n",
       " 'job': 392,\n",
       " 'working': 393,\n",
       " 'cost': 394,\n",
       " 'innovation': 395,\n",
       " 'after': 396,\n",
       " 'immigrants': 397,\n",
       " 'department': 398,\n",
       " 'develop': 399,\n",
       " 'speech': 400,\n",
       " 'sex': 401,\n",
       " 'strategy': 402,\n",
       " 'powers': 403,\n",
       " 'va': 404,\n",
       " 'basic': 405,\n",
       " 'role': 406,\n",
       " 'society': 407,\n",
       " 'limit': 408,\n",
       " 'address': 409,\n",
       " 'crisis': 410,\n",
       " 'he': 411,\n",
       " '10': 412,\n",
       " 'stop': 413,\n",
       " 'repeal': 414,\n",
       " 'values': 415,\n",
       " 'strength': 416,\n",
       " 'intelligence': 417,\n",
       " 'influence': 418,\n",
       " 'attack': 419,\n",
       " 'existing': 420,\n",
       " 'cut': 421,\n",
       " 'greater': 422,\n",
       " 'around': 423,\n",
       " 'death': 424,\n",
       " 'liberty': 425,\n",
       " 'prosperity': 426,\n",
       " 'approach': 427,\n",
       " 'deal': 428,\n",
       " 'east': 429,\n",
       " 'taiwan': 430,\n",
       " 'gop': 431,\n",
       " 'together': 432,\n",
       " 'paying': 433,\n",
       " 'illegal': 434,\n",
       " 'stand': 435,\n",
       " 'investments': 436,\n",
       " 'fair': 437,\n",
       " 'leading': 438,\n",
       " 'enact': 439,\n",
       " 'interests': 440,\n",
       " 'bill': 441,\n",
       " 'senate': 442,\n",
       " 'since': 443,\n",
       " 'given': 444,\n",
       " 'two': 445,\n",
       " 'rebuild': 446,\n",
       " 'order': 447,\n",
       " 'donald': 448,\n",
       " 'rule': 449,\n",
       " 'workforce': 450,\n",
       " 'opportunities': 451,\n",
       " 'threats': 452,\n",
       " 'status': 453,\n",
       " 'during': 454,\n",
       " 'crime': 455,\n",
       " 'mental': 456,\n",
       " 'equip': 457,\n",
       " 'left': 458,\n",
       " 'challenges': 459,\n",
       " 'level': 460,\n",
       " 'majority': 461,\n",
       " 'penalty': 462,\n",
       " 'veterans': 463,\n",
       " 'loans': 464,\n",
       " 'relations': 465,\n",
       " 'court': 466,\n",
       " 'put': 467,\n",
       " 'ownership': 468,\n",
       " 'expanding': 469,\n",
       " 'position': 470,\n",
       " 'become': 471,\n",
       " 'parents': 472,\n",
       " 'increasing': 473,\n",
       " 'voter': 474,\n",
       " 'agencies': 475,\n",
       " 'making': 476,\n",
       " 'markets': 477,\n",
       " 'average': 478,\n",
       " 'improve': 479,\n",
       " 'lives': 480,\n",
       " 'were': 481,\n",
       " 'groups': 482,\n",
       " 'regulation': 483,\n",
       " 'part': 484,\n",
       " 'terror': 485,\n",
       " 'administration’s': 486,\n",
       " 'africa': 487,\n",
       " 'plan': 488,\n",
       " 'cooperation': 489,\n",
       " 'racial': 490,\n",
       " 'common': 491,\n",
       " 'even': 492,\n",
       " 'back': 493,\n",
       " 'ability': 494,\n",
       " 'applaud': 495,\n",
       " 'secure': 496,\n",
       " 'conditions': 497,\n",
       " 'trust': 498,\n",
       " 'fund': 499,\n",
       " 'engage': 500,\n",
       " 'effective': 501,\n",
       " 'reject': 502,\n",
       " 'invest': 503,\n",
       " 'much': 504,\n",
       " 'supreme': 505,\n",
       " 'limits': 506,\n",
       " 'billion': 507,\n",
       " 'afghanistan': 508,\n",
       " 'nov': 509,\n",
       " 'great': 510,\n",
       " 'threat': 511,\n",
       " 'teachers': 512,\n",
       " 'get': 513,\n",
       " 'creating': 514,\n",
       " 'serve': 515,\n",
       " 'training': 516,\n",
       " 'providing': 517,\n",
       " 'plans': 518,\n",
       " 'regulatory': 519,\n",
       " 'land': 520,\n",
       " 'creation': 521,\n",
       " 'sexual': 522,\n",
       " 'means': 523,\n",
       " 'strategies': 524,\n",
       " 'troops': 525,\n",
       " 'apr': 526,\n",
       " 'n': 527,\n",
       " 'let': 528,\n",
       " 'million': 529,\n",
       " 'within': 530,\n",
       " 'know': 531,\n",
       " 'wall': 532,\n",
       " 'elections': 533,\n",
       " 'promise': 534,\n",
       " 'pledge': 535,\n",
       " 'rather': 536,\n",
       " 'requirements': 537,\n",
       " 'process': 538,\n",
       " 'ensuring': 539,\n",
       " 'infrastructure': 540,\n",
       " 'enable': 541,\n",
       " 'country’s': 542,\n",
       " 'rates': 543,\n",
       " 'hold': 544,\n",
       " 'risk': 545,\n",
       " 'money': 546,\n",
       " 'violence': 547,\n",
       " 'congressional': 548,\n",
       " 'look': 549,\n",
       " 'conservative': 550,\n",
       " 'pro': 551,\n",
       " 'less': 552,\n",
       " 'self': 553,\n",
       " 'allies': 554,\n",
       " 'election': 555,\n",
       " 'lower': 556,\n",
       " 'grants': 557,\n",
       " 'used': 558,\n",
       " 'benefit': 559,\n",
       " 'strongly': 560,\n",
       " 'universal': 561,\n",
       " 'pursue': 562,\n",
       " 'agreements': 563,\n",
       " 'basis': 564,\n",
       " 'impose': 565,\n",
       " 'stem': 566,\n",
       " 'medicaid': 567,\n",
       " 'homeland': 568,\n",
       " 'prayer': 569,\n",
       " 'obamacare': 570,\n",
       " 'missiles': 571,\n",
       " 'coverage': 572,\n",
       " 'shared': 573,\n",
       " 'term': 574,\n",
       " 'interest': 575,\n",
       " 'live': 576,\n",
       " 'campaign': 577,\n",
       " 'rules': 578,\n",
       " 'living': 579,\n",
       " 'issue': 580,\n",
       " 'young': 581,\n",
       " 'critical': 582,\n",
       " 'close': 583,\n",
       " 'adoption': 584,\n",
       " 'intellectual': 585,\n",
       " 'criminal': 586,\n",
       " 'anti': 587,\n",
       " 'taxes': 588,\n",
       " 'centers': 589,\n",
       " 'puerto': 590,\n",
       " 'privacy': 591,\n",
       " '2007': 592,\n",
       " 'thru': 593,\n",
       " 'voted': 594,\n",
       " 'had': 595,\n",
       " 'overseas': 596,\n",
       " 'face': 597,\n",
       " 'god': 598,\n",
       " 'honor': 599,\n",
       " 'lgbt': 600,\n",
       " '000': 601,\n",
       " 'priority': 602,\n",
       " 'remain': 603,\n",
       " 'today': 604,\n",
       " 'information': 605,\n",
       " 'place': 606,\n",
       " 'problems': 607,\n",
       " 'independence': 608,\n",
       " 'environment': 609,\n",
       " 'special': 610,\n",
       " 'courts': 611,\n",
       " 'run': 612,\n",
       " 'issues': 613,\n",
       " 'does': 614,\n",
       " 'adversaries': 615,\n",
       " 'ballistic': 616,\n",
       " 'asia': 617,\n",
       " 'far': 618,\n",
       " 'protections': 619,\n",
       " 'unions': 620,\n",
       " 'pass': 621,\n",
       " 'major': 622,\n",
       " 'trump': 623,\n",
       " 'require': 624,\n",
       " 'toward': 625,\n",
       " 'parts': 626,\n",
       " 'preserve': 627,\n",
       " 'options': 628,\n",
       " 'next': 629,\n",
       " 'seniors': 630,\n",
       " 'retirement': 631,\n",
       " 'food': 632,\n",
       " 'problem': 633,\n",
       " 'demand': 634,\n",
       " 'modernize': 635,\n",
       " 'led': 636,\n",
       " 'progress': 637,\n",
       " 'abroad': 638,\n",
       " 'able': 639,\n",
       " 'corporations': 640,\n",
       " 'condemn': 641,\n",
       " 'decision': 642,\n",
       " 'cover': 643,\n",
       " 'non': 644,\n",
       " 'limited': 645,\n",
       " 'poor': 646,\n",
       " 'set': 647,\n",
       " 'however': 648,\n",
       " 'individual': 649,\n",
       " 'passed': 650,\n",
       " 'principles': 651,\n",
       " 'man': 652,\n",
       " 'always': 653,\n",
       " 'makes': 654,\n",
       " 'bring': 655,\n",
       " 'called': 656,\n",
       " 'practices': 657,\n",
       " 'prevent': 658,\n",
       " 'effort': 659,\n",
       " 'funds': 660,\n",
       " 'appropriate': 661,\n",
       " 'science': 662,\n",
       " 'net': 663,\n",
       " 'arms': 664,\n",
       " 'terrorists': 665,\n",
       " 'past': 666,\n",
       " 'being': 667,\n",
       " 'line': 668,\n",
       " 'provided': 669,\n",
       " 'therefore': 670,\n",
       " 'multiple': 671,\n",
       " 'proliferation': 672,\n",
       " 'southern': 673,\n",
       " 'latin': 674,\n",
       " 'vouchers': 675,\n",
       " 'charitable': 676,\n",
       " 'morale': 677,\n",
       " 'conflict': 678,\n",
       " 'meet': 679,\n",
       " 'here': 680,\n",
       " 'early': 681,\n",
       " 'street': 682,\n",
       " 'never': 683,\n",
       " 'personal': 684,\n",
       " 'areas': 685,\n",
       " 'enforce': 686,\n",
       " 'may': 687,\n",
       " 'participation': 688,\n",
       " 'data': 689,\n",
       " 'others': 690,\n",
       " 'before': 691,\n",
       " 'opposed': 692,\n",
       " 'protected': 693,\n",
       " 'guard': 694,\n",
       " 'terrorist': 695,\n",
       " 'border': 696,\n",
       " 'center': 697,\n",
       " 'representatives': 698,\n",
       " '2008': 699,\n",
       " 'how': 700,\n",
       " 'wages': 701,\n",
       " 'wealth': 702,\n",
       " 'stronger': 703,\n",
       " 'raise': 704,\n",
       " 'code': 705,\n",
       " 'liberties': 706,\n",
       " 'break': 707,\n",
       " 'supporting': 708,\n",
       " 'exercise': 709,\n",
       " 'voluntary': 710,\n",
       " 'sure': 711,\n",
       " 'presidential': 712,\n",
       " 'credit': 713,\n",
       " 'prepare': 714,\n",
       " 'decades': 715,\n",
       " 'systems': 716,\n",
       " 'cultural': 717,\n",
       " 'whether': 718,\n",
       " 'taxpayers': 719,\n",
       " 'dangerous': 720,\n",
       " 'banks': 721,\n",
       " 'fully': 722,\n",
       " 'tools': 723,\n",
       " 'include': 724,\n",
       " 'agreement': 725,\n",
       " 'held': 726,\n",
       " 'lost': 727,\n",
       " 'facilities': 728,\n",
       " 'v': 729,\n",
       " 'size': 730,\n",
       " 'further': 731,\n",
       " 'pre': 732,\n",
       " 'region': 733,\n",
       " 'regime': 734,\n",
       " 'russia': 735,\n",
       " 'ties': 736,\n",
       " 'plus': 737,\n",
       " 'iraqi': 738,\n",
       " 'fronts': 739,\n",
       " 'history': 740,\n",
       " 'choose': 741,\n",
       " 'gained': 742,\n",
       " 'reach': 743,\n",
       " 'potential': 744,\n",
       " 'borders': 745,\n",
       " 'homes': 746,\n",
       " 'attempts': 747,\n",
       " 'forced': 748,\n",
       " 'commission': 749,\n",
       " 'big': 750,\n",
       " 'advanced': 751,\n",
       " 'space': 752,\n",
       " 'start': 753,\n",
       " 'director': 754,\n",
       " 'police': 755,\n",
       " 'avoid': 756,\n",
       " '11': 757,\n",
       " 'affirmative': 758,\n",
       " 'initiative': 759,\n",
       " 'native': 760,\n",
       " 'air': 761,\n",
       " 'add': 762,\n",
       " 'essential': 763,\n",
       " 'banning': 764,\n",
       " 'conscience': 765,\n",
       " 'cause': 766,\n",
       " 'unfairness': 767,\n",
       " 'beliefs': 768,\n",
       " 'come': 769,\n",
       " 'politics': 770,\n",
       " 'race': 771,\n",
       " 'allowed': 772,\n",
       " 'deserve': 773,\n",
       " 'number': 774,\n",
       " 'form': 775,\n",
       " 'color': 776,\n",
       " 'contribute': 777,\n",
       " 'leave': 778,\n",
       " 'necessary': 779,\n",
       " 'everyone': 780,\n",
       " 'rate': 781,\n",
       " 'age': 782,\n",
       " 'promoting': 783,\n",
       " 'water': 784,\n",
       " 'learn': 785,\n",
       " 'measures': 786,\n",
       " 'often': 787,\n",
       " 'agency': 788,\n",
       " 'safeguard': 789,\n",
       " 'prevention': 790,\n",
       " '3': 791,\n",
       " 'farmers': 792,\n",
       " 'domestic': 793,\n",
       " 'providers': 794,\n",
       " 'vital': 795,\n",
       " 'modern': 796,\n",
       " 'decisions': 797,\n",
       " 'another': 798,\n",
       " 'pollution': 799,\n",
       " '1': 800,\n",
       " 'goals': 801,\n",
       " 'reforms': 802,\n",
       " 'treaty': 803,\n",
       " 'washington': 804,\n",
       " 'cell': 805,\n",
       " 'mar': 806,\n",
       " 'results': 807,\n",
       " 'peacekeeping': 808,\n",
       " '1997': 809,\n",
       " 'ideas': 810,\n",
       " 'forward': 811,\n",
       " 'hard': 812,\n",
       " 'oil': 813,\n",
       " 'longer': 814,\n",
       " 'created': 815,\n",
       " 'barriers': 816,\n",
       " 'goal': 817,\n",
       " 'building': 818,\n",
       " 'transportation': 819,\n",
       " 'already': 820,\n",
       " 'beyond': 821,\n",
       " 'rural': 822,\n",
       " 'itself': 823,\n",
       " 'cuts': 824,\n",
       " 'personnel': 825,\n",
       " 'recent': 826,\n",
       " 'transparency': 827,\n",
       " 'ethnic': 828,\n",
       " 'citizenship': 829,\n",
       " 'persons': 830,\n",
       " 'central': 831,\n",
       " 'forms': 832,\n",
       " 'done': 833,\n",
       " 'sovereignty': 834,\n",
       " 'moral': 835,\n",
       " 'manage': 836,\n",
       " 'foundation': 837,\n",
       " 'restrictions': 838,\n",
       " 'inalienable': 839,\n",
       " 'responsible': 840,\n",
       " 'era': 841,\n",
       " 'oversight': 842,\n",
       " 'practice': 843,\n",
       " 'prescription': 844,\n",
       " 'strategic': 845,\n",
       " 'ok': 846,\n",
       " 'mccain': 847,\n",
       " 'ideology': 848,\n",
       " 'activist': 849,\n",
       " 'counterterrorism': 850,\n",
       " 'arm': 851,\n",
       " 'profit': 852,\n",
       " 'go': 853,\n",
       " 'finance': 854,\n",
       " 'safer': 855,\n",
       " 'lawyers': 856,\n",
       " 'soldiers': 857,\n",
       " 'day': 858,\n",
       " 'generations': 859,\n",
       " 'undermine': 860,\n",
       " 'path': 861,\n",
       " 'serving': 862,\n",
       " 'nearly': 863,\n",
       " 'includes': 864,\n",
       " 'competitive': 865,\n",
       " 'historic': 866,\n",
       " 'reserve': 867,\n",
       " 'gender': 868,\n",
       " 'challenge': 869,\n",
       " 'certain': 870,\n",
       " 'example': 871,\n",
       " 'religion': 872,\n",
       " 'language': 873,\n",
       " 'maintain': 874,\n",
       " 'territories': 875,\n",
       " 'destruction': 876,\n",
       " 'voters': 877,\n",
       " 'plants': 878,\n",
       " 'coast': 879,\n",
       " 'material': 880,\n",
       " 'post': 881,\n",
       " 'colleges': 882,\n",
       " 'achievement': 883,\n",
       " 'abortions': 884,\n",
       " 'assault': 885,\n",
       " 'victims': 886,\n",
       " 'elected': 887,\n",
       " 'gay': 888,\n",
       " 'parties': 889,\n",
       " 'economics': 890,\n",
       " 'propose': 891,\n",
       " 'initiated': 892,\n",
       " 'four': 893,\n",
       " 'move': 894,\n",
       " 'fairness': 895,\n",
       " 'today’s': 896,\n",
       " 'richest': 897,\n",
       " 'half': 898,\n",
       " 'still': 899,\n",
       " 'employers': 900,\n",
       " 'levels': 901,\n",
       " 'raising': 902,\n",
       " 'offer': 903,\n",
       " 'impact': 904,\n",
       " 'throughout': 905,\n",
       " 'supports': 906,\n",
       " 'generation': 907,\n",
       " 'broader': 908,\n",
       " 'track': 909,\n",
       " 'source': 910,\n",
       " 'white': 911,\n",
       " 'mandatory': 912,\n",
       " 'want': 913,\n",
       " 'states’': 914,\n",
       " 'kids': 915,\n",
       " 'skills': 916,\n",
       " 'capital': 917,\n",
       " 'flexibility': 918,\n",
       " 'engagement': 919,\n",
       " '2013': 920,\n",
       " 'cap': 921,\n",
       " 'gives': 922,\n",
       " 'burden': 923,\n",
       " 'north': 924,\n",
       " 'wealthy': 925,\n",
       " 'renewable': 926,\n",
       " 'minorities': 927,\n",
       " 'reporting': 928,\n",
       " 'consent': 929,\n",
       " '9': 930,\n",
       " 'travel': 931,\n",
       " 'democrat': 932,\n",
       " 'id': 933,\n",
       " 'exempt': 934,\n",
       " 'objectives': 935,\n",
       " 'greatly': 936,\n",
       " 'gap': 937,\n",
       " 'solutions': 938,\n",
       " 'join': 939,\n",
       " 'ways': 940,\n",
       " 'model': 941,\n",
       " 'dollars': 942,\n",
       " '40': 943,\n",
       " 'matters': 944,\n",
       " 'employees': 945,\n",
       " 'off': 946,\n",
       " 'share': 947,\n",
       " 'paid': 948,\n",
       " 'steps': 949,\n",
       " 'stability': 950,\n",
       " 'elderly': 951,\n",
       " 'production': 952,\n",
       " 'clear': 953,\n",
       " 'disability': 954,\n",
       " 'keeping': 955,\n",
       " 'independent': 956,\n",
       " 'contributions': 957,\n",
       " 'understand': 958,\n",
       " 'grow': 959,\n",
       " 'themselves': 960,\n",
       " 'large': 961,\n",
       " 'actions': 962,\n",
       " 'review': 963,\n",
       " 'push': 964,\n",
       " 'indians': 965,\n",
       " 'result': 966,\n",
       " 'world’s': 967,\n",
       " 'controlled': 968,\n",
       " 'aspect': 969,\n",
       " 'guarantee': 970,\n",
       " 'granting': 971,\n",
       " 'meaningful': 972,\n",
       " 'crimes': 973,\n",
       " 'carbon': 974,\n",
       " 'several': 975,\n",
       " 'prices': 976,\n",
       " 'aids': 977,\n",
       " 'suicide': 978,\n",
       " 'woman': 979,\n",
       " 'iran': 980,\n",
       " 'broad': 981,\n",
       " 'chemical': 982,\n",
       " 'reduced': 983,\n",
       " 'feingold': 984,\n",
       " '26': 985,\n",
       " 'regarding': 986,\n",
       " 'few': 987,\n",
       " 'bear': 988,\n",
       " 'recapitalize': 989,\n",
       " 'enlarge': 990,\n",
       " 'guard’s': 991,\n",
       " 'fleet': 992,\n",
       " 'reason': 993,\n",
       " 'ago': 994,\n",
       " 'obama’s': 995,\n",
       " 'creates': 996,\n",
       " 'matter': 997,\n",
       " 'dignity': 998,\n",
       " 'principle': 999,\n",
       " 'diplomacy': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is ordered by the number of occurences of the word. \n",
    "tokenizer.word_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now it's time to tokenize all of the training and testing data for future use. \n",
    "X_train_tokens = tokenizer.texts_to_sequences(X_train_text)\n",
    "\n",
    "X_test_tokens = tokenizer.texts_to_sequences(X_test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Padding and truncating\n",
    "\n",
    "Not all senetences are created equal (both in meaning and length!) To preserve the same size input property of a neural network, this means padding the shorter phrases, and truncating the longer ones. For padding these zeros (which will be interpreted as meaningless) will be placed at the start of the sentence as the sequential nature should play less of a role. Rather than an abrupt jump to zero which could have an adverse effect on the RNN, it is smarter to go from 0 up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_tokens = [len(tokens) for tokens in X_train_tokens + X_test_tokens]\n",
    "num_tokens = np.array(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.326511453248216"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(num_tokens)\n",
    "#avg num of tokens in a phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(num_tokens)\n",
    "#max num of tokens in a phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "max_tokens = int(max_tokens)\n",
    "max_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9474277131055201"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(num_tokens < max_tokens) / len(num_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So by setting it to mean + 2 stds, this covers about 93% of the dataset. Fine by me!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pad = 'pre' #pad in the beginning, reasoning explained earlier. \n",
    "\n",
    "X_train_pad = pad_sequences(X_train_tokens, maxlen=max_tokens,\n",
    "                            padding=pad, truncating=pad)\n",
    "\n",
    "X_test_pad = pad_sequences(X_test_tokens, maxlen=max_tokens,\n",
    "                           padding=pad, truncating=pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3568, 40)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1758, 40)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pad.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = tokenizer.word_index\n",
    "inverse_map = dict(zip(idx.values(), idx.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokens_to_string(tokens):\n",
    "    \"\"\"Helper function to go back to the text.\"\"\"\n",
    "    # Map from tokens back to words.\n",
    "    words = [inverse_map[token] for token in tokens if token != 0]\n",
    "    \n",
    "    # Concatenate all words.\n",
    "    text = \" \".join(words)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7801"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Democratic Party supports equal opportunity for all Americans regardless of sex, age, race, ethnicity, sexual orientation, gender identity, religion, creed, or national origin.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_text[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the democratic party supports equal opportunity for all americans regardless of sex age race ethnicity sexual orientation gender identity religion creed or national origin'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_to_string(X_train_tokens[10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Creating a Recurrent Neural Network \n",
    "\n",
    "\n",
    "Now for the implementation of an RNN to classify this data, using the keras structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "embedding_size = 10  #dimensions of word2vec (basically.)\n",
    "\n",
    "#this is essentially a word2vec model but it is a part of the RNN, as it trains simultaneously. \n",
    "model.add(Embedding(input_dim=num_words,\n",
    "                    output_dim=embedding_size,\n",
    "                    input_length=max_tokens,  \n",
    "                    name='layer_embedding'))\n",
    "\n",
    "\n",
    "\n",
    "model.add(GRU(units=16, return_sequences=True))\n",
    "model.add(GRU(units=8, return_sequences=True))\n",
    "model.add(GRU(units=4))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "optimizer = Adam(lr=1e-3)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer_embedding (Embedding)  (None, 40, 10)            60000     \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 40, 16)            1296      \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 40, 8)             600       \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 4)                 156       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 62,057\n",
      "Trainable params: 62,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3389 samples, validate on 179 samples\n",
      "Epoch 1/15\n",
      "3389/3389 [==============================] - 7s 2ms/step - loss: 0.6601 - acc: 0.6247 - val_loss: 0.6525 - val_acc: 0.6313\n",
      "Epoch 2/15\n",
      "3389/3389 [==============================] - 3s 1ms/step - loss: 0.6501 - acc: 0.6279 - val_loss: 0.6439 - val_acc: 0.6313\n",
      "Epoch 3/15\n",
      "3389/3389 [==============================] - 3s 1ms/step - loss: 0.6196 - acc: 0.6598 - val_loss: 0.6321 - val_acc: 0.6592\n",
      "Epoch 4/15\n",
      "3389/3389 [==============================] - 3s 993us/step - loss: 0.5174 - acc: 0.7560 - val_loss: 0.5157 - val_acc: 0.7598\n",
      "Epoch 5/15\n",
      "3389/3389 [==============================] - 4s 1ms/step - loss: 0.4027 - acc: 0.8389 - val_loss: 0.4382 - val_acc: 0.8156\n",
      "Epoch 6/15\n",
      "3389/3389 [==============================] - 4s 1ms/step - loss: 0.3186 - acc: 0.8879 - val_loss: 0.4002 - val_acc: 0.8603\n",
      "Epoch 7/15\n",
      "3389/3389 [==============================] - 4s 1ms/step - loss: 0.2610 - acc: 0.9162 - val_loss: 0.3835 - val_acc: 0.8547\n",
      "Epoch 8/15\n",
      "3389/3389 [==============================] - 4s 1ms/step - loss: 0.2103 - acc: 0.9407 - val_loss: 0.3763 - val_acc: 0.8715\n",
      "Epoch 9/15\n",
      "3389/3389 [==============================] - 4s 1ms/step - loss: 0.1887 - acc: 0.9436 - val_loss: 0.4002 - val_acc: 0.8492\n",
      "Epoch 10/15\n",
      "3389/3389 [==============================] - 3s 1ms/step - loss: 0.1552 - acc: 0.9587 - val_loss: 0.3884 - val_acc: 0.8715\n",
      "Epoch 11/15\n",
      "3389/3389 [==============================] - 3s 1ms/step - loss: 0.1243 - acc: 0.9711 - val_loss: 0.4285 - val_acc: 0.8492\n",
      "Epoch 12/15\n",
      "3389/3389 [==============================] - 3s 1ms/step - loss: 0.1046 - acc: 0.9782 - val_loss: 0.4566 - val_acc: 0.8436\n",
      "Epoch 13/15\n",
      "3389/3389 [==============================] - 3s 1ms/step - loss: 0.0929 - acc: 0.9817 - val_loss: 0.4360 - val_acc: 0.8659\n",
      "Epoch 14/15\n",
      "3389/3389 [==============================] - 3s 1ms/step - loss: 0.0833 - acc: 0.9841 - val_loss: 0.4706 - val_acc: 0.8492\n",
      "Epoch 15/15\n",
      "3389/3389 [==============================] - 4s 1ms/step - loss: 0.0806 - acc: 0.9841 - val_loss: 0.6269 - val_acc: 0.8212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x126b730f0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_pad, y_train,\n",
    "          validation_split=0.05, epochs=15, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1758/1758 [==============================] - 1s 472us/step\n",
      "Accuracy: 82.03%\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(X_test_pad, y_test)\n",
    "print(\"Accuracy: {0:.2%}\".format(result[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of mis-classified text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#In order to show an example of mis-classified text, \n",
    "#we first calculate the predicted sentiment for the first 500 texts in the test-set.\n",
    "\n",
    "y_pred = model.predict(x=X_test_pad[0:500])\n",
    "y_pred = y_pred.T[0]\n",
    "\n",
    "\n",
    "#These predicted numbers fall between 0.0 and 1.0. \n",
    "#We use a cutoff / threshold and say that all values above 0.5 \n",
    "#are taken to be 1.0 and all values below 0.5 are taken to be 0.0. \n",
    "#This gives us a predicted \"class\" of either 0.0 or 1.0.\n",
    "\n",
    "\n",
    "cls_pred = np.array([1.0 if p>0.5 else 0.0 for p in y_pred])\n",
    "cls_true = np.array(y_test[0:500])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then get indices for all the texts that were incorrectly classified by comparing all the \"classes\" of these two arrays.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2031"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_dems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3295"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3295 / (3295 + 2031)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect = np.where(cls_pred != cls_true)\n",
    "incorrect = incorrect[0]\n",
    "\n",
    "len(incorrect)  #how many out of 500 were wrong?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = incorrect[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Building the Future: Technology  (Top)\\n\\nThe digital revolution has transformed how we work, learn, sell, shop, socialize — in short, how we live.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = X_test_text[idx]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9729476"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "\n",
      "As such, they pushed the ADA Amendments Act of 2008, a legal expansion that became law.\n",
      "Incorrectly classified as  0.023068\n",
      "\n",
      "22\n",
      "\n",
      "The Democratic Party is extreme on abortion.\n",
      "Incorrectly classified as  0.972077\n",
      "\n",
      "23\n",
      "\n",
      "They practice boots-on-the-ground conservation in their states every day.\n",
      "Incorrectly classified as  0.946593\n",
      "\n",
      "30\n",
      "\n",
      "Africa: The Promise and the Challenge  (Top)\n",
      "\n",
      "We recognize Africa’s extraordinary potential.\n",
      "Incorrectly classified as  0.952158\n",
      "\n",
      "31\n",
      "\n",
      "American businesses have now added 14.8 million jobs since private-sector job growth turned positive in early 2010.\n",
      "Incorrectly classified as  0.0792379\n",
      "\n",
      "33\n",
      "\n",
      "To protect religious liberty we will ensure that faith-based institutions, especially those that are vital parts of underserved neighborhoods, do not face discrimination by government.\n",
      "Incorrectly classified as  0.970309\n",
      "\n",
      "38\n",
      "\n",
      "(Jan 2012)\r\n",
      "    Cut taxes to stimulate economy and help families.\n",
      "Incorrectly classified as  0.883378\n",
      "\n",
      "52\n",
      "\n",
      "(Aug 2012)\r\n",
      "    Workers will have choice to invest their payroll taxes.\n",
      "Incorrectly classified as  0.670538\n",
      "\n",
      "55\n",
      "\n",
      "At the same time, we look to broaden our trade agreements with countries which share our values and commitment to fairness, along with transparency in our commercial and business practices.\n",
      "Incorrectly classified as  0.974194\n",
      "\n",
      "56\n",
      "\n",
      "And we will continue to push NATO members to contribute their fair share.\n",
      "Incorrectly classified as  0.217307\n",
      "\n",
      "63\n",
      "\n",
      "Discrimination should have no place in the mortgage industry.\n",
      "Incorrectly classified as  0.971458\n",
      "\n",
      "77\n",
      "\n",
      "And for too many families, the dream of homeownership is out of reach.\n",
      "Incorrectly classified as  0.0258249\n",
      "\n",
      "78\n",
      "\n",
      "\"[27]\n",
      " The Demecratic Party's most important environmental concern is climate change.\n",
      "Incorrectly classified as  0.0222454\n",
      "\n",
      "81\n",
      "\n",
      "We believe that individuals with preexisting conditions who maintain continuous coverage should be protected from discrimination.\n",
      "Incorrectly classified as  0.974744\n",
      "\n",
      "83\n",
      "\n",
      "There is certainly a need to protect certain species threatened worldwide with extinction.\n",
      "Incorrectly classified as  0.971714\n",
      "\n",
      "90\n",
      "\n",
      "Alaska has been scorched by wildfire.\n",
      "Incorrectly classified as  0.0224644\n",
      "\n",
      "93\n",
      "\n",
      "We are deeply concerned that, in the face of genocide against them, Christian communities in cities like Erbil are receiving no financial support from either the U.S. government or the UN to help with displaced persons and urban refugees.\n",
      "Incorrectly classified as  0.974929\n",
      "\n",
      "94\n",
      "\n",
      "And we can have more economic fairness, so the rewards are shared broadly, not just with those at the top.\n",
      "Incorrectly classified as  0.06452\n",
      "\n",
      "96\n",
      "\n",
      "We oppose legislative attempts to modify the system of military justice that would undermine its fairness and due process rights for all concerned, both the accuser and the accused.\n",
      "Incorrectly classified as  0.957943\n",
      "\n",
      "99\n",
      "\n",
      "It also opposed using public revenues to promote abortions, to perform them, or to fund organizations that do either such things.\n",
      "Incorrectly classified as  0.973639\n",
      "\n",
      "102\n",
      "\n",
      "We encourage states to continue to fight this public menace and pledge our commitment to children’s safety and well-being.\n",
      "Incorrectly classified as  0.974889\n",
      "\n",
      "104\n",
      "\n",
      "It must mean aiding those who have suffered the most — and doing so before they starve.\n",
      "Incorrectly classified as  0.711437\n",
      "\n",
      "113\n",
      "\n",
      "A Republican administration will never say, as Hillary Clinton did as Secretary of State in 2009, that raising human rights concerns “can’t interfere with the global economic crisis, the global climate change crisis, and the security crisis.”\n",
      "\n",
      "The United States needs a radical rethinking of our human rights diplomacy.\n",
      "Incorrectly classified as  0.97495\n",
      "\n",
      "126\n",
      "\n",
      "Additionally, the next president must not sow seeds of division and distrust between the police and the people they have sworn to serve and protect.\n",
      "Incorrectly classified as  0.974908\n",
      "\n",
      "130\n",
      "\n",
      "To continue our headway against breast and prostate cancer, diabetes, and other killers, research must consider the needs of formerly neglected demographic groups.\n",
      "Incorrectly classified as  0.971067\n",
      "\n",
      "132\n",
      "\n",
      "Today they are the entrepreneurs, independent contractors, and small business men and women of our new economy.\n",
      "Incorrectly classified as  0.972739\n",
      "\n",
      "135\n",
      "\n",
      "We will audit the Pentagon, launch a high-level commission to review the role of defense contractors, and take greater action against those who have been involved in fraud.\n",
      "Incorrectly classified as  0.0237504\n",
      "\n",
      "137\n",
      "\n",
      "To make further progress, to advance a constitutional amendment for consideration by the states, we must expand the current Republican majorities in both chambers.\n",
      "Incorrectly classified as  0.548746\n",
      "\n",
      "138\n",
      "\n",
      "Charter schools must reflect their communities, and thus must accept and retain proportionate numbers of students of color, students with disabilities and English Language Learners in relation to their neighborhood public schools.\n",
      "Incorrectly classified as  0.129332\n",
      "\n",
      "140\n",
      "\n",
      "A major factor in the 40-year decline in the middle class is that the rights of workers to bargain collectively for better wages and benefits have been under attack at all levels.\n",
      "Incorrectly classified as  0.078293\n",
      "\n",
      "148\n",
      "\n",
      "States, not Washington bureaucrats, are best equipped to engage farmers and ranchers to develop sound farm oversight policies.\n",
      "Incorrectly classified as  0.943265\n",
      "\n",
      "159\n",
      "\n",
      "(Oct 2007)\r\n",
      "    Marriage is legal union of one man and one woman.\n",
      "Incorrectly classified as  0.843005\n",
      "\n",
      "165\n",
      "\n",
      "As the Party of Abraham Lincoln, we must continue to foster solutions to America’s difficult challenges when it comes to race relations today.\n",
      "Incorrectly classified as  0.97493\n",
      "\n",
      "166\n",
      "\n",
      "Republicans believe that the employer-employee relationship of the future will be built upon employee empowerment and workplace flexibility.\n",
      "Incorrectly classified as  0.974814\n",
      "\n",
      "167\n",
      "\n",
      "We urge every state to join the Interstate Voter Registration Cross Check Program to keep voter rolls accurate and to prevent people from voting in more than one state in the same election.\n",
      "Incorrectly classified as  0.974754\n",
      "\n",
      "174\n",
      "\n",
      "We therefore oppose the adoption or ratification of treaties that would weaken or encroach upon American sovereignty or that could be construed by courts to do so.\n",
      "Incorrectly classified as  0.866809\n",
      "\n",
      "180\n",
      "\n",
      "For example, the paleoconservative and social conservative factions would be far more inclined to favor federal drug regulations trumping states rights, while the libertarian faction would be more inclined to see such power devolved to the states or even further.\n",
      "Incorrectly classified as  0.920788\n",
      "\n",
      "182\n",
      "\n",
      "We should repeal the 3-year, 10-year and permanent bars, which often force persons in mixed status families into the heartbreaking dilemma of either pursuing a green card by leaving the country and their loved ones behind, or remaining in the shadows.\n",
      "Incorrectly classified as  0.0230555\n",
      "\n",
      "194\n",
      "\n",
      "[83]\n",
      " A May 2012 poll found that 37% of Republicans supported a constitutional amendment defining marriage between a man and a woman.\n",
      "Incorrectly classified as  0.965897\n",
      "\n",
      "203\n",
      "\n",
      "It has provided decades of stability and economic growth for the world and for America.\n",
      "Incorrectly classified as  0.0225444\n",
      "\n",
      "207\n",
      "\n",
      "Democrats believe that global institutions—most prominently the United Nations—and multilateral organizations have a powerful role to play and are an important amplifier of American strength and influence.\n",
      "Incorrectly classified as  0.0543039\n",
      "\n",
      "212\n",
      "\n",
      "For the people of Russia, we affirm our respect and our determination to maintain a friendship beyond the reach of those who wish to divide us.\n",
      "Incorrectly classified as  0.973157\n",
      "\n",
      "214\n",
      "\n",
      "freedom derived from economic opportunity).\n",
      "Incorrectly classified as  0.0751889\n",
      "\n",
      "215\n",
      "\n",
      "We acknowledge the past injustices and the misguided, harmful federal and state policies and actions based on outdated and discredited values and beliefs that resulted in the destruction of the Indian nations’ economies, social, and religious systems, the taking of their lands, and the creation of intergenerational trauma that exists to this day.\n",
      "Incorrectly classified as  0.0228365\n",
      "\n",
      "216\n",
      "\n",
      "Saving Social Security  (Top)\n",
      "\n",
      "We reject the old maxim that Social Security is the “Third Rail” of American politics, deadly for anyone who would change it.\n",
      "Incorrectly classified as  0.960499\n",
      "\n",
      "218\n",
      "\n",
      "We must impose firm caps on future debt, accelerate the repayment of the trillions we now owe in order to reaffirm our principles of responsible and limited government, and remove the burdens we are placing on future generations.\n",
      "Incorrectly classified as  0.974852\n",
      "\n",
      "223\n",
      "\n",
      "We urge states and community groups to help these young adults become independent.\n",
      "Incorrectly classified as  0.973725\n",
      "\n",
      "224\n",
      "\n",
      "[12] The party is generally split on the issue of how to deal with illegal immigration.\n",
      "Incorrectly classified as  0.966874\n",
      "\n",
      "237\n",
      "\n",
      "No wonder, then, that so much seems to be coming apart now.\n",
      "Incorrectly classified as  0.974395\n",
      "\n",
      "241\n",
      "\n",
      "A statehood amendment was soundly rejected by the states when last proposed in 1976 and should not be revived.\n",
      "Incorrectly classified as  0.973359\n",
      "\n",
      "245\n",
      "\n",
      "The regime is also responsible for grave human rights abuses against the North Korean people.\n",
      "Incorrectly classified as  0.0242989\n",
      "\n",
      "246\n",
      "\n",
      "Our working relationship is a necessary, though sometimes difficult, benefit to both, and we look toward the strengthening of historic ties that have frayed under the weight of international conflict.\n",
      "Incorrectly classified as  0.974659\n",
      "\n",
      "253\n",
      "\n",
      "We will fight to train and support this workforce, encourage providers to work with underserved populations through the National Health Service Corps, and create a comprehensive strategy to increase the pool of primary health care professionals.\n",
      "Incorrectly classified as  0.0353846\n",
      "\n",
      "263\n",
      "\n",
      "It has not limited risks, it has created more.\n",
      "Incorrectly classified as  0.964293\n",
      "\n",
      "279\n",
      "\n",
      "It will be the standard that applies to Wall Street and all Americans.\n",
      "Incorrectly classified as  0.0478759\n",
      "\n",
      "299\n",
      "\n",
      "In addition, our Workforce Innovation and Opportunity Act will make it easier for students with disabilities to pursue competitive employment.\n",
      "Incorrectly classified as  0.974075\n",
      "\n",
      "300\n",
      "\n",
      "(Sep 2012)\r\n",
      "    Knock down barriers to free, fair and balanced trade.\n",
      "Incorrectly classified as  0.0811358\n",
      "\n",
      "302\n",
      "\n",
      "[104] The party stresses the common interests of the two countries, which include ending terrorism, combating nuclear proliferation, promoting bilateral trade.\n",
      "Incorrectly classified as  0.970765\n",
      "\n",
      "311\n",
      "\n",
      "Republicans also believe that limits on eligibility and benefits must be in place to ensure that the safety net is not abused.\n",
      "Incorrectly classified as  0.971201\n",
      "\n",
      "313\n",
      "\n",
      "We intend to finish that pipeline and others as part of our commitment to North American energy security.\n",
      "Incorrectly classified as  0.974242\n",
      "\n",
      "319\n",
      "\n",
      "(Jun 2016)\r\n",
      "Rebuilding the Economy and Creating Jobs  (Top)\n",
      "\n",
      "We are the party of a growing economy that gives everyone a chance in life, an opportunity to learn, work, and realize the prosperity freedom makes possible.\n",
      "Incorrectly classified as  0.963289\n",
      "\n",
      "320\n",
      "\n",
      "We welcome students, tourists, and investors, who can see for themselves our vibrant American democracy and how real democracy works.\n",
      "Incorrectly classified as  0.964355\n",
      "\n",
      "322\n",
      "\n",
      "Our most urgent task as a Party is to restore\n",
      "\n",
      "the American people’s faith in their government by electing a president who will enforce duly enacted laws, honor constitutional limits on executive authority, and return credibility to the Oval Office.\n",
      "Incorrectly classified as  0.930366\n",
      "\n",
      "328\n",
      "\n",
      "We recognize the value of data in allowing us to count and carefully consider the needs of different communities.\n",
      "Incorrectly classified as  0.0361395\n",
      "\n",
      "334\n",
      "\n",
      "A Republican administration will strategize with partners around the world to prevent the demand for trafficking victims that makes exploitation lucrative and will prosecute sex tourists and domestic buyers to the fullest extent of the law.\n",
      "Incorrectly classified as  0.967598\n",
      "\n",
      "338\n",
      "\n",
      "(Sep 2012)\r\n",
      "    Lead the world by telling truth to our troops & our citizens.\n",
      "Incorrectly classified as  0.0837181\n",
      "\n",
      "345\n",
      "\n",
      "Americans overseas should enjoy the same rights as Americans residing in the United States, whose private financial information is not subject to disclosure to the government except as to interest earned.\n",
      "Incorrectly classified as  0.943732\n",
      "\n",
      "356\n",
      "\n",
      "This will reduce America’s vulnerability to energy price volatility.\n",
      "Incorrectly classified as  0.885132\n",
      "\n",
      "361\n",
      "\n",
      "[43] Since 2008,[44] many members of the Republican Party have been criticized for being anti-environmentalist[45][46][47] and promoting climate change denial[48][49][50] in opposition to the general scientific consensus, making them unique even among other worldwide conservative parties.\n",
      "Incorrectly classified as  0.97462\n",
      "\n",
      "367\n",
      "\n",
      "We will do away with it altogether.\n",
      "Incorrectly classified as  0.820145\n",
      "\n",
      "371\n",
      "\n",
      "The Democratic Party is extreme on abortion.\n",
      "Incorrectly classified as  0.972077\n",
      "\n",
      "382\n",
      "\n",
      "That is why the Fifth \n",
      "\n",
      "Amendment declares that private property may not be “taken for public use without just compensation.” The Supreme Court’s Kelo decision undermined this safeguard by allowing local governments to seize a person’s home or land not only for vital public use, but also for “public purpose,” which thus allowed the government to seize it for transfer to private developers or other private entities.\n",
      "Incorrectly classified as  0.960217\n",
      "\n",
      "395\n",
      "\n",
      "America has a sacred trust with our veterans, and we are committed to ensuring them  and their families’ care and dignity.\n",
      "Incorrectly classified as  0.974819\n",
      "\n",
      "400\n",
      "\n",
      "Today, everything has changed.\n",
      "Incorrectly classified as  0.288083\n",
      "\n",
      "401\n",
      "\n",
      "They call for slashes in student loan debt and support reforms to force down tuition fees.\n",
      "Incorrectly classified as  0.022593\n",
      "\n",
      "406\n",
      "\n",
      "That hurts rural America, where farmers, ranchers, and small business people need connectivity to operate in real time with the world’s producers.\n",
      "Incorrectly classified as  0.97169\n",
      "\n",
      "410\n",
      "\n",
      "Like all Americans, American Indians want safe communities for their families; but inadequate resources and neglect have, over time, allowed criminal activities to plague Indian country.\n",
      "Incorrectly classified as  0.974683\n",
      "\n",
      "414\n",
      "\n",
      "Therefore, we recommend a permanent line item for National Guard affairs, one that is not eliminated by the President and reinstated by Congress.\n",
      "Incorrectly classified as  0.973769\n",
      "\n",
      "418\n",
      "\n",
      "We will end the government’s use of disparate impact theory in enforcing anti-discrimination laws with regard to lending.\n",
      "Incorrectly classified as  0.873387\n",
      "\n",
      "419\n",
      "\n",
      "This decision ensures that those families will remain needy and cut off from the economic mainstream of American society.\n",
      "Incorrectly classified as  0.974764\n",
      "\n",
      "421\n",
      "\n",
      "And we will bar financial service regulators from lobbying their former colleagues for at least two years.\n",
      "Incorrectly classified as  0.0628354\n",
      "\n",
      "432\n",
      "\n",
      "The Republican Party, a party of law and order, must make clear in words and action that every human life matters.\n",
      "Incorrectly classified as  0.972447\n",
      "\n",
      "439\n",
      "\n",
      "Also neglected are our strategic forces, especially the development and deployment of ballistic missile defenses.\n",
      "Incorrectly classified as  0.974398\n",
      "\n",
      "443\n",
      "\n",
      "(Oct 2007)\r\n",
      "    Marriage is legal union of one man and one woman.\n",
      "Incorrectly classified as  0.843005\n",
      "\n",
      "450\n",
      "\n",
      "The results are damning: intergenerational poverty has persisted and worsened since 1966.\n",
      "Incorrectly classified as  0.95009\n",
      "\n",
      "453\n",
      "\n",
      "Africa is home to many of the fastest growing economies in the world.\n",
      "Incorrectly classified as  0.10217\n",
      "\n",
      "458\n",
      "\n",
      "(Aug 2000)\r\n",
      " Invest in stem cell and other medical research.\n",
      "Incorrectly classified as  0.118215\n",
      "\n",
      "464\n",
      "\n",
      "That is why the Fifth \n",
      "\n",
      "Amendment declares that private property may not be “taken for public use without just compensation.” The Supreme Court’s Kelo decision undermined this safeguard by allowing local governments to seize a person’s home or land not only for vital public use, but also for “public purpose,” which thus allowed the government to seize it for transfer to private developers or other private entities.\n",
      "Incorrectly classified as  0.960217\n",
      "\n",
      "466\n",
      "\n",
      "We further recognize the historic significance of the 2012 local referendum in which a 54 percent majority voted to end Puerto Rico's current status as a U.S. territory, and 61 percent chose statehood over options for sovereign nationhood.\n",
      "Incorrectly classified as  0.974494\n",
      "\n",
      "471\n",
      "\n",
      "It is the solemn compact built upon principles of the Declaration that enshrines our God-given individual rights and ensures that all Americans stand equal before the law, defines the purposes and limits of government, and is the blueprint for ordered liberty that makes the United States the world’s freest and most prosperous nation.\n",
      "Incorrectly classified as  0.846265\n",
      "\n",
      "472\n",
      "\n",
      "We also believe that Native children are the future of tribal nations and that the Indian Child Welfare Act is critical to the survival of Indian culture, government, and communities and must be enforced with the statutory intent of the law.\n",
      "Incorrectly classified as  0.278663\n",
      "\n",
      "489\n",
      "\n",
      "Left unchecked, it will hit $30 trillion by 2026.\n",
      "Incorrectly classified as  0.764013\n",
      "\n",
      "495\n",
      "\n",
      "Building the Future: Technology  (Top)\n",
      "\n",
      "The digital revolution has transformed how we work, learn, sell, shop, socialize — in short, how we live.\n",
      "Incorrectly classified as  0.972948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for val in incorrect:\n",
    "    print(val)\n",
    "    idx = val\n",
    "    text = X_test_text[idx]\n",
    "    print()\n",
    "    print(text)\n",
    "    print(\"Incorrectly classified as \",y_pred[idx])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Data\n",
    "\n",
    "Now let's try and classify new statements. Some will be obvious, while others should be consfusing.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text1 = \"Climate change is the most important issue to address.\"\n",
    "text2 = \"We need a safer form of gun control.\"\n",
    "text3 = \"Obamacare is bad\"\n",
    "text4 = \"Our welfare system is broken\"\n",
    "text5 = \"The wealthy need to pay their fair share in taxes.\"\n",
    "text6 = \"Roe v Wade must be overturned.\"\n",
    "text7 = \"Make America Great Again\"\n",
    "text8 =  \"Israel is our greatest ally.\"  #inherently ambiguous (I hope!)\n",
    "text9 = \"I love russia.\"\n",
    "texts = [text1, text2, text3, text4, text5, text6, text7, text8,text9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens = tokenizer.texts_to_sequences(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 40)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tokens_pad = pad_sequences(tokens, maxlen=max_tokens,\n",
    "                           padding=pad, truncating=pad)\n",
    "tokens_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03666094],\n",
       "       [ 0.96099228],\n",
       "       [ 0.02572565],\n",
       "       [ 0.08876403],\n",
       "       [ 0.9571901 ],\n",
       "       [ 0.02362171],\n",
       "       [ 0.95581186],\n",
       "       [ 0.48675978],\n",
       "       [ 0.03998385]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(tokens_pad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now recreating that prediction method with a raw input for a more direct approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obamacare\n",
      "Republican\n"
     ]
    }
   ],
   "source": [
    "text = [input()]\n",
    "tokens = tokenizer.texts_to_sequences(text)\n",
    "tokens_pad = pad_sequences(tokens, maxlen=max_tokens,\n",
    "                           padding=pad, truncating=pad)\n",
    "\n",
    "x = model.predict(tokens_pad)\n",
    "if x[0][0] < .5:\n",
    "    print(\"Republican\")\n",
    "else:\n",
    "    print(\"Democrat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if x[0][0] < .5:\n",
    "    print(\"Republican\")\n",
    "else:\n",
    "    print(\"Democrat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qualitatively speaking, this model gueses 6 out of 7, not bad! The democratic ones that serve as the first two are the one's misclassified, and maybe this says something about their policy..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Exploration\n",
    "\n",
    "\n",
    "One perk of the embedding layer is that during the training period, it semantically maps the meaning of different words based on their classification, relative place in the sequence, etc. Certain terms will end up being more meaningful ot the message, while others are not (like stop words, 'and', the',etc.)\n",
    "\n",
    "\n",
    "By retreiving the embedding layer, we can explore these embeddings and have a little peek under the hood as to what this model has learned about politics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the layer from the model\n",
    "layer_embedding = model.get_layer('layer_embedding')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 10)\n"
     ]
    }
   ],
   "source": [
    "#get the weights from that layer. \n",
    "weights_embedding = layer_embedding.get_weights()[0]\n",
    "print(weights_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, vec, in enumerate(weights_embedding):\n",
    "    #convert to word\n",
    "    tokenizer.word_index\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously we said that the vec would have 8 dimensions, so this is consistent with those findings here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ex what is the \n",
    "token_good = tokenizer.word_index['good']\n",
    "token_good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "510"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_great = tokenizer.word_index['great']\n",
    "token_great"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.4825162 ,  0.3311922 ,  0.64928097,  0.87284219,  0.24644057,\n",
       "        0.76803237,  0.47215921,  0.42661455,  0.27512088,  0.05215252], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_embedding[token_good]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.49037293,  0.92012733,  0.5688715 ,  0.78711706,  0.28240907,\n",
       "        0.60960138,  0.57438099,  0.47182074,  0.77179307,  0.7913934 ], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_embedding[token_great]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since these words are similar, we'd expect their embeddings to be close (speaking from displacement meaning) We see that in some of these dimensions, that is the case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting\n",
    "\n",
    "Using this helper function, find the distances between every word and sort.\n",
    "\n",
    "\n",
    "\n",
    "# There is an issue with this function where the index goes beyond what I have originally set. Seems this won't work (yet). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_sorted_words(word, metric='cosine'):\n",
    "    \"\"\"\n",
    "    Print the words in the vocabulary sorted according to their\n",
    "    embedding-distance to the given word.\n",
    "    Different metrics can be used, e.g. 'cosine' or 'euclidean'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the token (i.e. integer ID) for the given word.\n",
    "    token = tokenizer.word_index[word]\n",
    "\n",
    "    # Get the embedding for the given word. Note that the\n",
    "    # embedding-weight-matrix is indexed by the word-tokens\n",
    "    # which are integer IDs.\n",
    "    embedding = weights_embedding[token]\n",
    "\n",
    "    # Calculate the distance between the embeddings for\n",
    "    # this word and all other words in the vocabulary.\n",
    "    distances = cdist(weights_embedding, [embedding],\n",
    "                      metric=metric).T[0]\n",
    "    \n",
    "    # Get an index sorted according to the embedding-distances.\n",
    "    # These are the tokens (integer IDs) for words in the vocabulary.\n",
    "    sorted_index = np.argsort(distances)\n",
    "    \n",
    "    # Sort the embedding-distances.\n",
    "    sorted_distances = distances[sorted_index]\n",
    "    \n",
    "    # Sort all the words in the vocabulary according to their\n",
    "    # embedding-distance. This is a bit excessive because we\n",
    "    # will only print the top and bottom words.\n",
    "    sorted_words = [inverse_map[token] for token in sorted_index\n",
    "                  if token != 0]\n",
    "    # Helper-function for printing words and embedding-distances.\n",
    "    def _print_words(words, distances):\n",
    "        for word, distance in zip(words, distances):\n",
    "            print(\"{0:.3f} - {1}\".format(distance, word))\n",
    "\n",
    "    # Number of words to print from the top and bottom of the list.\n",
    "    k = 10\n",
    "\n",
    "    print(\"Distance from '{0}':\".format(word))\n",
    "\n",
    "    # Print the words with smallest embedding-distance.\n",
    "    _print_words(sorted_words[1:k+1], sorted_distances[1:k+1])\n",
    "\n",
    "    print(\"...\")\n",
    "\n",
    "    # Print the words with highest embedding-distance.\n",
    "    _print_words(sorted_words[-k:], sorted_distances[-k:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance from 'guns':\n",
      "0.014 - proposed\n",
      "0.026 - injustice\n",
      "0.026 - affect\n",
      "0.026 - crumbling\n",
      "0.028 - 200\n",
      "0.029 - speculation\n",
      "0.032 - permanent\n",
      "0.035 - congestion\n",
      "0.036 - races\n",
      "0.036 - seriousness\n",
      "...\n",
      "0.531 - expensive\n",
      "0.533 - spreads\n",
      "0.539 - criminal\n",
      "0.542 - prices\n",
      "0.549 - oil\n",
      "0.580 - venture\n",
      "0.582 - jun\n",
      "0.596 - sized\n",
      "0.602 - prominently\n",
      "0.658 - choices\n"
     ]
    }
   ],
   "source": [
    "print_sorted_words('guns', metric='cosine')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# New Idea: I've downloaded Josh Gottheimer's stances on the issues, now tokenize and model this to predict each statement, looking at the strongest ones on each as proof."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 'gottissues.txt'...\n"
     ]
    }
   ],
   "source": [
    "#open the text file and \n",
    "gottheimer_raw = u\"\"\n",
    "print(\"Reading '{0}'...\".format('gottissues.txt'))\n",
    "with codecs.open('gottissues.txt', \"r\", \"utf-8\") as book_file:\n",
    "    gottheimer_raw += book_file.read()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WORKING FOR YOU!\\nIn Congress, I’m laser-focused on getting things done for our families and for our children. When I got there, I quickly noticed that the extreme partisanship and gridlock were even worse than any of us could have imagined. However, I also found that from day one, if you actually made an effort to reach across the aisle, to find common ground, you could actually get things done that are good for the country and for New Jersey.\\n\\nEarly last year, I was elected Co-Chair of the bipartisan Problem Solvers Caucus. It’s a group of 24 Democrats and 24 Republicans who meet every week to see where we can make progress on our toughest issues, from lowering taxes, to creating jobs, to fixing our infrastructure, to balancing the budget. Just like when I was at Ford Motor Company and Microsoft, my goal is to bring people together to get something done. I was honored to be recognized as the most bipartisan freshman Democrat in Congress. For me, it’s not about a partisan agenda; it’s about working with both sides for what’s best for New Jersey. It’s about our shared values – our Jersey Values.\\n\\nWhat does that mean? We need lower taxes, less red tape, balanced budgets, and we must reinstitute the State and Local Tax Deduction (SALT) that was gutted by the federal Tax Hike Bill. We must claw more of our federal tax dollars back home, instead of continuing to prop up those Moocher States who take so much more than they give. We must also fight for clean drinking water, top-notch schools and STEM education for our children, and investment in our roads, bridges, and tunnels – so we can cut down on our commutes and attract new and keep our businesses.I will always stand by our seniors, veterans, and first responders, so our families are safe from crime and terror at home and around the world.\\n\\nThe bottom line: I work for Jersey, not some national political party. We are always stronger when we work together and remember that our best days are ahead of us.\\n\\nCutting Taxes and Clawing Back our Federal Tax Dollars\\nBefore I took office, our District had one of the worst returns on the tax dollars we sent to Washington – just $0.33 for every dollar. Our hard-earned money has instead been going to prop up Moocher States like Mississippi and Alabama that get back as much as $4.38 per dollar. That’s a raw deal and it means that making up the gap falls upon the shoulders of our towns and taxpayers.\\n\\nSo, when Congress passed a Tax Hike Bill that slammed our state and raised taxes on a majority of our residents and businesses, I fought back for Jersey. I’m also not going to stand idly by when so much damage is being done to our state. This massive tax hike on New Jersey is already driving property values down and sending businesses and jobs to other states.\\n\\nLast December, I introduced a Jersey Tax Cut Plan to restore the value of the State and Local Tax Deduction (SALT). Our plan gives New Jersey taxpayers a tax cut by allowing them to donate to new charitable funds set up by their towns. In just four months, Democrats and Republicans came together to pass our plan and it was signed into law. I’m now working to make sure this plan – which is supported by our nation’s tax scholars and consistent with legal precedent and IRS rulings – can be quickly implemented in our towns to provide much needed tax relief.\\n\\nOur Jersey Tax Cut Plan is just one way I’m fighting back against the Moocher States and working to cut taxes for our families and our businesses. We must eliminate wasteful spending, balance budgets, and cut taxes, at every level – and I’ve made that my top priority. When I took office, I also quickly got to work with our mayors and local officials to claw back more of the tax dollars that we have already sent to Washington. Working together, we’re getting results – winning back 16% more than in recent years. That’s $290 per family to help our towns lower their property taxes, fix our infrastructure, protect our students in their schools, respond quickly to storms, and provide essential equipment our first responders need to fight crime and terror.\\n\\nThere’s nothing partisan about getting our families a better return on their investment. Whether it’s cutting taxes or clawing back our hard-earned money, I will keep fighting to make our District more affordable for our families and more attractive for businesses to invest and create jobs.\\n\\nBringing New Businesses and Jobs to the District\\nHere in North Jersey, we have some of the best schools and brightest minds who call our communities home. Many of the top life science companies are based in our state and we have some of the fastest broadband in the country – which is why the whole back-end of the New York Stock Exchange sits in Bergen County. The question is: How can we maximize these assets to create good-paying job and strengthen our economy?\\n\\nThat’s why, as part of my Five-Point Economic Growth Plan, I’m working across the aisle to help create jobs, draw, keep and expand businesses in northern New Jersey, lower taxes, cut red tape, and eliminate outdated, burdensome regulations. I’ve also fought to secure bipartisan funding for the Gateway Program and other essential investments to fix our transit, roads, bridges, and infrastructure to boost economic growth. Ultimately, harnessing our potential is about creating the conditions where innovative businesses can thrive and stay here to create good-paying jobs for our residents.\\n\\nFor my pro-business work across the aisle to help New Jersey, I was honored to receive the U.S. Chamber of Commerce’s “Spirit of Enterprise” Award. I have partnered with chapters across our District and the New Jersey Chamber of Commerce President Tom Bracken noted that I am, “fighting for us every day.” I will continue to work to lower taxes and help businesses of all sizes stay and grow in New Jersey by making the state we love more affordable.\\n\\nFixing Our Roads, Bridges, Tunnels and Trains\\nNew Jersey is second in the nation among states with commuters who rely on public transit. Meanwhile, one-third of New Jersey’s bridges are considered unsafe for travel and NJ Transit had more accidents in 2016 than any of the 10 largest commuter railroads in the country.\\n\\nWith the safety of our families at stake, there’s no room for partisan games. My first stand-alone bill to pass the House, the FRA Safety Data Improvement Act, strengthens our data collection so that we can uncover potential safety problems on our rails before they can do harm or cost lives.\\n\\nSafety has to be our top priority, but we also know that we can’t attract new businesses and jobs to a state where our roads, tunnels and bridges are crumbling. That’s why I’ve fought to secure bipartisan funding for the Gateway Project, which would double our rail capacity into New York City. Right now, only twenty-one trains can travel in and out of the city in an hour because we have one tunnel – that’s more than a hundred years old and in massive disrepair – along this corridor that one-fifth of America’s economy relies upon. Moving this project forward couldn’t be more vital to our region and our nation’s economy.\\n\\nI’ve also worked to bring new bus and rail service to our communities in Sussex and Warren and we need to bring light rail to Bergen County to ease our commute within our District. Fixing our infrastructure isn’t just essential to our economic future. Most importantly, it allows us to get home earlier to spend more time with our families and tuck our kids into bed.\\n\\nStanding Strong Against Terror, Standing by Our Veterans and First Responders\\nIn New Jersey, we know all too well about the threat of homegrown, Lone-Wolf terror, and that we must always be vigilant at home and in the war on terror – against ISIS, Al-Qaeda, Hamas, and other terrorist groups around the world. We need to make certain our cops, first responders, and military have the tools they need to protect our families and to prevent terrorists from following through on their threats, both foreign and domestic. There is no room for compromise against terror and Americans must present in a united front, coming together as Democrats and Republicans, for our national security. We owe that to all Americans and to the brave men and women, who have risked their lives to protect our freedoms.\\n\\nIn the aftermath of the tragic terror attack in New York City last October, where a rented pickup truck was used to kill eight people, including Darren Drake, a resident of New Milford, New Jersey, I was proud to work with Darren’s father Jimmy to develop a plan to prevent future ISIS-inspired Lone-Wolf attacks. Named in memory of Darren, TheDarren Drake Combatting 21st Century Weapons of Terror Act is essential to help keep us safe against these new, emerging threats.\\n\\nLast year, I also introduced the bipartisan Freezing Assets of Suspected Terrorists and Enemy Recruits (FASTER) Act to give law enforcement the tools that they need to combat domestic terrorism, especially Lone-Wolf attacks in our backyard. We must make sure that our law enforcement agencies have the training, information, and cutting-edge resources necessary to protect our communities.\\n\\nI will always have the backs of the brave cops that keep our families safe across North Jersey. For my work in Congress and at home to support law enforcement, I was received a perfect rating on a recent scorecard from the National Association of Police Organizations (NAPO), which includes police from across our state and the New Jersey State PBA.\\n\\nI’m also working to honor our commitment to our military, veterans, and first responders who put their lives on the line every day by ensuring that they have the best possible care, when they serve and after. I am committed to helping New Jersey veterans cut through the red tape and bureaucratic hurdles whether it relates to their benefits, health care, a VA home loan, or overdue medals. I’m proud that the very first measure of mine to become law was to help our veterans get jobs when they return home and makes it easier for these courageous men and women to get care in the District.\\n\\nCivil Rights and Equality\\nAs I learned growing up, we were all created in the image of God. I believe that everyone should be treated equally no matter what their background, race, sexual orientation, or station in life. We will only succeed as a nation if everyone is included and treated with respect and dignity. It’s what built America and allowed our economy and culture to flourish.\\n\\nAs a member of the Congressional LGBTQ Equality Caucus, I’ve fought to extend protections for the LGBTQ community. Last year, I proudly introduced the Freedom from Discrimination in Credit Act (FDCA), a bipartisan bill to prohibit credit discrimination based on sexual orientation and gender identity.\\n\\nI’m also fighting to defend the hard-won victories enshrined in the Voting Rights Act and working towards prison reform for nonviolent offenders, an area with great bipartisan support that will save taxpayers money.\\n\\nProtecting Medicare & Social Security\\nOur seniors shouldn’t have to worry that their Social Security checks, which they worked hard for, will always clear and that Medicare will be available to them. I’m fighting to protect and strengthen these essential programs for future generations and will always oppose any attempt to privatize them or cut benefits. In Congress, I’ve strongly opposed attempts to reduce the cost-of-living adjustment and access to Social Security, and voted against a budget plan that would have ended Medicare as we know it.\\n\\nWe also have to do more for our greatest generation and for our residents who are approaching retirement age. With my Three-Part Senior Security Strategy, my goal is to make it more affordable for seniors to stay in Jersey and enjoy their retirement here with their families. First, I’m working to cut taxes and help seniors save more of their hard-earned money during their golden years by co-sponsoring a bipartisan bill to finally put an end to the double taxation of Social Security benefits. The second part of our plan is working to pass a bipartisan bill to prevent this income from being garnished by debt collectors. Third, I’m fighting to protect seniors’ pocketbooks against the onslaught of aggressive Medicare scammers. Social Security and Medicare are the foundation of our retirement security; they should be a guarantee – not a gamble or put at risk in any way.\\n\\nLast but not least, I introduced the bipartisan Senior Housing Improvement and Retirement Accounts (IRA) Act, to give seniors the opportunity to save money so they can stay right here in New Jersey. My legislation cuts taxes for seniors if they sell their home and use a Roth IRA for retirement savings. New Jersey seniors are moving away because they cannot afford to stay, which is why I introduced this common-sense plan to help them save and stay in the Garden State.\\n\\nSafeguarding our Children’s Drinking Water\\nLike all parents, I’m deeply concerned about the health and safety of our children. Yet, despite the quality of the education offered in our schools, we haven’t been so sure about the quality of the water that flows out of our school’s water fountains, faucets or pipes, many of them generations old. We’ve all see the headlines about elevated lead levels in the water at our schools – and no mother or father should have to worry about whether the water their child drinks contains lead or other toxic chemicals.\\n\\nThat’s why I announced a Clean Water for Kids Plan, urging the state to improve reporting about the testing being done at our kids’ schools and to make it accessible to the public so that parents know exactly what’s in the water their kids might drink. We can’t solve this problem if we don’t know exactly what it is. I’ve also called for the Governor to strengthen efforts to keep our water lead-free in a comprehensive plan to get to the bottom of this problem and protect our children’s health and safety.\\n\\nIf we’re going to get lead out of our school drinking water once and for all, our schools will need better resources for testing, remediation and reporting. Last year, I introduced The Lead-Free Schools Act – a bipartisan bill that requires testing for lead in our schools, empowers parents by improving transparency and creates a pilot program to help schools replace out-of-date infrastructure like lead-tainted water fountains. This bill will also claw back some of the federal tax dollars we are already sending to Washington to help secure the health and safety of our children. Under my bipartisan plan, parents have the transparency they want, schools can invest in lead-free water, and our kids will be safe.\\n\\nBuilding Strong Families\\nWe live in a time where three women currently sit on the Supreme Court, women occupy twenty percent of all congressional seats, and scores sit in America’s boardrooms. The sky should be the limit for all of our sons and our daughters.\\n\\nAs I said in my very first speech on the floor of Congress, I unequivocally fight any attempt to get between a woman and her doctor when it comes to making personal health care choices. I also believe women should have access to affordable health care services around the country.\\n\\nWe need to expand opportunities for women in business. Last year, I proudly cosponsored the Paycheck Fairness Act to ensure that women receive equal pay for equal work.\\n\\nWe must also support families by providing new parents with sensible family leave and quality, affordable childcare. We should also invest in stem cell research and ensure that the National Institutes of Health continue to fund ground-breaking research in cancer, autism, and other diseases.\\n\\nInvest in Education, STEM, College Affordability\\nOur District has the best K-12 schools in the country but we can’t afford to take our eye off the ball. We must aggressively push forward and ensure that our children are given every opportunity to succeed in the global, digital economy. At Microsoft, I saw first-hand how few engineers and computer programmers our country produces; we simply aren’t graduating enough of them. And, given our immigration policies, many of the engineers who graduate from our colleges can’t stay here. The result is a huge skills gap – one I’m fighting hard to close.\\n\\nI support integrating education technology in the classroom and programs that greatly emphasize Science, Technology, Engineering, Arts and Math (STEAM), skills that are increasingly necessary for children who will enter the workforce in the coming decades. I am also exploring ways to help our local business community partner with our schools so that students get the training they need to build successful careers.\\n\\nProviding our children with a STEAM education will make our District an attractive location for companies from the technology industry and position our children to compete for the high paying jobs of the future. Meanwhile, what we do now to help our technology industry grow is of critical importance when it comes to Northern New Jersey’s economic future. In fact, studies have shown that over time each high-tech job creates about five jobs outside of tech (two professional and three nonprofessional). In Congress, I supported the Strengthening Career and Technical Education for the 21st Century Act, to boost the efficiency of the training programs that we already have on the books so they actually achieve their job training goals. I am working to claw back those resources to help in our District and state.\\n\\nBeyond job training, we also must take steps to make college more affordable. The costs of college tuition have skyrocketed 80 percent in the last decade. Seven in ten college graduates have an average debt of more than $35,000, and only 59 percent of students seeking a bachelor’s degree actually finish. We need to incentivize college completion, for both students and colleges, better match college training with employer needs, and address the runaway costs.\\n\\nIsrael\\nI unequivocally support the strength, safety, and prosperity of Israel. I am working with Democrats and Republicans to strengthen the U.S.-Israel partnership as our strongest ally. Knowing of the challenges we both face, I want to enhance this alliance by working tirelessly towards greater economic, diplomatic, cultural, and defense exchanges between Israel and the United States.\\n\\nIsrael’s commitment to freedom of expression and religion, and democratic values is unprecedented across the globe, across history, and especially across the Middle East. This is precisely why Israel is, and must remain, our closest ally. It is also why I believe so strongly that Israel cannot be used as partisan football and instead must maintain strong, bipartisan support. In Congress, I am working for a stronger partnership to stop dangerous terrorist financing, invest in robust missile defense, and increase technology exchanges between Israel and the United States. I believe we must do everything in our power to support the strength, safety, and prosperity of Israel – including fight back against biased attacks and those who wish to harm our vital partner. That’s why, last year, I introduced a bipartisan bill to help state and local governments fight back against the politically-motivated boycott of Israel. That’s also why, since 2015, I’ve strongly opposed the Iran Deal that failed to permanently prevent Tehran from developing a nuclear bomb or addressed the aggressive development of long-range ballistic missiles to carry these weapons.\\n\\nThere should be nothing partisan about protecting our national security and defending our vital ally, Israel.\\n'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gottheimer_raw  #now convert !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "gottheimer_text = gottheimer_raw.split('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From what I can tell, this data needs to already be in the corpus prior to testing. This means re-running the model every time you grab one of these text files. I need a robust scraper that immediately gets all the text including this one, but keeping them in separate directories until testing later. This is especially because this prediction data is not labelled. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the blank spaces correspond to words not in original corpus... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "gottheimer_tokens = tokenizer.texts_to_sequences(gottheimer_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "gottheimer_tokens_pad = pad_sequences(gottheimer_tokens, maxlen=max_tokens,\n",
    "                            padding=pad, truncating=pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(gottheimer_tokens_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = 0\n",
    "for result in results:\n",
    "    if result > .5:\n",
    "        x+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "105 of the len(results)= 135 statements are democratic, meaning this is a democratic candidate (probably )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now to repeat this testing this with a republican candidate, for reproducibility, I'll stick with Gott's competitor, John Mcann\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 'mcissues.txt'...\n"
     ]
    }
   ],
   "source": [
    "#open the text file and \n",
    "mcann_raw = u\"\"\n",
    "print(\"Reading '{0}'...\".format('mcissues.txt'))\n",
    "with codecs.open('mcissues.txt', \"r\", \"utf-8\") as book_file:\n",
    "    mcann_raw += book_file.read()\n",
    "\n",
    "\n",
    "mcann_text = mcann_raw.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcann_tokens = tokenizer.texts_to_sequences(mcann_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mcann_tokens_pad = pad_sequences(mcann_tokens, maxlen=max_tokens,\n",
    "                            padding=pad, truncating=pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = model.predict(mcann_tokens_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = 0\n",
    "for result in results:\n",
    "    if result > .5:\n",
    "        x+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Too many Americans are unemployed, underemployed or working undesirable jobs',\n",
       " '\\n\\nThat’s why I’m running for Congress',\n",
       " '\\n\\nTaxes\\n\\nI will work to make the tax code more favorable to small businesses which are the backbone of the nation’s economy',\n",
       " ' It’s time that Congress put Main Street before Wall Street',\n",
       " '\\n\\nSince historic tax cuts passed, New Jersey residents are concerned about the elimination of the SALT (state and local tax) deduction',\n",
       " ' Elect me to Congress and I will work to fix this pertinent concern',\n",
       " '\\n\\nTrade\\n\\nWe’ve all heard the arguments for free and fair trade',\n",
       " ' Like the President, I am for America First trade',\n",
       " ' We need to reevaluate trade deals to see what benefits America first',\n",
       " '\\n\\nWe’ve been taken advantage of too often on the world stage—while your jobs have been shipped off to other countries',\n",
       " '\\n\\nAs your Congressman I will never vote for a bill that guts American jobs and creates a negative trade balance',\n",
       " ' All trade deals need to protect jobs, grow the economy, and forge good diplomatic relations around the world',\n",
       " '\\n\\nAs Americans, we are proud of our rich immigrant history and understand the need to reform immigration law',\n",
       " ' But New Jersey Governor Phil Murphy plans to make New Jersey a Sanctuary State for illegal immigrants—handcuffing law enforcement from working with federal immigration officials to arrest illegal immigrants convicted of VIOLENT CRIMES living in our communities',\n",
       " '\\n\\nHow could the Democrats be so irresponsible? Sanctuary City laws endanger our communities, and I will not stand by as politicians posture for reelection risking you and your loved ones’ lives',\n",
       " ' Our incredible state cannot be a sanctuary for violent criminals',\n",
       " '\\n\\nProud of my immigrant heritage, I will lead the fight in Congress to protect our families by:\\n\\nStopping the liberal Democrats in the D',\n",
       " 'C',\n",
       " ' and NJ swamps from blocking our President’s commonsense plan to fight illegal immigration',\n",
       " '\\nWorking to secure the border and ports of entry',\n",
       " '\\nBlocking terrorists, gangs, and drugs from entering this country',\n",
       " '\\nVoting to end the Diversity Visa Lottery and Chain Migration',\n",
       " '\\nWorking to create Merit-Based immigration so we’re only taking in the best and brightest from around the world',\n",
       " '\\nSecuring our border and protecting Americans shouldn’t come down to partisan politics',\n",
       " ' It is our government’s primary job to protect Americans but the elites have been failing us, year after year',\n",
       " '\\n\\nLet’s elect someone who will finally fight to protect all of our country’s citizens',\n",
       " '\\n\\n\\nIn the 1990s when Hillarycare (the precursor to Obamacare) was being prepped to pass, I worked as a young staff member in the United States Senate to expose Hillarycare as a fraud perpetrated on the American people',\n",
       " '\\n\\nAs a business owner, I’m committed to bringing a market-based approach to healthcare',\n",
       " '\\n\\nYou need better access to the doctors of your choice',\n",
       " '\\n\\nYou need better care for whatever health challenges you face',\n",
       " '\\n\\nYou need to be unburdened from crippling insurance rates',\n",
       " '\\n\\nAs your Congressman, I will finish the job of repealing and replacing Obamacare with a market-based approach that improves access to quality, affordable healthcare',\n",
       " ' I will also fight the current deathgrip Big Pharma has on D',\n",
       " 'C',\n",
       " ' politicians and will work to drive down costs and drive up care',\n",
       " '\\n\\nLet’s bring back medical freedom so you can get about living',\n",
       " '\\n\\nFrom the Desk of Paul Brubaker\\n\\nDear fellow American:\\n\\nMy name is Paul Brubaker and I’m writing to you today to tell you about a moment in history that occurred on the floor of the United States Senate back in summer of 1994; back when Hilary Clinton attempted, for the first time, to take over our healthcare system and the pivotal role John McCann played, who is your candidate for Congress in the 5th District of New Jersey',\n",
       " ' I know all about this because I was there',\n",
       " '  \\n\\nBack in 1994, I was the Republican Staff Director for the Senate Sub Committee on Oversight of Government Management',\n",
       " ' At that time the Democrats had complete control of our government and the Republicans had not controlled the House of Representatives for over 40 years',\n",
       " '  One of our committee’s functions was to monitor the Clintons’ Plan which would have taken over 1/7th of the US economy',\n",
       " ' At the time, then Republican Senator Arlen Spector’s office was the lead Republican office fighting the Clinton Plan',\n",
       " '\\n\\nDuring the Summer of 1994 it seemed all but inevitable that the Clinton Plan was going to become law',\n",
       " ' Then on August 10, 1994 there was a seismic shift in the political debate',\n",
       " ' The Republican Senator entered the Senate floor along with John McCann and presented to the nation a chart that demonstrated to the entire country what a bureaucratic mess the Clinton Plan was for the nation',\n",
       " ' The Senator announced that he was bringing Mr',\n",
       " ' McCann to the floor because he was the one who prepared the chart(s)',\n",
       " ' We on the committee watched and cheered as the Republican Senator used the chart to expose the flaws on the Plan',\n",
       " ' We on staff could see that public opinion was reversed',\n",
       " ' Less than 3 weeks later, the Clinton Plan was declared dead',\n",
       " ' As Staff Director of the Sub Committee on Government Oversight and Management, my staff and I recognized how much work John McCann put into the creation of the chart and held a special appreciation for how he contributed to changing political debate on the Bill',\n",
       " ' The rest is history we are all familiar with',\n",
       " ' The defeat of the Clintons’ Plan significantly weakened the House Democrats and a few weeks later, the Republicans took control of the House of Representatives gaining 54 seats in the next election led by Newt Gingrich’s Contract with America',\n",
       " '\\n\\nI do not live in the district and have no vested interest in this election',\n",
       " ' I do know that John McCann has a great understanding of Health Care Policy; I know that he has a personal interest in it as his wife is a high-risk Obstetrician with his oldest child heading off to medical school this summer',\n",
       " ' In a political climate where people write anonymous emails and posts making wild claims and remarks, I thought that the voters of New Jersey’s District 5, should know the facts concerning Mr',\n",
       " ' McCann’s important role because I was there',\n",
       " '   \\n\\nSincerely,\\n\\nPaul Brubaker\\n\\nFormer Republican Staff Director\\n\\nThe Second Amendment is personal for me—since 1981 when my veteran father was a victim of domestic terrorism',\n",
       " '\\n\\nShot by members of a domestic terror organization while working for Brinks, my father’s—and our family’s life—was never the same',\n",
       " '\\n\\nWithout the ability to defend our homes and our families, we can never truly be free',\n",
       " '\\n\\nThe Founding Fathers provided Americans with the freedom to exercise this right to keep and bear arms without governmental infringement',\n",
       " '\\n\\nOur inalienable rights to life, liberty and the pursuit of happiness are protected by the Second Amendment',\n",
       " ' Guns can save lives',\n",
       " '\\n\\nThis is why I will always fight to defend Second Amendment rights from liberal politicians in Washington and Trenton',\n",
       " '\\n\\nClick here to review my 2018 U',\n",
       " 'S',\n",
       " ' House Candidate Q&A with the NRA',\n",
       " '\\n\\nAs the only candidate in the race that has ever had a carry-and-conceal permit, I am the only pro-gun candidate in NJ-5 who will fight to protect your Second Amendment rights',\n",
       " '\\n\\n\\nSupport our military\\n\\nAs our incredible Defense Secretary James Mattis has said, “No enemy in the field has done more to harm the readiness of our military than sequestration',\n",
       " '”\\n\\nI will work with our President to invest in our military so they are fully equipped to protect our great country and our allies',\n",
       " ' We must roll back the Obama Administration’s cuts to defense spending—which have crippled our ability to defend ourselves, forcing our incredible servicemen and women to use outdated equipment',\n",
       " '\\n\\nJerusalem as Capital of Israel\\n\\nWhen President Trump recognized Jerusalem as the capital of Israel, I applauded this historic decision',\n",
       " ' After eight years of the Obama Administration’s anti-Israel policies, it’s time to restore our unwavering support and defense of Israel—our greatest ally',\n",
       " '\\n\\nNorth Korea\\n\\nIn order to truly Make America Safe Again, we must address North Korean aggression',\n",
       " ' When you send me to Congress, I will work with our President to stop North Korea from becoming a nuclear power',\n",
       " ' We must strengthen our support for allies in the region as well as use economic influence to spur action by the Chinese government',\n",
       " '\\n\\nRocket Man is no match for American leadership',\n",
       " '\\n\\nIran\\n\\nThe Obama Administration’s Iran deal is a national disgrace—rolling back sanctions on the Iranian regime as the nation continues to be a state sponsor of terrorism, advancing both ballistic missile and nuclear weapons programs',\n",
       " '\\n\\nI will work with our President to address all national security threats as we fight to eradicate radical Islamic terror',\n",
       " '\\n\\nI believe in school choice',\n",
       " ' Whether you want your kids in public school, private, charter or homeschool, I believe you—not some D',\n",
       " 'C',\n",
       " ' swamp creature—should be making the best decision for your family',\n",
       " '\\n\\nOur country is far behind other countries in updating our infrastructure',\n",
       " ' I believe this issue may be one of the few bipartisan issues left that we can all agree to work on to improve our communities',\n",
       " ' Through private-public partnerships, I know we can update our infrastructure and make it state-of-the-art',\n",
       " '\\n\\nLife begins at conception',\n",
       " '\\n\\nOn January 19, Congress voted on the “Born-Alive Abortion Survivors Protection Act,” making it the law of the land that a doctor must provide medical care to babies who survive botched abortions',\n",
       " ' While the bill passed the House, Rep',\n",
       " ' Gottheimer voted NO on protecting these poor children',\n",
       " '\\n\\nWhat kind of man votes in favor of letting babies born outside the womb die?\\n\\nLife begins at conception',\n",
       " ' Congress should be fighting for every American’s life whether they be in the womb or in old age—whether they be healthy or suffering from disabilities',\n",
       " '\\n\\nAs a Member of Congress I will oppose all taxpayer funding for any portion of Planned Parenthood’s budget supporting abortion services or the harvesting of fetal tissue',\n",
       " '\\n\\nI am a supporter of women’s healthcare, but there should be no taxpayer funding for abortions',\n",
       " '\\n\\nAs your Congressman, I will fight to ensure the government has a responsibility to protect the sanctity of life—one of our constitutional, Creator-endowed inalienable rights',\n",
       " '\\n\\nOpioid epidemic\\n\\nI have met too many families who have lost husbands, wives and children to the deadly opioid epidemic',\n",
       " '\\n\\nIt’s time we as Americans fight this life-altering crisis together—discovering better ways to treat chronic pain',\n",
       " ' By exploring non-addictive medications and holistic treatments to actually help patients get better, we will empower our fellow Americans to return to full and active lives, enjoying our inalienable rights of life, liberty and the pursuit of happiness',\n",
       " '\\n\\nBig Pharma has a powerful grip on politicians—but I can never be bought',\n",
       " ' I will fight for the best solutions for you—not some lobbyist’s bottomline',\n",
       " '\\n\\nWe also need to cut off the illegal drug supply pouring across our border that is poisoning our youth',\n",
       " ' By securing our Southern border, we will stop the illegal flow and access to deadly drugs',\n",
       " '\\n\\nCongress has become a career for professional politicians like Josh Gottheimer and Bob Menendez',\n",
       " ' The system is broken and we need term limits, which is why I was proud to sign the U',\n",
       " 'S',\n",
       " ' Term Limits pledge and will fight for term limits as your Congressman',\n",
       " ' \\n\\n']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcann_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion \n",
    "\n",
    "\n",
    "By looking at the issues page of a republican and democrat running for the same seat, we see that of the 135 detected statements on the dem's page, 105 were considered dem, good for 78%. On the contrary, the republican's issue page has 107 detected statements, where 61 register as democrat or 57%. At face value this means that the model successfully distinguished which candidate is more democratic of the two, there is a lot more work to be done. For one the training data isn't necessarily perfect and could be drawn from more sources, the strengh of such statements used here may have an impact, among other things. Overall this seems like a good starting point and this project seems to have some potential. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
